---
layout: post
title:  AI Chip（二）, GPU通信技术
category: AI 
---

# AI Chip

## 行业信息（续）

https://mp.weixin.qq.com/s/jINnom16KWiEKiug3N-f8g

一文看懂AI芯片：三大门派四大场景146亿美元大蛋糕

https://mp.weixin.qq.com/s/-FwuhibwwG6CFUcZXNBTFA

投资者梳理AI芯片产业，一文秒懂AI芯片生态！

https://zhuanlan.zhihu.com/p/28325678

零基础看懂全球AI芯片：详解“xPU”

https://mp.weixin.qq.com/s/Zng0NTR9P78lnR_vniiM8g

Chris Rowen: 分析全球334家真正的深度学习创业公司，盘点25家AI芯片创业公司

https://zhuanlan.zhihu.com/p/33462550

传统IP Vendor的AI加速器一览

https://mp.weixin.qq.com/s/IaCWZXQI8mYLJQXwDoNQcQ

自动驾驶芯片：GPU的现在和ASIC的未来

https://mp.weixin.qq.com/s/KjQ5BTGd92Y0Mqzk1A5JYg

老兵戴辉讲述海思视频监控芯片从0到1的血泪史！如何一步步成为行业霸主的

## 参考

https://zhuanlan.zhihu.com/p/58971347

深度学习的芯片加速器

https://cloud.tencent.com/community/article/244743

深度学习的异构加速技术（一）：AI需要一个多大的“心脏”？

https://cloud.tencent.com/community/article/581797

深度学习的异构加速技术（二）：螺狮壳里做道场

https://cloud.tencent.com/community/article/446425

深度学习的异构加速技术（三）：互联网巨头们“心水”这些AI计算平台

https://zhuanlan.zhihu.com/p/25382177

AI芯片怎么降功耗？

https://mp.weixin.qq.com/s/8HIZRhb-KJOtPnQtQ3GQVg

第一代芯片是CPU，第二代是GPU，第三代是什么？

https://mp.weixin.qq.com/s/qkpbKN62YV2f0W5HLnr7Dg

GPU是如何工作的？与CPU、DSP有什么区别？

https://mp.weixin.qq.com/s/Jof-u8oUuLR4v7t3jjXEmA

GPU和线下训练

https://mp.weixin.qq.com/s/2aE5fzGZeyX-oFyWbcbA5A

揭开神经网络加速器的神秘面纱之DianNao

https://mp.weixin.qq.com/s/VAFb0DAZAUyDnjE6SlNcXw

如何对比评价各种深度神经网络硬件？不妨给它们跑个分

https://mp.weixin.qq.com/s/zTO4UZ3zDLZL0GOjv0YqrQ

GPU加速深度学习

https://mp.weixin.qq.com/s/7vxJTh4IHeqUsc7IsLFLSA

解密哈萨比斯投资的IPU，他们要分英伟达一杯羹

https://zhuanlan.zhihu.com/p/26594188

浅析Yann LeCun提到的两款Dataflow Chip

https://zhuanlan.zhihu.com/p/25728988

AI芯片的几种选择，你更看好哪个？

https://zhuanlan.zhihu.com/p/25510056

ISSCC 2017看AI芯片的四大趋势

https://zhuanlan.zhihu.com/p/26404565

AI芯片四大流派论剑，中国能否弯道超车？

https://zhuanlan.zhihu.com/p/27472524

从AI芯片说起，一起来看芯片门类

https://mp.weixin.qq.com/s/Cy_vb0PpcvGTDmlMt1VkSw

从GPU、TPU到FPGA及其它：一文读懂神经网络硬件平台战局

https://mp.weixin.qq.com/s/RKRDBiBzG5u2P2eaqNAFbg

机器学习的处理器列表

https://mp.weixin.qq.com/s/bL1PoUjZ_sH2VKcBxI6N5A

Wave公司发布数据流处理架构DPU

https://mp.weixin.qq.com/s/uzeeZiaAFdA0C_zAcX756w

深度学习架构之争

https://mp.weixin.qq.com/s/VM-KiIJHA2gXLVu0WRIzwA

王中风教授：如何满足不同应用场景下深度神经网络模型算力和能效需求

https://mp.weixin.qq.com/s/f5mQkWxPYc77t2we1Y306Q

深度学习引领AI芯片大战

https://mp.weixin.qq.com/s/6ksL9p1Gmnrd2HahU3KniQ

ARM攒机指南——AI篇：5大千万级设备市场技术拆解

https://zhuanlan.zhihu.com/p/32953957

浅析图像视频类AI芯片的灵活度

https://mp.weixin.qq.com/s/cfqnLYZSxJhtsgtrydx02A

语音及文本类AI芯片的需求分析

https://mp.weixin.qq.com/s/31SBgTXfIcwkmIzujBLxOA

深度学习引擎的终极形态是什么?

https://zhuanlan.zhihu.com/p/35103140

“传说中”的异步电路能否在AI芯片界异军突起？

https://mp.weixin.qq.com/s/DnurlGgd5q4Fwjxy3YnIrQ

当数据库遇见FPGA：X-DB异构计算如何实现百万级TPS？

https://mp.weixin.qq.com/s/PDe8O5zskxD_mycwH0_3lg

AI是如何影响计算机内存系统的？

https://blog.csdn.net/lien0906/article/details/78863118

深度学习中GPU和显存分析

https://mp.weixin.qq.com/s/H_KnHQ6AzCNFqmW8uDj1rA

基于FPGA的深度学习加速器综述：挑战与机遇

http://eyeriss.mit.edu/

Eyeriss是MIT设计的一款NN加速器。

https://zhuanlan.zhihu.com/p/37520172

一窥ARM的AI处理器

https://mp.weixin.qq.com/s/QPuOmv7-agrcgnchgs3Hkg

清华大学提出AI计算芯片的存储优化新方法

https://mp.weixin.qq.com/s/eyzzeYOKdah-9WGUrhbAkg

非冯诺依曼新架构：IBM100万忆阻器大规模神经网络加速AI

https://mp.weixin.qq.com/s/1oDVo7eGMGYODRd00OxpIw

陈天奇团队推出开源AI芯片栈VTA，降低芯片设计门槛

https://mp.weixin.qq.com/s/oOYGa4Mti6KpkpI4TtpitQ

地平线杨铭：从无形视觉到有形芯片

https://mp.weixin.qq.com/s/_8lbTU0GFEXQr_4pdQ6XPw

同步SGD等现有分布式训练方式将过时，Yoshua Bengio谈迈向硬件友好的深度学习

https://mp.weixin.qq.com/s/acAbNP_ERnKlL3_9v_mwow

FPGA：AI ASIC的必经之路？

https://mp.weixin.qq.com/s/5MyuZf_TBm2NV47CRAz5Dw

2017图灵奖得主：通用芯片每年仅提升3%，神经专用架构才是未来

https://mp.weixin.qq.com/s/S1fVrSfAM_UJh06Q43s8vA

网络芯片架构的新改变

https://zhuanlan.zhihu.com/p/47904879

AI芯片在5G中的机会

https://mp.weixin.qq.com/s/Z_QVN7OCLqeyMrwK3Sc7qA

AI芯片和传统芯片的区别

https://mp.weixin.qq.com/s/mMiAGH2Yz42xes7jicyygA

“超级芯片”或在十年内诞生，摩尔定律再续一命！（自旋电子逻辑器件“MESO器件”）

https://mp.weixin.qq.com/s/VysqrYVXG1JiNG86viQ6Xg

学深度学习的你有GPU了吗

https://zhuanlan.zhihu.com/p/57808378

AI芯片0.5与2.0

https://mp.weixin.qq.com/s/XDwTI-gnnFMLjVBbOGKL9w

清华大学团队研制高能效通用神经网络处理器芯片STICKER-T

https://mp.weixin.qq.com/s/xbHP1RFn7F7BbimxgWaKqg

Facebook把服务27亿人的AI硬件系统开源了

https://mp.weixin.qq.com/s/BD-HAILp3TPvBFlIy6QC4w

一文看懂机器视觉芯片

https://mp.weixin.qq.com/s/PMnNay4CRgVghA4fU9oLqg

牛津大学研发类脑光子芯片，运算速度超人脑1000倍

https://mp.weixin.qq.com/s/HeoVktVtvOK4VgocyxuCXg

摩尔定律已死？GPU会取代CPU的位置吗？

https://mp.weixin.qq.com/s/e333KjLavEvvpNIL3u1Y4Q

NovuMind异构智能核心技术引领智联网

https://mp.weixin.qq.com/s/fSSyOs4-NXbPTbDjpfJBNQ

Google IPU：互联网巨头纷纷进军芯片行业是为何？

https://mp.weixin.qq.com/s/S1y4NEx4_Mgwf68S2pexqA

拿着锤子找钉子，数字芯片领导者比特大陆进军人工智能

https://mp.weixin.qq.com/s/gtgPYf939uYRzxAab_LZLQ

谢源：计算存储一体化，在存储里做深度学习，架构创新实现下一代AI芯片

https://mp.weixin.qq.com/s/s-fYxv4z5kkJUFueU2IR7w

BP表达式与硬件架构：相似性构建更高效的计算单元

https://mp.weixin.qq.com/s/1r7G84les7FihqPbSiS0Ng

华为首款手机端AI芯片麒麟970

https://mp.weixin.qq.com/s/y9dVg9YtfWxu6NcW-fxi6Q

内存带宽与计算能力，谁才是决定深度学习执行性能的关键？

https://mp.weixin.qq.com/s/K_dohaZbCISZlxe1Utu50w

如何用FPGA加速卷积神经网络(CNN)？

https://mp.weixin.qq.com/s/z68hk1yqg60QCjgTyzgG2w

GPU深度学习的“加速神器”

https://zhuanlan.zhihu.com/p/31782874

Graphcore AI芯片：更多分析

https://mp.weixin.qq.com/s/O-NDsFs6AOwl43LyevXtzg

OpenAI发布“块稀疏”GPU内核：实现文本情感分析与图像生成建模当前最优水平

https://mp.weixin.qq.com/s/Qfbc2iQnXacOqOGIrpRQRw

Tensor Core究竟有多快？全面对比英伟达Tesla V100/P100的RNN加速能力

https://mp.weixin.qq.com/s/JYTqJDlGw6Q2gNLaYIGLcQ

特斯拉芯片究竟怎么样？

https://mp.weixin.qq.com/s/R1_mXxBrQYgIPlUDGz8w6Q

片上多核系统的互联需求

![](/images/img3/Wallace_Tree.png)

https://mp.weixin.qq.com/s/_n1FA7H5q4AwXqeBg9tekA

硬件实现快速累加

>Christopher Stewart "Chris" Wallace，1933～2004，澳大利亚计算机科学家和物理学家。University of Sydney博士（1959）。Monash University教授。ACM fellow。在早期计算机的软件/硬件方面皆有重大贡献。

https://mp.weixin.qq.com/s/XXef4F9HEZizoWRYXwHitw

如何配置一台深度学习工作站?

https://mp.weixin.qq.com/s/_xFRRkVyN9qevLeek7bFxQ

深度学习中GPU和显存分析

https://mp.weixin.qq.com/s/k5Xx-nnaf-yfWqGLIY3LEg

特斯拉的芯片究竟多强

# GPU通信技术

## RDMA

RDMA网卡（Remote Direct Memory Access，这是一种硬件的网络技术，它使得计算机访问远程的内存时无需远程机器上CPU的干预）已经可以提供50~100Gbps的网络带宽和微秒级的传输延迟。

目前许多以深度学习为目标应用的GPU机群都部署了这样的网络。

参考：

https://mp.weixin.qq.com/s/_xcE8RUs0m4gwk3kxpe9jA

基于HTM/RDMA的可扩展内存事务处理系统

## NVLink

NVLink技术提供比PCIe 3更高的带宽与更多的链路，并可提升多GPU和多GPU/CPU系统配置的可扩展性。

官网：

https://www.nvidia.cn/data-center/nvlink/

![](/images/img3/nvlink.png)

Tesla V100中以NVLink连接的GPU至GPU和GPU至CPU通信。

![](/images/img3/nvlink_2.png)

在DGX-1V服务器中，混合立体网络拓扑使用NVLink连接8个Tesla V100加速器。每个GPU有6条nvlink通道，总带宽高达300GB/s。

从上图可以看到，即使每个GPU拥有6条nvlink通道，仍然无法做到“全连接”（即任意两个GPU之间存在双向通道）。这就引出了下一个更加疯狂的技术：nvswitch。

![](/images/img3/nvswitch.png)

NVSwitch是首款节点交换架构，可支持单个服务器节点中16个全互联的GPU，并可使全部8个GPU对分别以300GB/s的惊人速度进行同时通信。这16个全互联的GPU还可作为单个大型加速器，拥有0.5 TB统一显存空间和2 PetaFLOPS计算性能。

## 参考

https://www.infoq.cn/article/3D4MsRVS8ZOtGCj7*krT

GPU通信技术初探

https://zhuanlan.zhihu.com/p/67785062

不止显卡！这些硬件因素也影响着你的深度学习模型性能
