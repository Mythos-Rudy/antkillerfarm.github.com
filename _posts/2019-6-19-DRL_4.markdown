---
layout: post
title:  深度强化学习（四）——PPO, AlphaGo
category: DRL 
---

# DDPG（续）

## 参考

https://mp.weixin.qq.com/s/dgLJrn3omUKMqmqTIEcoyg

Tensorflow实现DDPG

https://github.com/jinfagang/rl_atari_pytorch

ReinforcementLearning Learn Play Atari Using DDPG and LSTM.

https://zhuanlan.zhihu.com/p/65931777

强化学习-基于pytorch的DDPG实现

https://mp.weixin.qq.com/s/p2jF2Awmgeem-XGCkix-Lg

深度确定性策略梯度DDPG详解

https://mp.weixin.qq.com/s/_dskX5U8gHAEl6aToBvQvg

从Q学习到DDPG，一文简述多种强化学习算法

https://www.zhihu.com/question/323420831

强化学习中A3C/DDPG/DPPO哪个效果更好？

https://blog.csdn.net/gsww404/article/details/80403150

从确定性策略（DPG）到深度确定性策略梯度(DDPG)算法的原理讲解及tensorflow代码实现

https://blog.csdn.net/qq_39388410/article/details/88828548

强化学习（DDPG，AC3，DPPO）

https://blog.csdn.net/qq_30615903/article/details/80776715

DDPG(Deep Deterministic Policy Gradient)算法详解

https://blog.csdn.net/kenneth_yu/article/details/78478356

DDPG原理和算法

# PPO

PPO是2017年由OpenAI提出的一种基于随机策略的DRL算法，也是当前OpenAI的默认算法。



和A3C类似，PPO也有一个分布式版本，叫做DPPO（Distributed Proximal Policy Optimization）。

参考：

https://www.jianshu.com/p/f4d383b0bd4c

TRPO与PPO实现

https://bluefisher.github.io/2018/07/03/Proximal-Policy-Optimization-Algorithms/

Proximal Policy Optimization Algorithms

https://www.jianshu.com/p/9f113adc0c50

Proximal Policy Optimization(PPO)算法原理及实现！

https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/6-4-DPPO/

Distributed Proximal Policy Optimization(DPPO)

# reward modeling

![](/images/img2/reward_modeling.jpg)

训练一个奖励模型，其中包含来自用户的反馈，从而捕捉他们的意图。与此同时，我们通过强化学习训练一个策略，使奖励模型的奖励最大化。换句话说，我们把学习做什么(奖励模型)和学习怎么做(策略)区分开来。

参考：

https://mp.weixin.qq.com/s/4yGQtHtMqWlaB7MAsr8T_g

DeepMind重磅论文：通过奖励模型，让AI按照人类意图行事

https://mp.weixin.qq.com/s/TIWnnCmVZnFQNH9Fig5aTw

DeepMind发布新奖励机制：让智能体不再“碰瓷”

# AlphaGo

樊麾讲解AlphaGo与李世石的五番棋：

https://deepmind.com/research/alphago/alphago-games-simplified-chinese/

论文：

《Mastering the game of Go with deep neural networks and tree search》

2017.1

岁首，业界最重要的事情莫过于AlphaGo以Master之名再度出山，60场快棋未遇敌手。牛逼！

## DarkForest

DarkForest是田渊栋2015年11月的作品，虽然棋力和稍后的AlphaGo相去甚远，但毕竟也算是用到了RL和DNN了。

代码：

https://github.com/facebookresearch/darkforestGo

## Leela Zero

Leela Zero是比利时人Gian-Carlo Pascutto开源的围棋AI。它的算法与AlphaGo Zero相同。而训练采用GTP协议，集合全球算力，进行分布式训练。

官网：

http://zero.sjeng.org/

代码：

https://github.com/gcp/leela-zero

>十多年前，当我还是一个中二青年的时候，就幻想有朝一日能够拿围棋世界冠军。当然，就算再中二，我自己也明白靠实力那是不可能的，当时做梦的法宝是制造一个AI，然后碾压一下所谓的国手。   
>按照当时(2000年前后)人们的预计，这个AI在2030年之前，都不可能造出来，然而，最终的结果实际上只花了一半左右的时间。   
>再之后，随着AI围棋的平民化，我的中二梦终于也有人将之付诸实现了：   
>https://mp.weixin.qq.com/s/npt2zZrKwPnNdY-hsa2RjQ   
>AI再乱围棋圈：“食言之战”柯洁落败；首例素人作弊引风波

这次作弊风波所使用的AI就是Leela Zero，可见目前（2018.5）它的棋力已经超过了顶尖棋手。

## ELF OpenGo

ELF OpenGo是Facebook开源的围棋AI，它是FB的AI游戏框架ELF的一部分。

官网：

https://github.com/pytorch/ELF

参考：

https://mp.weixin.qq.com/s/lOAx3suLIS-pEWyi8xZl6Q

“全民体验”AlphaZero：FAIR田渊栋首次开源超级围棋AI

## PhoenixGo

PhoenixGo是腾讯微信团队的AlphaGo Zero复刻版。

官网：

https://github.com/Tencent/PhoenixGo

参考：

https://mp.weixin.qq.com/s/tJDmxsuS1QigYS75ZIdzRA

微信团队开源围棋AI技术PhoenixGo，复现AlphaGo Zero论文

## 参考

https://mp.weixin.qq.com/s/Sfv-jzQAkN0PsZOGZUQhkQ

AlphaGo Zero横空出世，DeepMind Nature论文解密不使用人类知识掌握围棋

https://mp.weixin.qq.com/s/oAxouYX7-wDC5okbu--Wuw

Nature重磅：人工智能从0到1, 无师自通完爆阿法狗100-0

https://zhuanlan.zhihu.com/p/30262872

关于AlphaGo Zero

https://zhuanlan.zhihu.com/p/30263585

DeepMind新一代围棋程序AlphaGo Zero再次登上Nature

https://www.zhihu.com/question/66861459

如何评价DeepMind发表在Nature上的AlphaGo Zero？

http://www.alphago-games.com/

AlphaGo的棋谱

https://deepmind.com/blog/alphago-zero-learning-scratch/

AlphaGo Zero官方声明

https://zhuanlan.zhihu.com/mathNote

某牛的专栏，主要讲自制AlphaGo

https://mp.weixin.qq.com/s/DC9QqHdWT0xFnowEBuJDbw

自动化所解读“深度强化学习”：从AlphaGo到AlphaGoZero

https://mp.weixin.qq.com/s/uZtaxRwROCqYmL2k6Muxaw

从阿尔法狗元(AlphaGo Zero)的诞生看终极算法的可能性

https://mp.weixin.qq.com/s/i5OmLu8aNbypiTUmP4teeQ

刘遥行：深入浅出看懂AlphaGo Zero

https://mp.weixin.qq.com/s/aBrwbB_DOGTen-6XL7LGFQ

邓侃：白话蒙特卡洛树搜索和ResNet

https://mp.weixin.qq.com/s/nbTkr0PImlXUSYl91HD91Q

AlphaGo背后的力量：蒙特卡洛树搜索入门指南

https://mp.weixin.qq.com/s/-tH7DQo1cK9gA0bcpBJSDA

AlphaGo Zero：笔记与伪代码

https://mp.weixin.qq.com/s/CJuVoOf7idUChFIn7dH0Lg

围棋中的数学原理

https://mp.weixin.qq.com/s/d46qNFaftt4wxpV4sZnG-w

一张图看懂AlphaGo Zero

https://zhuanlan.zhihu.com/p/31749249

比AlphaGo Zero更强的AlphaZero问世，8小时解决一切棋类！

https://mp.weixin.qq.com/s/L7bZMkqyncwEt6D5tK1OdQ

AlphaZero炼成最强通用棋类AI，DeepMind强化学习算法8小时完爆人类棋类游戏

https://mp.weixin.qq.com/s/tFdnxqV5a5xZrFtB6E0AiQ

新AlphaZero出世称霸棋界，8小时搞定一切棋类！自对弈通用强化学习无师自通！

https://mp.weixin.qq.com/s/qYWsFBKNCKCGUmizX_1sVg

AlphaGo 教学工具终于上线了！

https://mp.weixin.qq.com/s/JxbIeDk8_wnYu_ewUHp29g

深度学习与围棋实战书籍《Deep Learning and the Game of Go》

https://mp.weixin.qq.com/s/gsRnbknytz2FY2dWgdWEYg

精通国际象棋的AI研究员：AlphaZero真的是一次突破吗？

https://mp.weixin.qq.com/s/Przl4ivbNuOFmz4pcYTrpQ

浅述：从Minimax到AlphaZero，完全信息博弈之路（1）

https://zhuanlan.zhihu.com/p/32089487

AlphaZero实战：从零学下五子棋

http://mp.weixin.qq.com/s/72riTTC3w0q9oF5H-51kXA

手把手教你搭建AlphaZero（使用Python和Keras）

https://mp.weixin.qq.com/s/Qw2tT7H1PwDvPgOYy8YUsQ

AlphaGo Zero代码迟迟不开源，TF等不及自己推了一个

https://mp.weixin.qq.com/s/Vq-osjgNXJQu5avGkxQdsw

手把手：AlphaGo有啥了不起，我也能教你做一个

https://mp.weixin.qq.com/s/ajajJ9yJZsOy4Vc0ULBxXg

国际象棋版AlphaZero出来了诶，还开源了Keras实现

https://zhuanlan.zhihu.com/p/41814142

从源码解密AlphaGo Zero背后基本原理

https://www.ifanr.com/630602

AlphaGo的棋局，与人工智能有关，与人生无关

https://mp.weixin.qq.com/s/J0w6kzzdKTbsaiZitbQdoA

达观数据：一文详解AlphaGo原理

https://mp.weixin.qq.com/s/BBQ54HHrFiqxXkC-EI6ELw

Science封面：AlphaZero达成终极进化体，史上最强棋类AI降临！

https://mp.weixin.qq.com/s/Pgw_xaCNl_kCPCg8NFzUBQ

人类没法下了！DeepMind贝叶斯优化调参AlphaGo，自弈胜率大涨16.5%

https://mp.weixin.qq.com/s/eE3oL6c5zHmTglHE-dgBvg

详解AlphaGo到AlphaGo Zero！

https://mp.weixin.qq.com/s/aAF0Gr7yEPkHRLASecJipw

百度正用谷歌AlphaGo，解决一个比围棋更难的问题
