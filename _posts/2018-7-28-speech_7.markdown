---
layout: post
title:  语音识别（七）——WFST（2）, 声纹识别
category: speech 
---

# WFST

## 相关的群论知识（续）

在WFST中用的比较多的是log半环和tropical半环。前者对路径概率进行了对数运算，而后者在log半环的基础上，进行了viterbi approximation，也就是用若干路径的概率极值，作为当前概率值，这和动态规划中的viterbi算法是一致的。

接下来定义WFST上的二元运算：

一整条路径的权重$$w[\pi ]=w[e_1]\bigotimes \cdots \bigotimes w[e_k]$$。

多个有限路径集合的权重$$w[R]=\bigoplus_{\pi \in R} w[\pi]$$。

参考：

http://hongjiang.info/semigroup-and-monoid/

半群(semigroup)与幺半群(monoid)

## Sum(Union)

介绍完WFST的定义，再来介绍一下定义在它之上的运算。

![](/images/img2/sum.png)

Sum运算的形式化描述为：

$$[T_1 \oplus T_2](x,y)=[T_1](x,y)\oplus [T_2](x,y)$$

## Product(Concatenation)

![](/images/img2/product.png)

Product运算的形式化描述为：

$$[T_1 \otimes T_2](x,y)=\bigoplus_{x=x_1x_2,y=y_1y_2} [T_1](x_1,y_1)\otimes [T_2](x_2,y_2)$$

## Closure

![](/images/img2/closure.png)

Closure运算的形式化描述为：

$$[T^*](x,y)=\bigoplus_{n=0}^{\infty}[T^n](x,y)$$

## Reversal

![](/images/img2/reversal.png)

Reversal运算的形式化描述为：

$$[\widetilde{T}](x,y)=[T](\widetilde{x},\widetilde{y})$$

## Inversion

![](/images/img2/inversion.png)

Inversion运算的形式化描述为：

$$[T^{-1}](x,y)=[T](y,x)$$

## Projection

![](/images/img2/projection.png)

Projection运算的形式化描述为：

$$[\prod_1(T)](x)=\bigoplus_y[T](x,y)$$

## Composition

Composition用来合并不同级别的转换器。用$$T=T_1\circ T_2$$表示这种操作。

![](/images/img2/composition.png)

Composition运算的形式化描述为：

$$[T_1\circ T_2](x,y)=\bigoplus_z [T_1](x,z)\bigotimes [T_2](z,y)$$

通俗一些的说法就是：

（1）起始状态应该是$$T_1，T_2$$的起始状态

（2）结束状态是$$T_1，T_2$$的结束状态

（3）如果$$q_1$$到$$r_1$$的边$$t_1$$的输出等于$$q_2$$到$$r_2$$的边$$t_2$$的输入，那么$$(q_1,q_2)$$和$$(r_1,r_2)$$应该有一条边，如果是tripical半环，则该边权重是以上两边权重之和。

当$$T_1$$的输出包含$$\epsilon$$，$$T_2$$的输入包含$$\epsilon$$的时候，会导致产生大量多余的边，使得最终结果不正确。这时需要去除$$\epsilon$$-path。细节略。

## Intersection

![](/images/img2/intersection.png)

Intersection运算的形式化描述为：

$$[A_1\cap A_2](x)=[A_1](x)\otimes[A_2](x)$$

Intersection是求两个WFST的公共部分，并把相应的权重相加。

## Difference

![](/images/img2/difference.png)

Difference运算的形式化描述为：

$$[A_1 - A_2](x)=[A_1\cap \overline{A_2}](x)$$

Difference大约是简单操作中最不好懂的了，我足足看了2个小时才看明白。

Difference的字面意思是：从A中去掉B。

比如上图中的A可以接受4个序列：ab,ad,cb,cd。但是ab,cd出现在B中，因此A-B就只有ad和cb了。可以看出，这里的B，其权重是无关紧要的，因此该操作要求B必须是无权重的FST。

## Connection

下面的几个运算属于图优化的范畴，因此没有简单的形式化描述，而只有算法流程。但限于篇幅，这里只讲运算的含义，而不讲具体的算法流程。

**既然是优化，则运算前后的FST必然是等价的。**

![](/images/img2/connection.png)

Connection运算用于计算FST的连通性。上图中的状态3，4和初始状态0之间没有连通，所以应该去掉。状态5没有路径到达终止状态2，所以也应该去掉。

## $$\epsilon$$-Removal

![](/images/img2/remove.png)

$$\epsilon$$-Removal运算用于去除FST中的$$\epsilon$$-transitions。

这里分为两步。

**Step1：计算$$\epsilon$$-closures。**closures中两个State的距离被称作$$\epsilon$$-Distances，这里不妨用$$ED(A\to B)$$来表示。

例如上图中：

$$ED(0\to 3)=ED(0\to 1)+ED(1\to 3)=\epsilon:\epsilon/0.2+\epsilon:\epsilon/0.6=\epsilon:\epsilon/0.8$$

**Step2：去除$$\epsilon$$-transitions。**

这里以0->4之间的`a:a/1.6`为例介绍一下计算方法。首先，0->4之间并没有直接的`a:a`连线，但是3->4有`a:a`连线。因此：

$$a:a/0.8+ED(0\to 3)=a:a/0.8+\epsilon:\epsilon/0.8=a:a/1.6$$

## Determinization

Determinization：所有状态在接受某个输入后只有一条输出边，而且不包含$$\epsilon$$。

这个操作的根本前提：两个自动机或者转换器是否相等，不需要每条边，每个权重都相等。只需要对于任何一个输入序列，其输出及权重相同，而不用在意权重的分布是否相同。

一般使用$$\otimes$$来计算分支内的权重。使用$$\oplus$$来处理分支间最终输出的权重。

![](/images/img2/determinization.png)

Determinization之后的FST采用`(原始状态号,剩余权重)`的方式表示Node。例如上图中，从(0,0)到(1,0)(2,1)的边a/1上消耗权重1，原图状态1，状态2剩余权重分别是0和1，所以用(1,0)(2,1)表示。 在输出到下一个状态时候，将剩余权重加上。比如原图中d/6,这里变成d/7。

## Pushing

Pushing包括Weight Pushing和Label Pushing两种情况。

![](/images/img2/weight_pushing.png)

上图是Weight Pushing的例子。如果WFST不在乎权重的分布，而只在乎最终权重的大小的话，则可以将权重前推（Pushing），以利于最小化。

![](/images/img2/label_pushing.png)

上图是Label Pushing的例子，将非$$\epsilon$$的label前推。

Kaldi中没有使用weight pushing。

## Minimization

最小化的目的是减少原图中的状态数，以及转移边数。从而减少存储空间和计算时间。

最小化一般是消除相同结点。常用算法与DFA的最小化算法类似。

## Pruning

![](/images/img2/pruning.png)

Pruning的目的是去除大于最短路径的$$\otimes$$分支。

## Other

除了这些常用操作之外，还有add-self-loops和remove-disambiguation-symbols等操作。这里不再赘述。

## HCLG

介绍完WFST的基本运算，这里来介绍一下WFST在语音识别上的应用——HCLG。

![](/images/img2/HCLG.png)

上图中，Language Model又名Grammar Model，Phonemic Model又名Lexicon Model，故名HCLG。

这个流程的形式化描述为：

$$H\circ C\circ L\circ G$$

直接使用这个WFST的状态空间较大，搜索效率比较低，Mohri因此提出了一个简化方案：

$$N = \pi_{\epsilon} (min(det(\tilde{H} \circ det(\tilde{C} \circ det(\tilde{L} \circ G)))))$$

## 参考

https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/ParallelizingWFSTSpeechDecoders.ICASSP2016.pdf

《parallelizing WFST speech decoders》

http://www.cs.nyu.edu/~mohri/pub/csl01.pdf

《Weighted Finite-State Transducers in Speech Recognition》

https://blog.csdn.net/l_b_yuan/article/category/6132477

这个专栏包含了4篇WFST的blog

http://djt.qq.com/article/view/507

定制你的语音识别-并行语音识别解码空间

https://blog.csdn.net/lucky_ricky/article/details/77511543

Kaldi WFST 构图 学习

https://blog.csdn.net/dearwind153/article/details/70053704

Kaldi HCLG深入理解

https://zhuanlan.zhihu.com/p/31174085

有限状态自动机和转换器在元音和谐处理中的应用。这篇blog研究的问题相对偏门，但是文末附有若干FST方面的软件资源，可以提供OpenFST之外的选择。

https://www.jianshu.com/p/5eb45c64f3e3

深入浅出理解有限状态机

http://infolocata.com/mirovia/finite-state-transducers-for-natural-language-processing/

Finite-State-Transducers for Natural Language Processing

https://zhuanlan.zhihu.com/p/23664023

构建CTC语音识别解码网络

https://mp.weixin.qq.com/s/2Un2Vy33dkxPwe8n7d_Yng

一个有限状态机的C++实现

# 声纹识别

声纹识别关心的“**谁在说**”，用于解决**生物身份确认和识别**；而语音识别关心的“**说了什么**”，用于解决**对说话内容的识别**。

对测试语音，同样提取mfcc->提取i-vector，然后进行打分，打分的方法有cosine, LDA, PLDA，其中PLDA的效果是最好的，但是需要数据去训练获得参数。

代码的话，推荐kaldi里的sre10/v1，里面有全套的i-vector/PLDA说话人识别系统流程。

这方面的数据集有：

https://ivectorchallenge.nist.gov

NIST i-vector Machine Learning Challenge

参考：

https://zhuanlan.zhihu.com/voicebiometrics

专栏：声纹识别的应用实践

https://www.jianshu.com/p/513dadeef1fd

声纹识别

https://blog.csdn.net/twinkle_star1314/article/details/55049746

声纹识别

https://blog.csdn.net/twinkle_star1314/article/details/55050138

声纹识别2

https://zhuanlan.zhihu.com/p/67088235

声纹识别5大核心知识点

https://zhuanlan.zhihu.com/p/24425179

End-to-End Voiceprint

https://mp.weixin.qq.com/s/I2nbzD2QqSYgahI2jLjYTQ

批训练、注意力模型及其声纹分割应用，谷歌三篇论文揭示其声纹识别技术原理

https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650750181&idx=5&sn=96d85740cb3d696cd2833f35f7908a6b

只对你有感觉：谷歌用声纹识别实现定向人声分离

https://mp.weixin.qq.com/s/Cfk3639bCy55qQj4HM2HWw

人工智能老司机带你认识声音黑科技：声纹识别

# 汽车声学

https://zhuanlan.zhihu.com/p/22722073

当我谈汽车声学时，我在谈什么(一)

https://zhuanlan.zhihu.com/p/28608243

当我谈汽车声学时，我在谈什么(二)

https://zhuanlan.zhihu.com/p/31240294

当我谈汽车声学时，我在谈什么(三)

https://zhuanlan.zhihu.com/p/34256635

当我谈汽车声学时，我在谈什么(四)

# ASR参考资源

https://zhuanlan.zhihu.com/p/40329331

谈谈语音识别与人声的物理原理，以及真声假声头声混声等概念

https://mp.weixin.qq.com/s/CjWNZf225OELIBoWRAbakg

全面了解什么是语音交互

# NLP参考资源

https://mp.weixin.qq.com/s/foknrQWnBxc4b0bpkFKSdQ

上海科技大学ACL2018高分论文：混合高斯隐向量文法

https://zhuanlan.zhihu.com/p/37621168

微博关键词抽取：借力评论信息

https://mp.weixin.qq.com/s/znafd7_N_TrQBFWvxYM_hg

基于强化学习的中文零指代消解模型

https://mp.weixin.qq.com/s/2QQ_lWUCExvdiXn2wJJeRQ

地理文本处理技术在高德的演进(上)

https://mp.weixin.qq.com/s/9GuyWUZ_qCH5Q_rin1yQwg

地理文本处理技术在高德的演进(下)
