---
layout: post
title: CPU(二)
category: Chip 
---

* toc
{:toc}

# CPU

## 封装

### BGA & QFP

BGA封装，就是那种引脚都在芯片背面的封装。QFP封装，即四侧引脚扁平封装。同样面积情况下，显然占据一个面的引脚数，要超过仅占据四个边的引脚数。

### 参考

https://mp.weixin.qq.com/s/vGONCRzvFGVo6giUFq0uag

芯片封装类型总结

https://mp.weixin.qq.com/s/RtSmbwguM7dbsXkWqAPuCQ

英特尔3D封装技术深度解读

https://zhuanlan.zhihu.com/p/54685671

PCB板上的黑色的物体是什么？

https://mp.weixin.qq.com/s/MQHZ-yLhZRIfOL9kN4XFKw

一文看懂3D封装技术及发展趋势

https://mp.weixin.qq.com/s/WBab6k4mIkZNzpvbgSbpVQ

一文看懂SiP封装技术

https://mp.weixin.qq.com/s/S-YGgvE6ey2t9_YmVmKOFg

一份难得的MOS管封装分析报告

https://mp.weixin.qq.com/s/FVcmCvimpoGCtCtm4RDtUg

浅谈先进封装技术

https://mp.weixin.qq.com/s/MXuN1ccza508TMkcYVadvA

芯片封装简史

## 片上网络

片上网络network-on-chip（NoC）是片上系统 system-on-chip（SoC）的一种新的通信方法。它是多核技术的主要组成部分。NoC方法带来了一种全新的片上通信方法，显著优于传统总线式系统（bus）的性能。

https://zhuanlan.zhihu.com/p/63683111

详说片上网络之一：片上多核系统与片上网络的发展

https://zhuanlan.zhihu.com/p/65501500

详说片上网络之二：片上多核系统的互联需求

https://zhuanlan.zhihu.com/p/68393867

详说片上网络之三：片上互联的需求与片上网络的研究意义

https://zhuanlan.zhihu.com/p/69012724

详说片上网络之四：片上网络研究的难与易

https://zhuanlan.zhihu.com/p/71775965

详说片上网络之五：网络分层模型在片上网络上的实现（上）

https://zhuanlan.zhihu.com/p/78672250

详说片上网络之六：网络分层模型在片上网络上的实现（下）

https://mp.weixin.qq.com/s/AW08yhPzBZqfys8CbOjrYg

详说片上网路（NoC）技术

https://www.zhihu.com/question/31049944

片上网络NoC为何还没有得到实际应用？

## 南北桥

北桥芯片则是整个主板的数据交换中枢，整合有内存控制器以及AGP/PCI-E控制器等重要的控制功能，CPU、GPU与内存之间的数据交换都要通过北桥芯片进行；

南桥芯片则用于扩展外围I/O接口，例如SATA和USB接口等。

## 历史

NetBurst可以说是Intel历史上最大的战略错误。

https://www.zhihu.com/answer/137624368

历史上有哪些“大力出悲剧”的产品？

---

https://mp.weixin.qq.com/s/-2kGkJzjay2WJzIpMs2Adw

IEEE盘点27款震撼世界的芯片

https://mp.weixin.qq.com/s/KhY-PPdvZ26Uy8xEgi70DA

纪念晶体管诞生71周年——改变世界30款芯片大阅兵！

http://m.uczzd.cn/webview/news?aid=15020380163392206798

你所不知道的经典科技发展史: 以前CPU是如何设计出来的

https://mp.weixin.qq.com/s/Lnolh9y0rf86wOGa-F1xmw

计算机的诞生史

https://mp.weixin.qq.com/s/f_rk-NPKNzYpbHOr5bgluw

一文了解半导体的过去、现在和未来

https://mp.weixin.qq.com/s/A6tc00Azj9AM-FApt5CkTQ

AMD YES！背后不为人知的故事

https://mp.weixin.qq.com/s/EfjhstpXsl6sG9q_-qQjXQ

世界半导体集成电路发展史

https://mp.weixin.qq.com/s/pSKQ3lRYV13qU_5DaOw2HQ

晶体管发展历程回顾

## AVX

MMX直接使用了80bit的FPU寄存器中的64bit，对CPU整个流水线几乎没有影响；SSE的128bit相比80bit增加了48bit宽度还算可以接受。AVX的256bit，整个CPU的数据通道比80bit增加了三倍多，需要消耗三倍的晶体管，功率也增加了三倍。因此在严格限定功耗的场景如笔记本或者服务器中，CPU运行AVX应用时需要降低频率从而降低功耗。

为了适应DL领域的应用，AVX还添加了一个VNNI的扩展指令集（Vector Neural Network Instructions）。

参考：

https://www.zhihu.com/question/406517759

如何看待Linus Torvalds对AVX512的评价？

https://zhuanlan.zhihu.com/p/449878214

向量化引擎初探（一）

## Cache

Cache本质上是一块小而快的存储设备和另一块大而慢的存储设备之间的协作关系。

Cache分为硬件Cache和软件Cache两种，这里只讨论前者。后者参见《数据库（一）》。

![](/images/img4/cache.jpg)

![](/images/img4/Mem_Gap.png)

上图展示了CPU和DRAM之间的速度增长的差异，这个差异通常被称为Memory Gap。1980年代以前的计算机是没有Cache的，但是随着Memory Gap的增大，Cache的级数也不断增多，目前3级片上Cache+1级片外Cache已经是标配了。

必须指出的是，和CPU的速度受限于技术进步不同，RAM的问题主要是性能和价格的折衷。Cache实际上也是一种RAM，最好的L0 Cache和CPU的速度相当，只是价格太高而已。

类似这样的还有PCB的线宽。微米级的线宽技术上完全可行，毕竟芯片都已经是纳米级的线宽了，主要还是价格的问题。

多核CPU多级缓存的一致性，一般由相关的一致性总线协议保证。这些协议包括：MSI、MESI和MOESI。

https://mp.weixin.qq.com/s/cSu-P-aDSXH0CYLN2HNrxw

深入理解Cache（上）

https://mp.weixin.qq.com/s/rml_wqePIx8vOk2ZO9_GMA

深入理解Cache（下）

https://mp.weixin.qq.com/s/Lydg1TMlNO_98Z-NF5BIBQ

理解CPU Cache

https://mp.weixin.qq.com/s/8g33nTI_-i9Rzmu-5Up-HA

高性能编程：三级缓存（LLC）访问优化

https://mp.weixin.qq.com/s/QidAD9OuVdEXFqxRMPx5lQ

响应速度不给力？解锁正确缓存姿势

https://mp.weixin.qq.com/s/570O2BloWjy3q0_m_mfiZg

CPU缓存一致性协议

https://mp.weixin.qq.com/s/ziJ8OFiLA1it3sQvycN7Mg

翻越缓存的三座大山

https://zhuanlan.zhihu.com/p/63494668

显存为什么不能当内存使？内存、Cache和Cache一致性

https://mp.weixin.qq.com/s/AekR-mv9EOD-4V5SKqI9YQ

一文看懂缓存

https://mp.weixin.qq.com/s/FY8sEX4acEUpCu_6ntArYw

CPU缓存L1/L2/L3工作原理

https://blog.csdn.net/ZoeyyeoZ/article/details/51804647

MESI&MOESI协议

https://mp.weixin.qq.com/s/G4SpTC8DZ-l5kWBRGwSwGQ

Linux内存、Swap、Cache、Buffer详细解析

## Bélády's Algorithm

Bélády认为最好的缓存算法是：丢弃那些在将来最长时间不被使用的数据。显然这是一个理想化的算法，因为我们没有办法预测未来。但它可以作为衡量缓存算法优越度的一个理论上限。

>László Bélády，1928年生，匈牙利计算机科学家。Technical University of Budapest本硕。IBM研究员。

LFU: least frequently used

LRU: least recently used

https://mp.weixin.qq.com/s/AdmEd1FHxpZUwSGYy3qggg

利用cpu缓存实现高性能程序

## 存算一体

![](/images/img4/bottleneck.png)

传统架构存在上图所示的“存储墙”问题。

目前存算技术主要有几个方向：

查存计算（Processing With Memory）：GPU中对于复杂函数就采用了这种计算方法，是早已落地多年的技术。存储芯片内部的存储单元完成查表计算操作，存储单元和计算单元完全融合，没有一个独立的计算单元。

近存计算（Computing Near Memory）：典型代表包括AMD的Zen系列CPU。计算操作由位于存储区域外部的独立计算芯片/模块完成。这种架构设计的代际设计成本较低，适合传统架构芯片转入。

存内计算（Computing In Memory）：典型代表是Mythic、闪忆、知存、九天睿芯。计算操作由位于存储芯片/区域内部的独立计算单元完成，存储和计算可以是模拟的也可以是数字的。这种路线适合算法固定的场景算法计算，目前主要用于语音等轻算力场景。

https://mp.weixin.qq.com/s/kq5F47N3LS43ZKdwe9-CUQ

端侧智能存算一体芯片的需求、现状与挑战

## Jim Keller

<table style="text-align:center" width="85%">
  <tbody>
    <tr>
      <td colspan="5">Jim Keller: Work Experience</td>
    </tr>
    <tr>
      <td colspan="2" rowspan="1"></td>
      <td>Company</td>
      <td>Title</td>
      <td>Important<br />
      Product</td>
    </tr>
    <tr>
      <td><strong>1980s</strong></td>
      <td><strong>1998</strong></td>
      <td>DEC</td>
      <td>Architect</td>
      <td>Alpha</td>
    </tr>
    <tr>
      <td><strong>1998</strong></td>
      <td><strong>1999</strong></td>
      <td>AMD</td>
      <td>Lead Architect</td>
      <td>K7, K8v1<br />
      HyperTransport</td>
    </tr>
    <tr>
      <td><strong>1999</strong></td>
      <td><strong>2000</strong></td>
      <td>SiByte</td>
      <td>Chief Architect</td>
      <td>MIPS Networking</td>
    </tr>
    <tr>
      <td><strong>2000</strong></td>
      <td><strong>2004</strong></td>
      <td>Broadcom</td>
      <td>Chief Architect</td>
      <td>MIPS Networking</td>
    </tr>
    <tr>
      <td><strong>2004</strong></td>
      <td><strong>2008</strong></td>
      <td>P.A. Semi</td>
      <td>VP Engineering</td>
      <td>Low Power Mobile</td>
    </tr>
    <tr>
      <td><strong>2008</strong></td>
      <td><strong>2012</strong></td>
      <td>Apple</td>
      <td>VP Engineering</td>
      <td>A4 / A5 Mobile</td>
    </tr>
    <tr>
      <td><strong>8/2012</strong></td>
      <td><strong>9/2015</strong></td>
      <td>AMD</td>
      <td>Corp VP and<br />
      Chief Cores Architect</td>
      <td>Skybridge / K12<br />
      (+ Zen)</td>
    </tr>
    <tr>
      <td><strong>1/2016</strong></td>
      <td><strong>4/2018</strong></td>
      <td>Tesla</td>
      <td>VP Autopilot<br />
      Hardware Engineering</td>
      <td>Fully Self-Driving<br />
      (FSD) Chip</td>
    </tr>
    <tr>
      <td><strong>4/2018</strong></td>
      <td><strong>6/2020</strong></td>
      <td>Intel</td>
      <td>Senior VP<br />
      Silicon Engineering</td>
      <td>?</td>
    </tr>
    <tr>
      <td colspan="2" rowspan="1"><strong>2021</strong></td>
      <td>Tenstorrent</td>
      <td>President and CTO</td>
      <td>TBD</td>
    </tr>
  </tbody>
</table>

## NUMA

![](/images/img2/NUMA.jpg)

上图是NUMA（Non-Uniform Memory Access）的结构图。可以看到CPU和一部分内存直接相连，而和其他内存通过总线相连。如果我们把局部数据放到直连内存上，CPU显然就能够更快速的访问数据。

与NUMA相关的还有一个著名的BUG：

https://zhuanlan.zhihu.com/p/387117470

十年后数据库还是不敢拥抱NUMA？

参考：

https://software.intel.com/en-us/articles/optimizing-applications-for-numa

Optimizing Applications for NUMA

https://mp.weixin.qq.com/s/uH0XRjDNfVQe5r1aes0zDw

性能之殇：从冯·诺依曼瓶颈谈起

## 多核

https://zhuanlan.zhihu.com/p/53596593

所有CPU内核一定生来平等吗？Intel非对称异构多处理器：Lakefield

https://en.wikipedia.org/wiki/ARM_big.LITTLE

ARM的big.LITTLE架构
