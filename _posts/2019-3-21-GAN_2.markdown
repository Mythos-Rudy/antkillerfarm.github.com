---
layout: post
title:  GAN（二）——GAN进阶, GAN的评估指标
category: GAN & VAE 
---

# 概况（续）

## Lipschitz约束

继续思考一下，我们会发现问题还没完。我们目前还没有对D做约束，不难发现，无约束的话Loss基本上会直接跑到负无穷去了～

最简单的方案就是采用Lipschitz约束：

$$\| D(y,\theta) - D(y' , \theta) \| \leq C \|y-y'\|$$

也可写作：

$$\left\| \frac{\partial D(y,\Theta)}{\partial y}\right\| \leq C$$

## WGAN

KL散度和JS散度由于不是距离，数学特性并不够好。

![](/images/img3/GAN_4.png)

如上图所示，从左到右，$$P_G$$和$$P_{data}$$的分布是越来越接近，然而前两个的JS散度居然是一样的。

究其原因在于：

1.对于两个没有交集的分布，它们的JS散度为$$\log 2$$。然而没有交集，并不意味着在空间中距离遥远。

2.采样总是有限的，即便是有交集的分布，其采样也未必有交集。

显然，**在这种情况下，JS散度是没有区分度的，梯度也就不存在了。**

因此，Martín Arjovsky于2017年1月，提出了Wasserstein GAN。

其中的一项改进就是使用Wasserstein距离替代KL散度和JS散度。Wasserstein距离的定义参看《机器学习（二十七）》。

WGAN极大程度的改善了GAN训练困难的问题，成为当前GAN研究的主流。

论文：

《Wasserstein GAN》

此外，还有使用最小二乘代替JS散度的GAN——LSGAN。

参考：

https://zhuanlan.zhihu.com/p/25071913

令人拍案叫绝的Wasserstein GAN

https://zhuanlan.zhihu.com/p/25204020

条条大路通罗马LS-GAN：把GAN建立在Lipschitz密度上

https://mp.weixin.qq.com/s/UO0pNLcwYN5tE5x_4azVJA

LSGAN：最小二乘生成对抗网络

https://zhuanlan.zhihu.com/p/65002974

《Towards Principled Methods for Training GAN》阅读笔记

## 其他细节

1.GAN的目的是在高维非凸的参数空间中找到纳什均衡点（Nash equilibrium），GAN的纳什均衡点是一个鞍点。而SGD只会找到局部极小值，所以GAN中的优化器不常用SGD。

![](/images/img3/Nash.png)

>John Nash，1928～2015，数学家、经济学家。Princeton博士（1950），Princeton教授。主要研究博弈论、微分几何学和偏微分方程。诺贝尔经济学奖获得者（1994）。奥斯卡金像奖电影《美丽心灵》男主角原型。

## 参考

https://mp.weixin.qq.com/s/xa3F3kCprE6DEQclas4umg

GAN的数学原理

http://www.jianshu.com/p/e2d2d7cbbe49

50行代码实现GAN

https://mp.weixin.qq.com/s/pgWysIGObceGVrxs85kyew

白话生成对抗网络GAN，50行代码玩转GAN模型！

https://mp.weixin.qq.com/s/YnOF9CCUFvtaiTY8HXYOuw

深入浅出：GAN原理与应用入门介绍

http://blog.csdn.net/u011534057/article/category/6396518

GAN系列blog

https://mp.weixin.qq.com/s/4CypEZscTfmUzOk-p_rZog

生成对抗网络初学入门：一文读懂GAN的基本原理

http://mp.weixin.qq.com/s/bzwG0QxnP2drqS4RwcZlBg

微软详解：到底什么是生成式对抗网络GAN？

https://mp.weixin.qq.com/s/TIgRVbnZYtrGUCDNLcL1uw

GAN的入门与实践

https://mp.weixin.qq.com/s/er-VG1P8iNIcQew2gXZqGw

一文读懂生成对抗网络

https://mp.weixin.qq.com/s/BNWPTPl_vowAlQUQ7__wvQ

有三说GANs

https://zhuanlan.zhihu.com/p/24897387

GAN的基本原理、应用和走向

https://mp.weixin.qq.com/s/YUMIL-f019vKpQ84mKS-8g

这篇TensorFlow实例教程文章告诉你GANs为何引爆机器学习？

https://zhuanlan.zhihu.com/p/27012520

从头开始GAN

https://mp.weixin.qq.com/s/uyn41vKKoptXPZXBP2vVDQ

生成对抗网络（GAN）之MNIST数据生成

http://mp.weixin.qq.com/s/21CN4hAA6p7ZjWsO1sT2rA

一文看懂生成式对抗网络GANs：介绍指南及前景展望

https://mp.weixin.qq.com/s/Lll9e5bCVwxdD0-Q2wamKg

一文详解生成对抗网络(GAN)的原理

https://mp.weixin.qq.com/s/Qso0pv0NjtNrYhZR-sV2xg

通俗了解对抗生成网络(GAN)核心思想

https://mp.weixin.qq.com/s/YLys6L9WT7eCC-xGr1j0Iw

带多分类判别器的GAN模型

https://mp.weixin.qq.com/s/lqQeCpLQVqSdJPWx0oxs2g

例解生成对抗网络

https://mp.weixin.qq.com/s/LAS0KgPiVekGdQXbqlw1cQ

深度学习的三大生成模型：VAE、GAN、GAN的变种

https://mp.weixin.qq.com/s/mPtv1fQd0NBgdY2b_ALNTQ

机器之心GitHub项目：GAN完整理论推导与实现，Perfect！

https://mp.weixin.qq.com/s/uUSq3irEIcBM35JCYGDPfw

生成对抗网络综述：从架构到训练技巧，看这篇论文就够了

https://mp.weixin.qq.com/s/d_W0O7LNqlBuZV87Ou9uqw

训练GAN的16个技巧

https://mp.weixin.qq.com/s/uJlgx9Bq-XI49l8wwmdIsw

用GAN让晴天下大雨，小猫变狮子，黑夜转白天

https://mp.weixin.qq.com/s/hjsFBVE3_IiKTZSesa44ug

GAN系列学习(1)——前生今世

https://mp.weixin.qq.com/s/JRyQ5vp_zDwcG3X15e32Gw

GAN系列学习(2)——前生今世

https://mp.weixin.qq.com/s/FL63vEAhp8mElI5RFxnbSQ

GAN开山之作及最新综述

https://mp.weixin.qq.com/s/A66WeHH77IOCv61RHiDE0w

生成式对抗网络（GAN）如何快速理解？这里有一篇最直观的解读

https://mp.weixin.qq.com/s/wW8kTQ7eQeCJsHC9ju8VLA

GAN_keras版

# GAN进阶

## Structured Learning

机器学习模型所预测的对象，不仅有值（例如线性回归模型），或者类别（例如逻辑回归模型），也可以是一个复杂的结构，例如Sequence、List、Tree、Image、Bounding Box等。

输出结果是复杂结构的ML，通常被称作Structured Learning。

Structured Learning有以下特点：

1.在分类任务中，每一个类别都有一定的样例Sample，但是在结构化预测中，如果把每一个output（例如一个sequence）当做一个类别来看的话，输出空间就非常大了，因为测试数据的输出很有可能都是训练数据没有见过的（毕竟完全相同的sequence会比较少）。

2.模型需要有planning的能力，以组合各种有依赖的component，从而达到全局最优。

参考：

https://www.cnblogs.com/bluemapleman/p/9277175.html

结构化学习（Structured Learning）

## 传统GAN的局限

**1.没有用户控制（user control）能力。**

在传统的GAN里，输入一个随机噪声，就会输出一幅随机图像。

但用户是有想法的，我们想输出的图像是我们想要的那种图像，和我们的输入是对应的、有关联的。比如输入一只喵的草图，输出同一形态的喵的真实图片。

**2. 低分辨率（Low resolution）和低质量（Low quality）问题。**

## GAN的发展

最早的GAN出现在2014年6月，但直到2015年底，也只有5个变种，发展并不迅速。

2016年，GAN开始发力，年底时已有52个变种。2017年6月底，更达到142个变种。

参考：

https://github.com/hindupuravinash/the-gan-zoo

GAN的各种变种

GAN的变种（或者说改进）主要分为两大类：

**1.修改Loss。**这一类的典型就是前述的WGAN。Sebastian Nowozin提出的f-GAN，对这一类改进进行了总结。

参见：

https://mp.weixin.qq.com/s/f93aCYrxlBFhRn0bgPDiTg

微软剑桥研究院153页最新GAN教程

>Sebastian Nowozin，微软剑桥研究院首席研究员。

**2.修改网络结构。**

![](/images/article/GAN_structure.png)

上图的源地址：

https://github.com/hwalsuklee/tensorflow-generative-model-collections

![](/images/img2/GAN.jpg)

![](/images/img2/GAN_2.jpg)

《Generating Reasonable and Diversified Story Ending Using Sequence to Sequence Model with Adversarial Training》，这篇论文提出的Seq2Seq+RL+GAN的组合模型，也算是让我开眼界了。

![](/images/img2/Seq2Seq_RL_GAN.png)

## 参考

https://machinelearningmindset.com/generative-adversarial-networks-roadmap/

生成对抗网络GANs学习路线

https://zhuanlan.zhihu.com/p/58812258

GAN万字长文综述

https://mp.weixin.qq.com/s/SBYtetkfi-DboM5jFTXVIQ

生成式对抗网络GAN最新进展综述

https://mp.weixin.qq.com/s/gH6b5zgvWArOSfKBSIG1Ww

必读！生成对抗网络GAN论文TOP 10

https://zhuanlan.zhihu.com/p/34016536

历史最全GAN网络及其各种变体整理

https://mp.weixin.qq.com/s/rE_RYklz8G_Etg5Gstlhew

十款神奇的GAN，总有一个适合你！

https://mp.weixin.qq.com/s/N7YU-YeXiVX7gSB-mzYgnw

生成式对抗网络GAN的研究进展与展望

https://mp.weixin.qq.com/s/IjlIT-3FVY7IfYzNDtkkgg

谷歌大脑发布GAN全景图：看百家争鸣的生成对抗网络

https://mp.weixin.qq.com/s/Y4Ags-yupq__gQZmparhsg

COLING 2018⽤对抗增强的端到端模型⽣成合理且多样的故事结尾

https://mp.weixin.qq.com/s/df51nYaA-uz7vd4WbBuE8g

GAN货：生成对抗网络知识资料全集

https://mp.weixin.qq.com/s/QRmy8f88eJcdp1xCxCI8bg

历数GAN的5大基本结构

https://mp.weixin.qq.com/s/LHCEh4BPZ_qbSKaar19nNg

十种主流GANs，我该如何选择？

https://mp.weixin.qq.com/s/RAlQVWMBYeddG2Mvu2bF4w

生成对抗网络（GANs）最新家谱：为你揭秘GANs的前世今生

https://mp.weixin.qq.com/s/NPUJ89nddF1WHfFv2nn-Hg

GANs有嘻哈：一次学完10个GANs明星模型

http://www.gwylab.com/pdf/生成模型-生成对抗网络.pdf

这篇中文综述写的很好

## GAN的理论解释

顾险峰教授对GAN提出了自己的理论解释。

>顾险峰，1989年考入清华大学计算机科学与技术系。1992年获得清华大学特等奖学金。后于美国哈佛大学获得计算机博士学位，师从国际著名微分几何大师丘成桐先生。目前为美国纽约州立大学石溪分校计算机系终身教授。

参考：

https://mp.weixin.qq.com/s/7O0AKIUVYK7HRyvdRbUVkg

虚构的对抗，GAN with the wind

https://mp.weixin.qq.com/s/trvMOTXNs7L6fSmTkZXwsA

看穿机器学习（W-GAN模型）的黑箱

https://mp.weixin.qq.com/s/thcxsBVttSIEzVNLQlAVCA

看穿机器学习的黑箱（II）

https://mp.weixin.qq.com/s/Jx0o17CwlIVcRV22PXk4wQ

看穿机器学习的黑箱（III）

https://mp.weixin.qq.com/s/ecqPzcSa75U9n4BcvnNJ_Q

GAN模式崩溃的理论解释

# GAN的评估指标

尽管可用的GAN模型非常多，但对它们的评估仍然主要是定性评估，通常需要借助人工检验生成图像的视觉保真度来进行。此类评估非常耗时，且主观性较强、具备一定误导性。鉴于定性评估的内在缺陷，恰当的定量评估指标对于GAN的发展和更好模型的设计至关重要。

论文：

《An empirical study on evaluation metrics of generative adversarial networks》

这篇论文是GAN评估指标方面的综述文章。

![](/images/img3/GAN_evaluation.png)

上图是该文给出的各种常见评估指标的体系结构图。

## Inception Score

论文：

《Improved Techniques for Training GANs》

Inception来源于Google的Inception Net，因为计算这个score需要用到Inception Net-V3。

评价一个生成模型，我们需要考验它两方面性能：

1.生成的图片是否清晰；

2.生成的图片是否多样。

生成的图片不够清晰，显然说明生成模型表现欠佳；生成的图片够清晰了，我们还要看是不是能生成足够多样的图片，有些生成模型只能生成有限的几种清晰图片，陷入了所谓mode collapse，也不是好的模型。
