---
layout: post
title:  深度强化学习（八）——AlphaStar, Dota 2, DRL参考资源（1）
category: DRL 
---

* toc
{:toc}

# StarCraft & AI（续）

https://mp.weixin.qq.com/s/x0G-LNCano7qjGdpj-fpCQ

2017年度星际争霸AI竞赛结果出炉

https://mp.weixin.qq.com/s/AndV-htPeTXlpAm1GONNtA

中科院开源星际争霸2宏观运营研究数据集MSC

https://mp.weixin.qq.com/s/I9gfoCxEYW5lSIy5QGyt6w

2018星际AI大赛（2018.11）冠军诞生！一个个机器学习算法，都输给不会学习的韩国bot

https://github.com/TeamSAIDA/SAIDA

2018.11冠军SAIDA的github

https://github.com/TorchCraft/TorchCraft

2018.11亚军CherryPi的github

https://github.com/bmnielsen/Locutus/

2018.8冠军Locutus的github

https://mp.weixin.qq.com/s/yAYF2i-Pr84RliKrJyPaUA

伯克利星际争霸II AI“撞车”腾讯，作者：我们不一样

https://mp.weixin.qq.com/s/uC8gi4kN_muRTwRL0RCZjQ

要玩转这个星际争霸II开源AI，你只需要i5+GTX1050

https://mp.weixin.qq.com/s/wyn-V4-DcjjOKziith3pXw

开源星际争霸2多智能体挑战smac

https://mp.weixin.qq.com/s/e4iv6FJAMZACEqWFmxeSFg

让AI掌握星际争霸微操：中科院提出强化学习+课程迁移学习方法

https://mp.weixin.qq.com/s/JbCIBFDRvg5qcpZ11g58dw

DeepMind提出关系性深度强化学习：在星际争霸2任务中获得最优水平

https://mp.weixin.qq.com/s/h0be7yRQMjLFi8EteTzuMQ

腾讯AI在星际2完整对战中击败“作弊级”内建Bot

https://zhuanlan.zhihu.com/p/29222384

sc2-101: 第一个rule-base的星际二agent

# AlphaStar

AlphaStar是DeepMind在解决了围棋问题之后，在RTS游戏领域的尝试。

里程碑事件：

2018.12 5:0击败TLO，5:0击败MaNa。

2019.1 表演赛不敌MaNa。

论文：

《Grandmaster level in StarCraft II using multi-agent reinforcement learning》

参考：

https://mp.weixin.qq.com/s/_Y0bCjTu9UrHfnen15htqQ

AlphaStar称霸星际争霸2！AI史诗级胜利，DeepMind再度碾压人类

https://mp.weixin.qq.com/s/axr5VFbHQmYo0shW9ilBaQ

DeepMind回应一切：AlphaStar两百年相当于人类多长时间？

https://www.zhihu.com/question/310011363

如何评价DeepMind在北京时间19年1月25日2点的《星际争霸 2》项目演示？

https://mp.weixin.qq.com/s/k0l2uoik-Z9aA9zax7AoZg

中科院自动化所深度解析：Deepmind AlphaStar如何战胜人类职业玩家

https://zhuanlan.zhihu.com/p/55781614

AlphaStar背后的机器学习原理

https://mp.weixin.qq.com/s/XljE82cJZfFOgf2KrXWSKA

DeepMind首个战胜星际2职业玩家的AI为何无敌？新视角揭秘AI里程碑

https://mp.weixin.qq.com/s/_t2vLFfIG6VYAdWDalpIXQ

说人话教AI打游戏，Facebook开源迷你版星际争霸，成果登上NeurIPS 2019

https://mp.weixin.qq.com/s/X7QQn6W2dB3y_Ljii-sJ3w

Alphastar再登Nature！星际争霸任一种族，战网狂虐99.8%人类玩家

https://zhuanlan.zhihu.com/p/102749648

基于多智能体强化学习主宰星际争霸游戏

https://zhuanlan.zhihu.com/p/92543229

AlphaStar

https://zhuanlan.zhihu.com/p/97720096

浅谈AlphaStar

## 启元世界

启元世界是国内的一家AI公司，碰巧也搞星际争霸2。研究员Flood Sung后来也加盟了该团队。

2020.6.21 启元AI 2：0 人类选手《星际争霸I/II》全国冠军黄慧明（TooDming）和中国星际最强人族选手、黄金总决赛三连冠选手李培楠（TIME）。

参考：

https://mp.weixin.qq.com/s/ev6F_prsP5nAtFKze3-zCQ

启元AI两局2：0战胜中国星际争霸冠军，仅用顶级科技巨头1%算力

https://www.zhihu.com/question/402678197

如何看待启元世界AI星际指挥官打败人族选手TIME？

# Dota 2

Dota 2的AI项目主要是OpenAI来搞，算是DRL在MOBA游戏上的应用。

里程碑事件：

2017.8 1vs1击败Dendi。2：0。稍后，OpenAI将该版本放在线上，被人找出破绽，惨遭调戏。

2018.6 OpenAI Five击败半职业玩家。

2018.7 OpenAI Five在Ti8表演赛被paiN Gaming和中国退役大神队击败。

2019.4 OpenAI Five击败Ti8冠军OG。

2019.12 OpenAI开发了更强的Rerun。Rerun对OpenAI Five的胜率为98%。

论文:

《Dota 2 with Large Scale Deep Reinforcement Learning》

参考：

https://mp.weixin.qq.com/s/rPsxvzOLuoo_IRtgH94Ecw

OpenAI自学习多智能体5v5团队战击败人类玩家

https://mp.weixin.qq.com/s/VPVzXzBYD_nYO1SjTMNGVA

Dota2团战AI击败人类最全解析：能团又能gank，AI一日人间180年

https://mp.weixin.qq.com/s/5Vg9RFvyNv6T7QkIfPm1aQ

DOTA2中打败Dendi的AI如何炼出？

https://mp.weixin.qq.com/s/e4lK3UoQq-8j1YIWKALBLg

嵌入技术在Dota2人工智能战队OpenAI Five中的应用

https://mp.weixin.qq.com/s/xsoS3tvOh78rkbI0UUIkPQ

2:0！Dota2世界冠军OG被OpenAI碾压，全程人类只推掉两座外塔

https://mp.weixin.qq.com/s/X73jL5T_uZ87F3iE-uTnpw

Dota2冠军OG如何被AI碾压？OpenAI累积三年的完整论文终于放出

# DRL参考资源

https://mp.weixin.qq.com/s/ruAAQEjPIDPWPiuPepKU6Q

Deep Reinforcement Learning: An Overview

https://mp.weixin.qq.com/s/FjmlXqlpaRVLdAbjqspOJA

这是一份你必须学习的强化学习算法清单

https://mp.weixin.qq.com/s/GISY-FvV1Vml3CNLInjgYg

Tensorflow2.0实现29种深度强化学习算法大汇总

https://mp.weixin.qq.com/s/lfXQqllfFPtuNIrQZiD-NQ

深度强化学习十大原则

https://mp.weixin.qq.com/s/I8IwPCY6-zocJKFXMr6rUg

深度强化学习的18个关键问题

https://mp.weixin.qq.com/s/_lmz0l1vP_CQ6p6DdFnHWA

谷歌大脑工程师的深度强化学习劝退文

https://zhuanlan.zhihu.com/p/39999667

强化学习路在何方？

https://mp.weixin.qq.com/s/Ns5AUGfDoTeTwnBD-pYdLA

详解强化学习当前进展及未来方向

https://mp.weixin.qq.com/s/oA98YyLqn1B22QZ5b_iDVA

IJCAI 2018：聚焦强化学习的学习效率

https://mp.weixin.qq.com/s/FtHJCXniVne2TGKfgCeS9w

Pieter Abbeel：深度强化学习加速方法

https://mp.weixin.qq.com/s/xlnwB9e1ks-4M4djnyIAyQ

解读72篇DeepMind深度强化学习论文

https://mp.weixin.qq.com/s/VYIyWRykREjOyLu4YDhLeA

61篇NIPS2019深度强化学习论文及部分解读

https://mp.weixin.qq.com/s/e6QOz-MQSn7n53EPtpw64w

DeepMind强化学习综述：她可以很快，但快从慢中来

https://zhuanlan.zhihu.com/p/72642285

基于模型的强化学习论文合集

https://zhuanlan.zhihu.com/p/77976582

强化学习并行训练论文合集

https://mp.weixin.qq.com/s/sHP03DAeZvdBxwVPuSNRPg

如何丝滑地入门神经网络？写个AI赛车游戏，只训练4代就能安全驾驶

https://mp.weixin.qq.com/s/1SZKhG1ZbD1pl-3YQD_umg

6行代码搞定基本的RL算法，速度围观Reddit高赞帖

https://mp.weixin.qq.com/s/6n5HawyR4AgH8Dq0gJMw2g

强化学习的基本概念与代码实现

https://mp.weixin.qq.com/s/RLEuaiRdq6AbTSUcYQ5O3A

深度强化学习在NLP怎么用？看清华黄民烈老师这一份120页《自然语言处理和搜索中的深度强化学习应用》讲义

https://zhuanlan.zhihu.com/p/29019246

基于策略的增强学习

https://mp.weixin.qq.com/s/OY56lJ_NFf5vVAgKfKyx2A

利用强化学习自动搜索最优化方法

https://mp.weixin.qq.com/s/nYOOwVoijl1p4V0A7yaI3w

机遇与挑战：用强化学习自动搜索优化算法

http://mp.weixin.qq.com/s/TBVVdX3erOpXNjXmhLmxOw

学“深度强化学习”，看懂DeepMind这篇文章就够了!

https://mp.weixin.qq.com/s/7BsXPQ8wC6_fHulU63ZQiQ

当强化学习遇见泛函分析

https://mp.weixin.qq.com/s/uDFsWebfLmka-zZX3Y_8kg

深度强化学习在面向任务的对话管理中的应用

https://mp.weixin.qq.com/s/FROyReDu7i5amGv-J4cmtg

“世界模型”实现，一步步让机器掌握赛车和躲避火球的技能

https://mp.weixin.qq.com/s/oyxqA_LYtze1f_YDwDZziQ

从零开始自学设计新型药物，UNC提出结构进化强化学习

https://zhuanlan.zhihu.com/p/41467058

Policy Optimization with Demonstrations

https://openreview.net/pdf?id=rJzoujRct7

深度学习之斗地主

https://mp.weixin.qq.com/s/qWuoo6cGLWLk4OKlunR-Og

滴滴KDD 2018论文详解：基于强化学习技术的智能派单模型

https://zhuanlan.zhihu.com/p/43496459

解决Sparse Reward RL任务的简单回顾

https://mp.weixin.qq.com/s/tuEhP3CDZ4PW7S66yP8AbA

如何解决稀疏奖励下的强化学习？

https://mp.weixin.qq.com/s/G99vqIYeWzgQ4kL4p77cKA

用强化学习做神经机器翻译：中山大学&MSRA填补多项空白

https://mp.weixin.qq.com/s/GUyZ0U5_JlXCI-5mO796SA

超越DQN和A3C：深度强化学习领域近期新进展概览

https://zhuanlan.zhihu.com/p/43843955

BAIR：基于人类演示&RL的夹爪训练——高效、通用、低成本

https://mp.weixin.qq.com/s/ADZlLx6gMTFU6IoBCF669g

快1万倍！伯克利提出用深度RL优化SQL查询

https://mp.weixin.qq.com/s/oZDDP59o-1qwfz8prK3nJQ

伯克利最新研究：如何用目标图像进行机器视觉强化学习？

https://mp.weixin.qq.com/s/00zHwpw2xWP2fR9sDHE2Xw

BAIR讲述如何利用深度强化学习控制灵活手

https://mp.weixin.qq.com/s/V7RESEm4xzhW8tXEjKjn1Q

层次强化学习、记忆与预测模型

https://mp.weixin.qq.com/s/aNskPERmekw9yQVb7A3GPQ

Google大脑最新研究成果：使用强化学习实现动态系统的韧性计算

https://mp.weixin.qq.com/s/pJkCOCl6o70le1WsE9p3pg

在全景视频中预测头部运动：一种深度强化学习方法

https://mp.weixin.qq.com/s/fodjmmh_jJMh4hD3m2OrLg

凭借幻想的目标进行视觉强化学习

https://mp.weixin.qq.com/s/6HVSh7_9Akmf6OE8PGNy6Q

怎样让AI完成人类搞不定的任务？OpenAI提出迭代扩增法给AI设目标

https://mp.weixin.qq.com/s/JpZimrHALjuc-H9WF8sPZg

智能体只想看电视？谷歌新型好奇心方法让智能体离开电视继续探索

https://mp.weixin.qq.com/s/dic_ssebe32L30pAUxlP6w

谷歌AI-强化学习中的好奇和拖延

https://mp.weixin.qq.com/s/tieGV_tDWkVVW2YFes4AqA

学习何时做分类决策，深度好奇提出强化学习模型Jumper

https://mp.weixin.qq.com/s/THgo4YzhUN2PUkyI5sSnpw

开源啦：连DeepMind也捉急的游戏，OpenAI给你攻破第一关的高分算法

https://mp.weixin.qq.com/s/loH6M0_U1DVrod0Drkl4eg

深度强化学习教机器人自己穿衣服！

https://mp.weixin.qq.com/s/VqPPQnH22Y-XeojNEZn3YQ

CoRL 2018最佳系统论文：如此鸡贼的机器手，确定不是人在控制？

https://mp.weixin.qq.com/s/eEQhwV1cA4nEgEBcOKDenA

将逆向课程生成用于强化学习：伯克利新研究让智能体掌握全新任务

https://mp.weixin.qq.com/s/cO1VlYGwdRBAbPs7IgvcAA

超越传统强化学习的价值分布方法
