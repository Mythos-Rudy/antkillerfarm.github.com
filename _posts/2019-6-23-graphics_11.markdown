---
layout: post
title:  图像处理理论（十一）——CV/CG参考资源
category: graphics 
---

# CV/CG参考资源

https://github.com/gzr2017/ImageProcessing100Wen

图像处理入门100题

https://zhuanlan.zhihu.com/p/32752535

立体匹配成像算法BM，SGBM，GC，SAD一览

https://mp.weixin.qq.com/s/cVTfk0xK6F_gHRnoHYUxSw

计算机视觉基本原理介绍—RANSAC

https://blog.csdn.net/wanghanthu/article/details/52777512

Tracking算法：Discriminative Correlation Filter (DCF)

https://blog.csdn.net/wanghanthu/article/details/53375393

Kernelized Correlation Filters (KCF) Tracking算法

https://mp.weixin.qq.com/s/1lLrbi_Dtyq4ixMfR4pPnA

线性卷积积分及其在图像增强和特效方面的应用

https://blog.csdn.net/iverson_49/article/details/38160081

薄板样条函数(Thin plate splines)的讨论与分析

https://mp.weixin.qq.com/s?__biz=MzI0ODcxODk5OA==&mid=2247508603&idx=2&sn=cfb091884ccc7a0ea03af38b1a629823

巧解图像处理经典难题之图像配准

https://blog.csdn.net/autocyz/article/details/48136473

相关滤波跟踪（MOSSE）

https://blog.csdn.net/qq_17783559/article/details/82254996

MOSSE原理及代码解析

https://mp.weixin.qq.com/s/XqFe9d72CepdfTSOq2gWJg

半全局匹配SGM

# 博弈论

## 囚徒困境（续）

比如，对于囚徒A来说：

当囚徒B选择坦白时，如果囚徒A选择坦白被判处3年有期徒刑；而这时如果A选择抵赖则被判处5年有期徒刑，所以这时囚徒A选择坦白要好。

当囚徒B选择抵赖时，如果囚徒A选择坦白，则当场释放；而这时如果A选择抵赖，则被判处1年有期徒刑，所以这时囚徒A选择坦白要好。

综合这两种情况，对于囚徒A不管囚徒B如何选择，选择坦白都是最好的。

在该例中（坦白，坦白）是占优策略（dominated strategy）。所谓占优策略是指如果一方在任何情况下从某种策略中得到的回报均大于从另外一种策略得到的回报，那么我们称为这种策略为占优策略。

## 纳什均衡



![](/images/img3/Nash.png)

>John Nash，1928～2015，数学家、经济学家。Princeton博士（1950），Princeton教授。主要研究博弈论、微分几何学和偏微分方程。诺贝尔经济学奖获得者（1994）。奥斯卡金像奖电影《美丽心灵》男主角原型。

## 参考

https://www.cnblogs.com/steven-yang/tag/博弈论/

一个博弈论的专栏

https://mp.weixin.qq.com/s/5o3m8RLwYkZJEhqNxOLq_A

不对称多代理博弈中的博弈理论解读

https://mp.weixin.qq.com/s/D9bRjYVJOMT0Jkh59XZ-Rg

DeepMind于Nature子刊发文提出非对称博弈的降维方法

https://mp.weixin.qq.com/s/1t6WuTQpltMtP-SRF1rT4g

当博弈论遇上机器学习：一文读懂相关理论

# 模仿学习

https://zhuanlan.zhihu.com/p/27935902

机器人学习Robot Learning之模仿学习Imitation Learning的发展

https://zhuanlan.zhihu.com/p/25688750

模仿学习（Imitation Learning）完全介绍

https://mp.weixin.qq.com/s/naq73D27vsCOUBperKto8A

从监督式到DAgger，综述论文描绘模仿学习全貌

https://mp.weixin.qq.com/s/LNNqp2KsEAljG26hY43mUw

ICML2018 模仿学习教程

https://mp.weixin.qq.com/s/f9vSgH1HQwGXBDb0UGHQyQ

深度学习进阶之无人车行为克隆

# RL与神经科学

Pavlov Model（1901）

Rescorla-Wagner Model（1972）

Thorndike’s Puzzle Box（1910）

参考：

https://zhuanlan.zhihu.com/p/24437724

学习理论之Rescorla-Wagner模型

# RL参考资源+

https://mp.weixin.qq.com/s/Fn1s9Ia8L1ckgn6iP24FhQ

如何让神经网络具有好奇心

https://mp.weixin.qq.com/s/PBf-YrkhwhPYXuiOGyahxQ

强化学习遭遇瓶颈！分层RL将成为突破的希望

https://zhuanlan.zhihu.com/p/58815288

强化学习之值函数学习

https://mp.weixin.qq.com/s/8Cqknze_iosz6Z6cqnuK5w

谷歌提出强化学习新算法SimPLe，模拟策略学习效率提高2倍

https://mp.weixin.qq.com/s/hKGS4Ek5prwTRJoMCaxQLA

强化学习Exploration漫游

https://zhuanlan.zhihu.com/p/65116688

值分布强化学习（01）

https://zhuanlan.zhihu.com/p/65364484

值分布强化学习（02）

https://zhuanlan.zhihu.com/p/62363784

强化学习之策略搜索

https://mp.weixin.qq.com/s/j9Cs5M9gyITu2u_XDkKm-g

Policy Gradient——一种不以loss来反向传播的策略梯度方法

https://mp.weixin.qq.com/s/x6gKTuYIx8y25KX-fCc5bA

蒙特卡洛梯度估计方法（MCGE）简述

# DRL参考资源+

https://mp.weixin.qq.com/s/AI3i3ZLZ-fynavbeNAMKgA

强化学习应用介绍，41页报告带你快速了解RL的最新应用价值

https://mp.weixin.qq.com/s/Dq4HsRg05bVMjvrsrxfOOQ

从这篇YouTube论文，剖析强化学习在工业级场景推荐系统中的应用

https://mp.weixin.qq.com/s/cyaQt-SO7sgG49kuUyPJbQ

旷视开源的深度强化学习绘画智能体论文解读

https://mp.weixin.qq.com/s/amXiNKJPEkAnu2m5NAERVw

Top-K Oﬀ-Policy Correction

https://mp.weixin.qq.com/s/kNtzy9-6GbsRhlL-mxksew

基于强化学习的人机对话

https://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&mid=2247494226&idx=1&sn=a96ea0ad8961ec3698301cf0c4514843

以YouTube论文学习如何在推荐场景应用强化学习

https://mp.weixin.qq.com/s/uppNSwxNrw4_8NGBQv85xw

今日头条首次改进DQN网络，解决推荐中的在线广告投放问题

https://mp.weixin.qq.com/s/Uin1gOmJEa6cvkiFJm6cHw

你当年没玩好的《愤怒的小鸟》，AI现在也犯难了

https://mp.weixin.qq.com/s/YY1FIMjDIMABdwRC5x9w4g

17种深度强化学习算法用Pytorch实现
