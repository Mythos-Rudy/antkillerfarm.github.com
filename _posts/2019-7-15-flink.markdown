---
layout: post
title:  Flink, Beam, Parquet
category: AI 
---

# Flink

Flink是一个流计算引擎。

官网：

https://flink.apache.org

参考：

https://mp.weixin.qq.com/s/WNcs0P5baLclZFBmEH3CCA

Spark比拼Flink：下一代大数据计算引擎之争，谁主沉浮？

https://mp.weixin.qq.com/s/_DLKTRI_IytYkPlMZ3eDCQ

流计算框架Flink与Storm的性能对比

https://mp.weixin.qq.com/s/NvD-NSR-aE8HTADR2LSSjA

基于Flink流处理的动态实时超大规模用户行为分析

https://mp.weixin.qq.com/s/UFzFuHFqsXl6ynKyYoOnRA

容错和高性能如何兼得: Flink创始人谈流计算核心架构演化和现状

https://mp.weixin.qq.com/s/qhiX62dALXd3owYYP9KsEQ

支持流式处理ACID事务！Flink团队开源新作Streaming Ledger

https://mp.weixin.qq.com/s/AoSDPDKbTbjH9rviioK-5Q

阿里巴巴为什么选择Apache Flink？

https://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&mid=2651749037&idx=1&sn=4a448647b3dae50779bc9ec0e9c10275

美团点评基于Flink的实时数仓建设实践

https://mp.weixin.qq.com/s/Jkd-FykUEKZZeVizRoTeJQ

一文读懂Apache Flink技术

https://mp.weixin.qq.com/s/rsJlZEP_oVG3NiFRyeS8gw

Apache Flink干货合集打包好了，速来下载

https://mp.weixin.qq.com/s/vVwBEzPyXAX1ObZ6IU8XeQ

Flink如何取代JStorm，成为字节跳动流处理唯一标准？

https://mp.weixin.qq.com/s/zeIcY_JknIo9-hR7UTxvrA

从Storm到Flink：大数据处理的开源系统及编程模型

https://mp.weixin.qq.com/s/ZkVK9S-BSoQTo09ALBI9aA

从Storm到Flink，有赞五年实时计算效率提升实践

https://mp.weixin.qq.com/s/hm_1A5Mu_6R0ygZPsspV8g

开源的Blink和Spark3.0，谁将称霸大数据领域？

https://mp.weixin.qq.com/s/DPLJA8Q2gDXLZF17FOcczw

OPPO数据中台之基石：基于Flink SQL构建实数据仓库

https://mp.weixin.qq.com/s/tbnl4a8lhamCQ-KDRYYhVA

Blink有何特别之处？菜鸟供应链场景最佳实践

https://mp.weixin.qq.com/s/zIp_14_hgRRa0sKCW4Vejw

腾讯基于Flink的实时流计算平台演进之路

https://mp.weixin.qq.com/s/15QDKqcMAuS0zXpqEDDw-Q

非Flink不可？构建实时数据集成平台，这4个因素怎能不注意！

https://mp.weixin.qq.com/s/Zz63igCUvWf1B3X4jJYTyQ

Flink与Storm协议级对比

https://mp.weixin.qq.com/s/WWCkdF1N6vXZKvw5fAq7iA

寻找数据统治力：比较Spark和Flink

https://mp.weixin.qq.com/s/BghNofoU6cPRn7XfdHR83w

日均处理万亿数据！Flink在快手的应用实践与技术演进之路

https://mp.weixin.qq.com/s/qRPquDgb2M8xptZWapajDg

Flink SQL功能解密系列——流式TopN挑战与实现

https://mp.weixin.qq.com/s/ynPmQjCCPFA_hNjvh3vS-w

Apache Flink零基础入门（一）：基础概念解析

# Beam

Apache Beam是一个数据处理的通用引擎，集成了多个处理数据框架（包括Cassandra、Elasticesarch、Hadoop-file-system、Hadoop-hbase、Jdbc、Kafka等）。Beam SDK给上层应用的开发者提供了一个统一的编程接口，开发者不需要了解底层的具体的大数据平台的开发接口是什么，直接通过Beam SDK的接口就可以开发数据处理的加工流程，不管输入是用于批处理的有界数据集，还是流式的无界数据集。

参考：

Apache Beam实战指南：大数据管道（pipeline）设计及实践

# Parquet

Parquet是由Cloudera和Twitter共同开发的一种供Hadoop使用的列式存储格式。

参考：

http://blog.csdn.net/dc_726/article/details/41777661

从NSM到Parquet：存储结构的衍化

http://blog.csdn.net/dc_726/article/details/41143175

几张图看懂列式存储

https://mp.weixin.qq.com/s/z9xpjhL5gS9w9ZpcZWee3g

大数据列式存储Parquet和ORC简介

# ORC

2013年初的时候，Hortonworks和Facebook一起开发出ORC用来替代Hive中的RCFile文件格式。

相比ORC，Parquet有两个优点：

- Parquet能够更好地支持嵌套类型，Parquet能够通过使用definition level和repetition level来标识复杂类型的层数等信息。

- Parquet的编码类型比ORC也更多一些，其支持plain、bit-packing以及浮点数等编码方式，所以Parquet在某些数据类型的压缩率上比ORC更高。

缺点：

- Parquet读取速度较慢。

参考：

https://mp.weixin.qq.com/s/aVLBXS-eiWVpvIbeE2JVIw

阿里巴巴如何打造“EB级计算平台存储引擎”？
