---
layout: post
title:  深度加速（五）——模型压缩与加速（2）
category: DL acceleration 
---

# 模型压缩与加速

https://mp.weixin.qq.com/s/IxVMMu_7UL5zFsDCcYfzYA

AutoML自动模型压缩再升级，MIT韩松团队利用强化学习全面超越手工调参

https://mp.weixin.qq.com/s/fU-AeaPz-lHlg0CBgqnpZQ

轻量化神经网络综述

https://mp.weixin.qq.com/s/BMsvhXytSy2nWIsGOSOSBQ

自动生成高效DNN，适用于边缘设备的生成合成工具FermiNets

https://mp.weixin.qq.com/s/nEMvoiqImd0RxrskIH7c9A

仅17KB、一万个权重的微型风格迁移网络！

https://mp.weixin.qq.com/s/pc8fJx5StxnX9it2AVU5NA

基于手机系统的实时目标检测

https://mp.weixin.qq.com/s/6wzmyhIvUVeAN4Xjfhb1Yw

论文解读：Channel pruning for Accelerating Very Deep Neural Networks

https://mp.weixin.qq.com/s/-X7NYTzOzljzOaQL7_jOkw

惊呆了！速度高达15000fps的人脸检测算法！

https://mp.weixin.qq.com/s/6eyEMW9dVBR5cZrHxn8iqA

腾讯AI Lab详解3大热点：模型压缩、自动机器学习及最优化算法

https://xmfbit.github.io/2018/02/24/paper-ssl-dnn/

论文-Learning Structured Sparsity in Deep Neural Networks

https://mp.weixin.qq.com/s/d6HFVbbHwkxPGdnbyVuMyQ

密歇根州立大学提出NestDNN：动态分配多任务资源的移动端深度学习框架

https://mp.weixin.qq.com/s/lUTusig94Htf7_4Z3X1fTQ

清华&伯克利ICLR论文：重新思考6大剪枝方法

https://mp.weixin.qq.com/s/g3y9mRhkFtzSuSMAornnDQ

韩松博士论文：面向深度学习的高效方法与硬件

https://mp.weixin.qq.com/s/aH1zQ7we8OE59-O9n4IXhw

应对未来物联网大潮：如何在内存有限的情况下部署深度学习？

https://mp.weixin.qq.com/s/IfvXrsUq8-cBDC4_3O5v_w

Facebook新研究优化硬件浮点运算，强化AI模型运行速率

https://mp.weixin.qq.com/s/Jsxiha_BFtWVLvO4HMwJ3Q

工业界第一手实战经验：深度学习高效网络结构设计

https://mp.weixin.qq.com/s/uXbLb5ITHOU0dZRSWNobVg

算力限制场景下的目标检测实战浅谈

https://mp.weixin.qq.com/s/DoeoPGnS88HQmxagKJWLlg

小米开源FALSR算法：快速精确轻量级的超分辨率模型

https://mp.weixin.qq.com/s/wT39oUWfrQK-dg7hGXRynQ

实时单人姿态估计，在自己手机上就能实现

https://mp.weixin.qq.com/s/GJ7JMtWiKBku7dVJWOfLOA

CNN能同时兼顾速度与准确度吗？CMU提出AdaScale

https://mp.weixin.qq.com/s/pmel2k2J159zQi87ib3q8A

如何让CNN高效地在移动端运行

https://mp.weixin.qq.com/s/m-wQRm3VpfQkEOoUAxEdoA

论文解读: Quantized Convolutional Neural Networks for Mobile Devices

https://mp.weixin.qq.com/s/w7O2JxDH2ECqPn50sLfxpg

不用重新训练，直接将现有模型转换为MobileNet

https://mp.weixin.qq.com/s/EW6jvf98ifBucVz74SfSIA

文档扫描：深度神经网络在移动端的实践

https://mp.weixin.qq.com/s/FvR6loJ8KUxm7qwclestcQ

专门为卷积神经网络设计的训练方法：RePr

https://mp.weixin.qq.com/s/67GSnZnJySFrCESvmwhO9A

论文解读Channel pruning for Accelerating Very Deep Neural Networks

https://mp.weixin.qq.com/s/Lkxc_9sbRY157sMWaD5c7g

视频分割在移动端的算法进展综述

https://mp.weixin.qq.com/s/F0ykoKv027ycinsAZZjbWQ

ThunderNet：国防科大、旷视提出首个在ARM上实时运行的通用目标检测算法

https://mp.weixin.qq.com/s/ie2O5BPT-QxTRhK3S0Oa0Q

剪枝需有的放矢，快手&罗切斯特大学提出基于能耗建模的模型压缩

https://mp.weixin.qq.com/s/NsvjADgQZrYkUGNN6fzXVg

驭势科技推出“东风网络”：如何找到速度-精度的最优解？

https://mp.weixin.qq.com/s/HzgRHtVwdmW6_m7OJwK-ew

SysML 2019论文解读：Accurate and Efficient 2-Bit Quantized Neural Netowrks

https://mp.weixin.qq.com/s/5NM9M1oY8bwsEqdBRVYpMg

网络规模更小、速度更快，这是谷歌提出的MorphNet

https://mp.weixin.qq.com/s/SC3ebx-C4N4H8B_R6K09cg

分段的人脸检测在移动端的应用

https://mp.weixin.qq.com/s/_C5AvD3YmRH2dmBjbEZFrQ

神经网络子网络压缩10倍，精确度保持不变

https://zhuanlan.zhihu.com/p/65348860

南邮提出实时语义分割的轻量级网络：LEDNET

https://zhuanlan.zhihu.com/p/67272163

百度提出关于网络压缩和加速的新剪枝算法

https://mp.weixin.qq.com/s/on1YdDexq5ICZL70mvikyw

谷歌大脑提出EfficientNet平衡模型扩展三个维度，取得精度-效率的最大化！

https://mp.weixin.qq.com/s/tCdG9gvpav1SvEzyAyBZXA

谷歌EfficientNet缩放模型，PyTorch实现出炉，登上GitHub热榜

https://mp.weixin.qq.com/s/jHv3Amti1YZq51Df2mNFtg

network sliming:加快模型速度同时不损失精度

https://mp.weixin.qq.com/s/8jyQ_7DYn7lHMcAWokKbcA

超Mask RCNN速度4倍，仅在单个GPU训练的实时实例分割算法

https://mp.weixin.qq.com/s/TC_Ju2vuKDP6d538v2F8CQ

剪枝需有的放矢，快手&罗切斯特大学提出基于能耗建模的模型压缩

https://mp.weixin.qq.com/s/UkqwPBYgYQuIB9_jGMt2QQ

Rocket Training: 一种提升轻量网络性能的训练方法

https://mp.weixin.qq.com/s/xCzS7sYMFmk5K4ClB1I2YQ

Uber提出SBNet：利用激活的稀疏性加速卷积网络

https://mp.weixin.qq.com/s/6Wj0Y4y30BVA75WrU4oZbQ

SBNet: 提高自动驾驶系统的感知效率

https://mp.weixin.qq.com/s/HXxnhMjAchxKSidu45kOeg

网络压缩最新进展：2019年最新文章概览

https://mp.weixin.qq.com/s/Bl7-hGIxZMsHxscqb7DnMA

200～1000+fps！谷歌公布亚毫秒级人脸检测算法BlazeFace，面向移动GPU

https://mp.weixin.qq.com/s/l2_N-PXjDMCqSRwYxU4BEA

模型加速概述与模型裁剪算法技术解析

https://mp.weixin.qq.com/s/af-z73asc-PmpEsI_yEulA

北邮提出新AI模型压缩算法，显著降低计算复杂度

https://mp.weixin.qq.com/s/AOI2LUjiKPUJFE0D7zX0Hw

谷歌新研究：基于数据共享的神经网络快速训练方法

https://mp.weixin.qq.com/s/m9I5TM9uJcgZvMusO667OA

5MB的神经网络也高效，Facebook新压缩算法造福嵌入式设备

https://mp.weixin.qq.com/s/FFs0-ROvbXSAIOspW_rMbw

超越MobileNetV3！谷歌大脑提出MixNet轻量级网络

https://mp.weixin.qq.com/s/nys9R6xCJXt0vG06gnQzFQ

模型剪枝，不可忽视的推断效率提升方法

https://mp.weixin.qq.com/s/EuT-4_eEtIVKh6QdLDbohg

解读小米MoGA：超过MobileNetV3的移动端GPU敏感型搜索
