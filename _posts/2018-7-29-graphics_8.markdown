---
layout: post
title:  图像处理理论（八）——目标跟踪, Meanshift
category: graphics 
---

# Viola-Jones（续）

## Integral image

Integral image一种计算差分数据的快速方法。

![](/images/img2/integral_image_a.png)

上图左侧是图像的像素值，右侧是相应的积分图。

![](/images/img2/integral_image_b.png)

由$$46 – 22 – 20 + 10 = 14$$，我们可以很快计算出左侧蓝色区域的像素值之和。

参考：

http://www.mathworks.com/help/vision/ref/integralimage.html

Integral image

## Cascade分类器

Cascade分类器，简单来说，就是先将几个通过Adaboost方法得到的强分类器进行排序，排序原则是简单的放在前边。因为通常来说人脸只占一小部分，所以可以很放心地在前几层分类器就拒绝掉大部分非人脸区域。只要前一级拒绝了，就不在进入下一级分类器，这可以大大提高速度。其本质是一颗退化决策树。

## 参考

https://www.jianshu.com/p/024ad859c8de

人脸检测的Viola-Jones方法

http://c.blog.sina.com.cn/profile.php?blogid=ab0aa22c890006v0

从Viola&Jones的人脸检测说起

http://www.cnblogs.com/hrlnw/archive/2013/10/23/3374707.html

Viola Jones Face Detector

# 目标跟踪

## 概述

目标跟踪（object tracking）就是在连续的视频序列中，建立所要跟踪物体的位置关系，得到物体完整的运动轨迹。

目标跟踪分为单目标跟踪和多目标跟踪。本文如无特别指出，均指单目标跟踪。

通常的做法是：

1.在第1帧给一个bbox框住需要跟踪的物体。

2.在不借助重检测（re-detection）的情况下，尽可能长时间的跟住物体。

3.不能使用依赖外部特征的姿态估计（pose estimation）。

当然这是针对目标跟踪算法的要求，至于实际产品中，对象的重检测以及依赖外部特征的姿态估计都是必不可少的。

比如，自动驾驶领域的车辆跟踪，一般都会针对车辆的运动特点建立模型，以辅助目标跟踪。

## TB50 & TB100

这个领域最著名的数据集是吴毅提出的OTB50 & OTB100，50和100分别代表视频数量。有的论文也把它们称作OTB-2013和OTB-2015。

>吴毅，中国科学院自动化研究所博士（2009年）。南京审计大学副教授。

官网：

http://cvlab.hanyang.ac.kr/tracker_benchmark/

论文：

《Online object tracking: A benchmark》

《Object tracking benchmark》

上面的论文在TB数据集上比较了包括2012年及之前的29个顶尖的tracker，基本解决了统一标准的问题，因此也成为了目标跟踪领域的权威数据集。

《Object tracking: A survey》

这篇论文总结了2006年以前的目标跟踪算法。

## VOT

VOT竞赛数据集是另一个常用数据集。官网：

http://votchallenge.net/challenges.html

OTB包括25%的灰度序列，但VOT都是彩色序列，这也是造成很多颜色特征算法性能差异的原因。

## 目标跟踪的难点

![](/images/article/tracker_hard.png)

![](/images/article/tracker_hard_2.png)

## 目标跟踪算法的分类

![](/images/img2/object_tracking.png)

上图是目标跟踪算法的分类，下表是具体分类和代表算法。

![](/images/img2/object_tracking_2.png)

**点跟踪**：在连续帧中检测到的目标被表达为点。这种方法需要引入其它方法来进行目标检测。

**核跟踪**：关联与目标的形状和外观表达。核函数可以是关联与一个直方图的矩形或椭圆模板。目标通过在连续帧中计算核的运动来跟踪。运动可以是参数形式的平移、旋转或仿射等。

**轮廓跟踪**：由在每帧中估计目标区域进行跟踪。轮廓跟踪方法用到的信息可以是外观密度和形状模型。给定目标模型，轮廓由形状匹配或轮廓推导得到。这些方法都可以视作时域上的目标分割。

按照是否依赖先验知识可分为两类：

1.不依赖于先验知识，直接从图像序列中检测到运动目标，并进行目标识别，最终跟踪感兴趣的运动目标；

2.依赖于目标的先验知识，首先为运动目标建模，然后在图像序列中实时找到相匹配的运动目标。

按照摄像机是否固定，可分为：

1.静态背景。

2.运动场。摄像机的运动形式可以分为两种：a)摄像机的支架固定，但摄像机可以偏转、俯仰以及缩放; b)将摄像机装在某个移动的载体上。

经典的目标跟踪算法主要有：meanshift、camshift、Kalman filter、particle filter、Optical flow、TLD、KCF、Struck等。

参考：

https://blog.csdn.net/app_12062011/article/details/48436959

目标跟踪算法的分类（一）

https://blog.csdn.net/app_12062011/article/details/51760256

目标跟踪算法的分类（二）

https://blog.csdn.net/app_12062011/article/details/52277537

目标跟踪算法的分类（三）

## 参考

https://www.zhihu.com/question/26493945

计算机视觉中，目前有哪些经典的目标跟踪算法？

https://mp.weixin.qq.com/s/Wz-loMz1oOlxtm10gazQRg

目标检测（Object Detection）和目标跟踪（Object Tracking）的区别

https://mp.weixin.qq.com/s/XJ5uVzYULWHLRjhb5iE8Qg

一文读懂图像定位及跟踪技术

# Meanshift

## Meanshift聚类

Meanshift（均值漂移）首先是个聚类算法，然后才应用到目标跟踪领域。它是Keinosuke Fukunaga和Larry D. Hostetler于1975年发明的。

>Keinosuke Fukunaga，日本裔美国科学家，普渡大学教授。著有《Introduction to Statistical Pattern Recognition》一书。

我们首先来定义一下Mean Shift向量。

对于给定的d维空间$$R^d$$中的n个样本点$$x_i, i=1,\cdots , n$$，则对于x点，其Mean Shift向量的基本形式为：

$$M_h\left ( x \right )=\frac{1}{k}\sum_{x_i\in S_h}\left ( x_i-x \right )$$

其中，$$S_h$$指的是一个半径为h的高维球区域，如上图中的蓝色的圆形区域。$$S_h$$的定义为：

$$S_h\left ( x \right )=\left ( y\mid \left ( y-x \right )\left ( y-x \right )^T\leqslant h^2 \right )$$

从物理的角度来看，由于$$\frac{1}{k}\sum_{x_i\in S_h}x_i$$实际上是$$S_h$$的质量中心，因此$$M_h\left ( x \right )$$实际上就是从x指向质心的向量，也被叫做归一化的概率密度梯度。所以，Meanshift聚类实际上是一种密度聚类。

下面来看一下Meanshift算法的具体步骤。

![](/images/img2/meanshift.png)

首先，在空间中任选一点x（上图中蓝色的圈），以x为圆心，h为半径做一个高维球（上图中蓝色的圆）。计算得到质心（上图中黄色的圈）。移动x到质心，并重复之前的步骤。最终x会收敛到最密集区域的质心。

基本的Mean Shift形式存在一个问题：在$$S_h$$的区域内，每一个点对x的贡献是一样的。而实际上，这种贡献与x到每一个点之间的距离是相关的。同时，对于每一个样本，其重要程度也是不一样的。

到了1995年，Yizong Cheng（现为University of Cincinnati副教授）对基本的Mean Shift算法在以下两个方面做了推广。

首先，定义了一族核函数,使得随着样本与被偏移点的距离不同,其偏移量对均值偏移向量的贡献也不同。

其次，还设定了一个权重系数,使得不同的样本点重要性不一样,这大大扩大了Mean Shift的适用范围。

基于以上的考虑，可对基本的Mean Shift向量形式中增加核函数和样本权重，得到如下的改进的Mean Shift向量形式：

$$M_h\left ( x \right )=\frac{\sum_{i=1}^{n}G_H\left ( x_i-x \right )w\left ( x_i \right )\left ( x_i-x \right )}{\sum_{i=1}^{n}G_H\left ( x_i-x \right )w\left ( x_i \right )}$$

其中：

$$G_H\left ( x_i-x \right )=\left | H \right |^{-\frac{1}{2}}G\left ( H^{-\frac{1}{2}}\left ( x_i-x \right ) \right )$$

G(x)是一个单位的核函数。H是一个正定的对称d×d矩阵，称为带宽矩阵，其是一个对角阵。$$w\left ( x_i \right )\geqslant 0$$是每一个样本的权重。对角阵H的形式为：

$$H=\begin{pmatrix}
h_1^2 & 0 & \cdots & 0\\ 
0 & h_2^2 & \cdots & 0\\ 
\vdots  & \vdots  &  & \vdots \\ 
0 & 0 & \cdots & h_d^2
\end{pmatrix}_{d\times d}$$

因此，上述Mean Shift向量也可以改写成：

$$M_h\left ( x \right )=\frac{\sum_{i=1}^{n}G\left ( \frac{x_i-x}{h_i} \right )w\left ( x_i \right )\left ( x_i-x \right )}{\sum_{i=1}^{n}G\left ( \frac{x_i-x}{h_i} \right )w\left ( x_i \right )}$$

这里的核函数可以是Uniform核，也可以是Gaussian核。

参考：

https://wenku.baidu.com/view/5862334827d3240c8447ef40.html

meanshift算法简介

http://www.cnblogs.com/liqizhou/archive/2012/05/12/2497220.html

Meanshift，聚类算法

https://wenku.baidu.com/view/0d9eb876a417866fb84a8eb2.html

mean-shift算法概述

http://www.cnblogs.com/cfantaisie/archive/2011/06/10/2077188.html

meanshift聚类

https://blog.csdn.net/google19890102/article/details/51030884

Mean Shift聚类算法

## 反向投影图

在继续介绍Meanshift之前，我们先引入反向投影图的概念。

首先，我们对图像的像素值按照某种特征进行直方图统计，得到一组bin值。

然后，计算位置x上的bin值，并用该bin值替换原来的像素值，就得到了反向投影图。

参考：

https://blog.csdn.net/poiiy333/article/details/9051409

反向投影图

http://www.cnblogs.com/zsb517/archive/2012/06/20/2556508.html

opencv直方图反向投影

## Meanshift与目标跟踪

由于RGB对光照的变化比较敏感，而这种敏感对目标跟踪而言是不利的。因此，通常我们要将图像转换到HSV颜色空间。

首先，统计**目标box**区域内H（色调）分量的直方图，并对其进行归一化，使得该直方图成为概率直方图。这一步相当于统计目标的颜色特征。

然后，使用统计得到的概率直方图，将**全图**转换为反向投影图，并应用Meanshift算法。由于前后两帧中目标通常不会隔的太远，原目标中心可能仍在目标范围内。因此，目标中心会向反向投影图中概率大的地方移动，从而达到了目标跟踪的效果。

总结：用meanshift进行跟踪最重要的一点是输入图像的把握，也就是要让它的迭代能越来越迭代到目标上。这种图像也不一定就是反向投影图，只要是一幅反映当前图像中每个像素点含有目标概率的图就可以了。反向投影图恰好就是这样的一幅图而已。
