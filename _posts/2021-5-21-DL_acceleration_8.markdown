---
layout: post
title:  深度加速（八）——模型压缩与加速进阶（2）, 硬盘
category: DL acceleration 
---

* toc
{:toc}

# 模型压缩与加速进阶

https://mp.weixin.qq.com/s/H6OTkpdIgSdugDrEMBLybw

超越MobileNetV3的轻量级网络（GhostNet）

https://mp.weixin.qq.com/s/Vh5Y9Ru_hbN0CzM7_xGg6A

超越GhostNet！吊打MobileNetV3！MicroNet通过极低FLOPs实现图像识别

https://mp.weixin.qq.com/s/DLNyb-GtzmSYuXcn6VQz4Q

高效轻量级深度模型的研究和实践

https://mp.weixin.qq.com/s/3SWtxtV9b0dFpvqfTNlqIg

Slimmable Neural Networks

https://mp.weixin.qq.com/s/lc7IoOV6S2Uz5xi7cPQUqg

基于元学习和AutoML的模型压缩新方法

https://zhuanlan.zhihu.com/p/64400678

轻量卷积神经网络的设计

https://mp.weixin.qq.com/s/pJk84bNzRn7LZZfQfSjs5A

VarGFaceNet：地平线提出轻量级、有效可变组卷积的人脸识别网络

https://mp.weixin.qq.com/s/cYimAphdyFO_XqKfT2Hbeg

如何使用强化学习进行模型剪枝

https://mp.weixin.qq.com/s/SgELZgoHzIvbg2-jzJw6Tw

港科大、清华与旷视提出基于元学习的自动化神经网络通道剪枝网络

https://mp.weixin.qq.com/s/q5-91AAKwBiYzTMmqadEcg

RefineDetLite：腾讯提出轻量级高精度目标检测网络

https://mp.weixin.qq.com/s/Vh5Y9Ru_hbN0CzM7_xGg6A

MicroNet通过极低FLOPs实现图像识别

https://mp.weixin.qq.com/s/Ck_GDv1Xo-YMZcu-00gTOA

中星微夺冠国际人工智能算法竞赛，目标检测一步法精度速度双赢

https://mp.weixin.qq.com/s/qWJarPrjOrwxSX77xQ9rCw

面向卷积神经网络的卷积核冗余消除策略

https://mp.weixin.qq.com/s/4aVY9vUBX_Bxht953r00sA

在Keras中利用TensorNetwork加速神经网络

https://mp.weixin.qq.com/s/5NM9M1oY8bwsEqdBRVYpMg

网络规模更小、速度更快，这是谷歌提出的MorphNet

https://mp.weixin.qq.com/s/SC3ebx-C4N4H8B_R6K09cg

分段的人脸检测在移动端的应用

https://mp.weixin.qq.com/s/_C5AvD3YmRH2dmBjbEZFrQ

神经网络子网络压缩10倍，精确度保持不变

https://zhuanlan.zhihu.com/p/65348860

南邮提出实时语义分割的轻量级网络：LEDNET

https://zhuanlan.zhihu.com/p/67272163

百度提出关于网络压缩和加速的新剪枝算法

https://mp.weixin.qq.com/s/jHv3Amti1YZq51Df2mNFtg

network sliming:加快模型速度同时不损失精度

https://mp.weixin.qq.com/s/gwXXkWumGWy24oWuZKSyAQ

MIT韩松组推出升级版AutoML方法，一个网络适配所有硬件

https://zhuanlan.zhihu.com/p/76909380

轻量型网络：MoGA简介

https://mp.weixin.qq.com/s/kgl7mz4bK7SywkbViY_qhQ

利用LSTM思想来做CNN剪枝，北大提出Gate Decorator

https://mp.weixin.qq.com/s/3_famaAmkAN-4xVEupSXSA

华为、北大等首创GAN剪枝算法，线上加速3倍以上

https://mp.weixin.qq.com/s/KuZ-mZKt7bTWhzygK1lmSg

加速目标检测

https://zhuanlan.zhihu.com/p/261146248

原生模型上的战斗

https://mp.weixin.qq.com/s/jqRBrs9Y_-3qvemL0RTflA

支付宝如何优化移动端深度学习引擎？

https://mp.weixin.qq.com/s/NJzGR-tY_WWeccbdshHckA

基于交错组卷积的高效深度神经网络

https://mp.weixin.qq.com/s/6eyEMW9dVBR5cZrHxn8iqA

腾讯AI Lab详解3大热点：模型压缩、自动机器学习及最优化算法

https://xmfbit.github.io/2018/02/24/paper-ssl-dnn/

论文-Learning Structured Sparsity in Deep Neural Networks

https://mp.weixin.qq.com/s/d6HFVbbHwkxPGdnbyVuMyQ

密歇根州立大学提出NestDNN：动态分配多任务资源的移动端深度学习框架

https://mp.weixin.qq.com/s/lUTusig94Htf7_4Z3X1fTQ

清华&伯克利ICLR论文：重新思考6大剪枝方法

https://mp.weixin.qq.com/s/g3y9mRhkFtzSuSMAornnDQ

韩松博士论文：面向深度学习的高效方法与硬件

https://mp.weixin.qq.com/s/aH1zQ7we8OE59-O9n4IXhw

应对未来物联网大潮：如何在内存有限的情况下部署深度学习？

https://mp.weixin.qq.com/s/GJ7JMtWiKBku7dVJWOfLOA

CNN能同时兼顾速度与准确度吗？CMU提出AdaScale

https://mp.weixin.qq.com/s/pmel2k2J159zQi87ib3q8A

如何让CNN高效地在移动端运行

https://mp.weixin.qq.com/s/m-wQRm3VpfQkEOoUAxEdoA

论文解读: Quantized Convolutional Neural Networks for Mobile Devices

https://mp.weixin.qq.com/s/w7O2JxDH2ECqPn50sLfxpg

不用重新训练，直接将现有模型转换为MobileNet

https://mp.weixin.qq.com/s/EW6jvf98ifBucVz74SfSIA

文档扫描：深度神经网络在移动端的实践

https://mp.weixin.qq.com/s/3oL0Bso3mwbsfaG8X5-xoA

英特尔提出新型压缩技术DeepThin，适合移动端设备深度神经网络

https://mp.weixin.qq.com/s/LGCGYSoMpPfojEi2WcmjnQ

TinyML：下一轮人工智能革命

https://mp.weixin.qq.com/s/B-OJ_oW_uJufqIfIZSA7Ww

专家从7个维度全面评测轻量级网络

https://mp.weixin.qq.com/s/UDUOIIyGJtXHdc3xcyfOIg

万字综述：用于深度神经网络加速的Shift操作

https://zhuanlan.zhihu.com/p/301162618

深度学习模型压缩与加速

https://mp.weixin.qq.com/s/Lv1JuwNohAsIAB1SKT7Lkg

深度卷积网络的剪枝和加速

https://mp.weixin.qq.com/s/VEnX3YKQ02mRg2qbqMbXcg

轻量级网络综述—主干网络篇

https://mp.weixin.qq.com/s/s9Bp3s-Ep3QPDpo1mmwgWw

模型压缩系列一：模型替换

https://mp.weixin.qq.com/s/CNaQbeLbN4J3CsUIMaezFw

模型压缩系列二：模型蒸馏

https://mp.weixin.qq.com/s/WVwB-ldc8Yoin6I_m6RT5g

CNN轻量化模型及其设计原则综述

https://mp.weixin.qq.com/s/IfvXrsUq8-cBDC4_3O5v_w

Facebook新研究优化硬件浮点运算，强化AI模型运行速率

https://mp.weixin.qq.com/s/Jsxiha_BFtWVLvO4HMwJ3Q

工业界第一手实战经验：深度学习高效网络结构设计

https://mp.weixin.qq.com/s/uXbLb5ITHOU0dZRSWNobVg

算力限制场景下的目标检测实战浅谈

https://mp.weixin.qq.com/s/DoeoPGnS88HQmxagKJWLlg

小米开源FALSR算法：快速精确轻量级的超分辨率模型

https://mp.weixin.qq.com/s/wT39oUWfrQK-dg7hGXRynQ

实时单人姿态估计，在自己手机上就能实现

https://mp.weixin.qq.com/s/RVsXUnAJ2f0Cby7BPaWifA

人物属性模型移动端实验记录

https://mp.weixin.qq.com/s/yCcK6UJqm850HON7xU3R6g

模型压缩重要方向-动态模型，如何对其长期深入

https://zhuanlan.zhihu.com/p/93020471

轻量型网络：IdleBlock

https://mp.weixin.qq.com/s/AjuTXFmxHYdUUqodSpP_4w

10倍加速！爱奇艺超分辨模型加速实践

# Tile

矩阵乘法的实现（matmul）是一个简易的三层for循环。这样的循环其实对于缓存是不友好的。

为解决缓存使用的问题，可以改变matmul的计算顺序，使得data矩阵的一部分数据可以长久地驻扎在缓存中，避免重复从内存读取这部分数据，这种技术被称为Blocking（或tiling）。它将矩阵划分几块，然后在小块中进行矩阵乘法，最后将数据汇集到输出矩阵中。

# 硬盘

早期，磁带和硬盘驱动器的面密度相似。但由于的市场规模和硬盘销售收入的增加，为更大规模的研发工作提供了资金，这使得他们的制造商能够更积极地扩大存储密度。因此，大容量硬盘驱动器的当前面密度约为最新磁带驱动器的100倍。

相比之下，磁带存储设备目前的区域密度远低于超顺磁极限。因此，磁带的摩尔定律可以持续十年或更长时间，而不会遇到基础物理学方面的障碍。

参考：

https://mp.weixin.qq.com/s/Fzu5YmWYxEohDJjmcGGjhQ

为什么说，数据存储的未来属于磁带

---

随着硬件设备存储介质的改变和性能不断的提升，存储设备处理IO的能力越来越快，传统的旋转设备HDD单个IO需要几毫秒到十几毫秒不等，而如今的高性能的NVMe SSD已经降低到了微秒级别。

因此也有了一些专门针对SSD硬盘的存储软件框架。

https://mp.weixin.qq.com/s/d8aoAFi_lpFoZZCZsPij_g

SPDK概览

---

千年盘，是美国Millenniata的公司将推出新型磁盘存储技术，这种光盘新技术可以将数据在室温下存储1000年，使用这种技术的特殊光盘叫Millennial Disc。

---

https://zhuanlan.zhihu.com/p/34858149

128G的固态硬盘为什么有的标120G，有的标100G？固态硬盘容量背后的秘密

https://zhuanlan.zhihu.com/p/38847308

为什么硬盘转速是5400或者7200这么奇怪的数字？7200转的硬盘一定比5400快吗？

https://www.zhihu.com/answer/470917953

Windows等操作系统是如何做到复制几G文件不出错的？

https://zhuanlan.zhihu.com/p/53547723

一篇文章告诉你SLC、MLC、TLC和QLC究竟有啥区别?

https://zhuanlan.zhihu.com/p/92712620

SLC、MLC、TLC、QLC究竟有什么不同

https://zhuanlan.zhihu.com/p/71267390

固态硬盘和u盘的区别

https://mp.weixin.qq.com/s/7athL-OWrFSxMwxqvR73TA

为了让你的硬盘资源能完好地传给曾曾曾孙，科学家想到了这些办法

https://mp.weixin.qq.com/s/ChAfcT5xDgExiEXytTfynw

关于存储技术的最强入门科普
