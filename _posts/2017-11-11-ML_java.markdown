---
layout: post
title:  Machine Learning之Java篇, MPI
category: AI 
---

* toc
{:toc}

# Machine Learning之Java篇

http://machinelearningmastery.com/java-machine-learning/

这篇文章包含了很多Machine Learning方面的软件和库。

## ND4J

numpy的等价物。

http://nd4j.org/

## DL4J

TensorFlow的等价物。

https://deeplearning4j.org/

参考：

https://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&mid=2247484466&idx=1&sn=9dd7d305f37f6cad8d4ac37ad17f61f8

Deeplearning4j：使用CNN进行文本分类:图文+代码

https://mp.weixin.qq.com/s/geJDbL1eVcJXDtsO_mu4-w

Deeplearning4j手把手深度学习教程系列完整版

## DJL

Deep Java Library是AWS开源的Java深度学习框架。和DL4J不同，DJL没有自己的运算层，而必须依靠TF或Pytorch进行计算。

https://github.com/awslabs/djl/

参考：

https://mp.weixin.qq.com/s/-GaxCVUOSe_2lFAeLRaIpQ

用Java训练深度学习模型，原来这么简单

## Joinery

Pandas的等价物。

https://github.com/cardillo/joinery

## Weka

Weka是一款开源的机器学习以及数据挖掘软件。主要开发者来自新西兰的the University of Waikato。

官网：

http://www.cs.waikato.ac.nz/ml/weka/

Weka不仅有GUI，而且也为开发提供了API，是单机Machine Learning的Java首选。国内的京东用的比较多。

GitHub：

https://github.com/bnjmn/weka

API Doc：

http://weka.sourceforge.net/doc.stable-3-8/

Weka除了基本库之外，还有许多扩展包：

http://weka.sourceforge.net/packageMetaData/

参考：

https://weka.wikispaces.com/Use+Weka+in+your+Java+code

如何在Java代码中使用Weka

## ELKI

ELKI是另一个数据挖掘软件，也有GUI和API。ELKI主要专注于聚类和异常检测算法。

官网：

https://elki-project.github.io/algorithms/

GitHub：

https://github.com/elki-project/elki

## smile

Statistical Machine Intelligence and Learning Engine虽然没有GUI，但却有一个类似Spark的命令行界面，以及类似Matplotlib的数据可视化接口。这是一个留美华人工程师写的统计和NLP方面的库。

官网：

https://haifengl.github.io/smile/

参考：

https://mp.weixin.qq.com/s/UZWSUUuPWcyv6yUx-woF4g

Smile实战（一）SVM

https://mp.weixin.qq.com/s/WE7afgw1VzvClKdbAaXVnA

Smile一下，轻松用Java玩转机器学习

## java-string-similarity

这个库虽然功能有限，但却针对字符处理进行了优化。比如Jaccard距离，weka没有实现，ELKI提供的是通用的集合类实现，用起来没有java-string-similarity方便。

官网：

https://github.com/tdebatty/java-string-similarity

## LDA4j

https://github.com/hankcs/LDA4j

## YTK

猿题库开源了两个Java的库：

https://github.com/yuantiku/ytk-learn

https://github.com/yuantiku/ytk-mp4j

## Apache Zeppelin

Zeppelin是一个让交互式数据分析变得可行的基于网页的开源框架。Zeppelin提供了数据分析、数据可视化等功能。

官网：

https://zeppelin.apache.org/

## 参考

https://mp.weixin.qq.com/s/WsjZERRkgnReWuDw_z5Hxw

LibRec：一个覆盖70多种算法的推荐系统开源库！

https://mp.weixin.qq.com/s/hn8Es-l1f6raJ_wj5HkqMA

LinkedIn开源Dagli，发布Java机器学习函数库

# MPI

集群可以很好解决单节点计算力不足的问题，但在集群中大规模的数据交换是很耗费时间的，因此需要一种在多节点的情况下能快速进行数据交流的标准，这就是Message passing interface(MPI)。

MPI的主流实现主要是：mpich和openmpi。

和MPI类似的技术，还有NVIDIA的NCCL，FaceBook的gloo等。

MPI官网：

http://www.mpi-forum.org/docs/

1994：MPI-1

1998：MPI-2

2012：MPI-3

因为MPI的历史比较久远，深刻影响了后来的分布式并行程序，比如TF等。所以这里简单介绍一下几个关键的术语。

gloo官网：

https://github.com/facebookincubator/gloo

## Barrier

![](/images/img4/barrier.png)

这个方法会构建一个屏障，任何进程都没法跨越屏障，直到所有的进程都到达屏障。

实现屏障的方式有很多，最简单的是令牌环（token ring）。

第一个进程到达的屏障生成一个token，然后传递给下一个到达屏障的进程。所有的进程都到达屏障之后，token被传递回第一个进程。

`MPI_Barrier`在TF中被称为`AfterAll`。

## Bcast & Scatter

![](/images/img4/broadcastvsscatter.png)

`MPI_Bcast`给每个进程发送的是同样的数据，然而`MPI_Scatter`给每个进程发送的是一个数组的一部分数据。

![](/images/img4/broadcast_tree.png)

在上图的树形算法里，能够利用的网络连接每个阶段都会比前一阶段翻番，直到所有的进程接收到数据为止。

## Gather & Allgather

![](/images/img4/gather.png)

`MPI_Gather`跟`MPI_Scatter`是相反的。

![](/images/img4/allgather.png)

`MPI_Allgather`相当于一个`MPI_Gather`操作之后跟着一个`MPI_Bcast`操作。

## Reduce & Allreduce

![](/images/img4/mpi_reduce_1.png)

数据归约包括通过函数将一组数字归约为较小的一组数字。例如，假设我们有一个数字列表[1,2,3,4,5]。用sum函数归约此数字列表将产生`sum([1、2、3、4、5]) = 15`。

![](/images/img4/mpi_allreduce_1.png)

`MPI_Allreduce`等效于先执行`MPI_Reduce`，然后执行`MPI_Bcast`。

## Alltoall

![](/images/img4/all-to-all-collective.png)

`MPI_Alltoall`的工作方式是`MPI_Scatter`和`MPI_Gather`的组合。它的用途之一就是上图所示的数据的行列转置,但它比转置要灵活的多。

## groups

以上这些操作都涉及了多个计算节点。执行同一操作的多个节点组成一个group。

group里包含了相关的节点的id，如果group为null，则该操作会在整个计算集群上执行。两个group可以进行交集、并集之类的集合运算，生成新的group。

## 总结

```cpp
ScatterGather(SrcIDRange,SrcAddr,DstIDRange,DstAddr,UnitSize,TotalSize)
When there is only one source and UnitSize = TotalSize, it is a Broadcast
When there is only one source and UnitSize != TotalSize, it is a Scatter
When there is only one destination and UnitSize = TotalSize, it is a Gather
When UnitSize = TotalSize and there are multiple sources and destinations, it is a AllGather operation
When UnitSize != TotalSize and there are multiple sources and destinations, it is a All-to-All operation
```

从上面可以看出，除了Reduce一系的操作之外，其他的都可以总结为Scatter+Gather。

Scatter也被称为One-to-all，Gather也被称为All-to-one。

## AllReduce

AllReduce有多种具体的实现方式。

Ring AllReduce：

![](/images/img4/Ring_AllReduce.jpg)

Having-Doubling AllReduce：

![](/images/img4/Having-Doubling_AllReduce.jpg)

该算法每次选择节点距离倍增的节点相互通信，每次通信量倍减（或倍增）。

该算法的优点是通信步骤较少，只有$$2 * log_2N$$次（其中N表示参与通信的节点数）通信即可完成，所以其有更低的延迟。相比之下Ring算法的通信步骤是$$2 ∗ (N−1)$$次；缺点是每一个步骤相互通信的节点均不相同，链接来回切换会带来额外开销。

ring all-reduce具有理论上最优的传输带宽，而没有考虑每次传输都包含的延迟（latency）。当数据量V比较大时，延迟项可以忽略。当V特别小，或者设备数p特别大时，带宽就变得不重要了，反而是延迟比较关键。

这也是为什么英伟达NCCL里既实现了ring all-reduce，也实现了double-tree all-reduce算法。

https://www.zhihu.com/question/57799212

ring allreduce和tree allreduce的具体区别是什么？

https://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/

Bringing HPC Techniques to Deep Learning

https://zhuanlan.zhihu.com/p/79030485

AllReduce算法的前世今生

https://mp.weixin.qq.com/s/4XMVYXnzpYZ4DrIabuTUig

Ring All-reduce: 分布式深度学习的巧妙同步

https://zhuanlan.zhihu.com/p/504957661

手把手推导Ring All-reduce的数学性质

https://developer.nvidia.com/blog/massively-scale-deep-learning-training-nccl-2-4/

Massively Scale Your Deep Learning Training with NCCL 2.4

## 其他概念

这里的有些概念并非MPI的内容，但在分布式计算中，应用的比较广，所以就放在这里了。

rank：进程号，在多进程上下文中，我们通常假定rank 0是第一个进程或者主进程，也被称为coordinator（master）。其余的进程为worker。由Rank0来协调所有Rank的进度。

node：物理节点，可以是一个容器也可以是一台机器，节点内部可以有多个GPU。

local_rank：指在一个node上进程的相对序号，local_rank在node之间相互独立。

![](/images/img4/rank.png)

rank与GPU之间没有必然的对应关系，一个rank可以包含多个GPU；一个GPU也可以为多个rank服务（多进程共享GPU），只是习惯上默认一个rank对应着一个GPU。

## 参考

https://zhuanlan.zhihu.com/p/69497154

高性能计算--mpi

https://mpitutorial.com/tutorials/

MPI Tutorials

https://zhuanlan.zhihu.com/p/363710263

集体通信

https://downey.io/notes/omscs/cse6220/distributed-memory-model-mpi-collectives/

distributed memory model and mpi collectives

https://blog.csdn.net/q19149/article/details/102594031

集合通信函数图解

https://zhuanlan.zhihu.com/p/465967735

分布式训练硬核技术——通讯原语

https://zhuanlan.zhihu.com/p/276122469

分布式训练常用技术简介

https://zhuanlan.zhihu.com/p/425830285

最理想的点到点通信库究竟是怎样的？
