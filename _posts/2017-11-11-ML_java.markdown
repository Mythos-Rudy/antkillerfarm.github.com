---
layout: post
title:  Machine Learning之Java篇, MPI
category: AI 
---

* toc
{:toc}

# Machine Learning之Java篇

http://machinelearningmastery.com/java-machine-learning/

这篇文章包含了很多Machine Learning方面的软件和库。

## ND4J

numpy的等价物。

http://nd4j.org/

## DL4J

TensorFlow的等价物。

https://deeplearning4j.org/

参考：

https://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&mid=2247484466&idx=1&sn=9dd7d305f37f6cad8d4ac37ad17f61f8

Deeplearning4j：使用CNN进行文本分类:图文+代码

https://mp.weixin.qq.com/s/geJDbL1eVcJXDtsO_mu4-w

Deeplearning4j手把手深度学习教程系列完整版

## DJL

Deep Java Library是AWS开源的Java深度学习框架。和DL4J不同，DJL没有自己的运算层，而必须依靠TF或Pytorch进行计算。

https://github.com/awslabs/djl/

参考：

https://mp.weixin.qq.com/s/-GaxCVUOSe_2lFAeLRaIpQ

用Java训练深度学习模型，原来这么简单

## Joinery

Pandas的等价物。

https://github.com/cardillo/joinery

## Weka

Weka是一款开源的机器学习以及数据挖掘软件。主要开发者来自新西兰的the University of Waikato。

官网：

http://www.cs.waikato.ac.nz/ml/weka/

Weka不仅有GUI，而且也为开发提供了API，是单机Machine Learning的Java首选。国内的京东用的比较多。

GitHub：

https://github.com/bnjmn/weka

API Doc：

http://weka.sourceforge.net/doc.stable-3-8/

Weka除了基本库之外，还有许多扩展包：

http://weka.sourceforge.net/packageMetaData/

参考：

https://weka.wikispaces.com/Use+Weka+in+your+Java+code

如何在Java代码中使用Weka

## ELKI

ELKI是另一个数据挖掘软件，也有GUI和API。ELKI主要专注于聚类和异常检测算法。

官网：

https://elki-project.github.io/algorithms/

GitHub：

https://github.com/elki-project/elki

## smile

Statistical Machine Intelligence and Learning Engine虽然没有GUI，但却有一个类似Spark的命令行界面，以及类似Matplotlib的数据可视化接口。这是一个留美华人工程师写的统计和NLP方面的库。

官网：

https://haifengl.github.io/smile/

参考：

https://mp.weixin.qq.com/s/UZWSUUuPWcyv6yUx-woF4g

Smile实战（一）SVM

https://mp.weixin.qq.com/s/WE7afgw1VzvClKdbAaXVnA

Smile一下，轻松用Java玩转机器学习

## java-string-similarity

这个库虽然功能有限，但却针对字符处理进行了优化。比如Jaccard距离，weka没有实现，ELKI提供的是通用的集合类实现，用起来没有java-string-similarity方便。

官网：

https://github.com/tdebatty/java-string-similarity

## LDA4j

https://github.com/hankcs/LDA4j

## YTK

猿题库开源了两个Java的库：

https://github.com/yuantiku/ytk-learn

https://github.com/yuantiku/ytk-mp4j

## Apache Zeppelin

Zeppelin是一个让交互式数据分析变得可行的基于网页的开源框架。Zeppelin提供了数据分析、数据可视化等功能。

官网：

https://zeppelin.apache.org/

## 参考

https://mp.weixin.qq.com/s/WsjZERRkgnReWuDw_z5Hxw

LibRec：一个覆盖70多种算法的推荐系统开源库！

https://mp.weixin.qq.com/s/hn8Es-l1f6raJ_wj5HkqMA

LinkedIn开源Dagli，发布Java机器学习函数库

# MPI

集群可以很好解决单节点计算力不足的问题，但在集群中大规模的数据交换是很耗费时间的，因此需要一种在多节点的情况下能快速进行数据交流的标准，这就是Message passing interface(MPI)。

MPI的主流实现主要是：mpich和openmpi。

官网：

http://www.mpi-forum.org/docs/

1994：MPI-1

1998：MPI-2

2012：MPI-2

因为MPI的历史比较久远，深刻影响了后来的分布式并行程序，比如TF等。所以这里简单介绍一下几个关键的术语。

## Barrier

![](/images/img4/barrier.png)

这个方法会构建一个屏障，任何进程都没法跨越屏障，直到所有的进程都到达屏障。

实现屏障的方式有很多，最简单的是令牌环（token ring）。

第一个进程到达的屏障生成一个token，然后传递给下一个到达屏障的进程。所有的进程都到达屏障之后，token被传递回第一个进程。

`MPI_Barrier`在TF中被称为`AfterAll`。

## Bcast & Scatter

![](/images/img4/broadcastvsscatter.png)

`MPI_Bcast`给每个进程发送的是同样的数据，然而`MPI_Scatter`给每个进程发送的是一个数组的一部分数据。

![](/images/img4/broadcast_tree.png)

在上图的树形算法里，能够利用的网络连接每个阶段都会比前一阶段翻番，直到所有的进程接收到数据为止。

## Gather & Allgather

![](/images/img4/gather.png)

`MPI_Gather`跟`MPI_Scatter`是相反的。

![](/images/img4/allgather.png)

`MPI_Allgather`相当于一个`MPI_Gather`操作之后跟着一个`MPI_Bcast`操作。

## Reduce & Allreduce

![](/images/img4/mpi_reduce_1.png)

数据归约包括通过函数将一组数字归约为较小的一组数字。例如，假设我们有一个数字列表[1,2,3,4,5]。用sum函数归约此数字列表将产生`sum([1、2、3、4、5]) = 15`。

![](/images/img4/mpi_allreduce_1.png)

`MPI_Allreduce`等效于先执行`MPI_Reduce`，然后执行`MPI_Bcast`。

## Alltoall

![](/images/img4/all-to-all-collective.png)

`MPI_Alltoall`的工作方式是`MPI_Scatter`和`MPI_Gather`的组合。它的用途之一就是上图所示的数据的行列转置,但它比转置要灵活的多。

## groups

以上这些操作都涉及了多个计算节点。执行同一操作的多个节点组成一个group。

group里包含了相关的节点的id，如果group为null，则该操作会在整个计算集群上执行。两个group可以进行交集、并集之类的集合运算，生成新的group。

## 参考

https://zhuanlan.zhihu.com/p/69497154

高性能计算--mpi

https://mpitutorial.com/tutorials/

MPI Tutorials

https://zhuanlan.zhihu.com/p/363710263

集体通信

https://downey.io/notes/omscs/cse6220/distributed-memory-model-mpi-collectives/

distributed memory model and mpi collectives

https://blog.csdn.net/q19149/article/details/102594031

集合通信函数图解
