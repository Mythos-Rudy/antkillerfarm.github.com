---
layout: post
title:  深度学习（十八）——FCN, SegNet
category: DL 
---

# 无监督/半监督/自监督深度学习（续）

https://zhuanlan.zhihu.com/p/80815225

Image-Level弱监督图像语义分割汇总简析

https://mp.weixin.qq.com/s/5czWf0xpqva5pmuvJDn5AQ

Google研究院提出FixMatch，简单粗暴却极其有效的半监督学习方法，附14页PDF下载

https://zhuanlan.zhihu.com/p/108088719

SSL:Self-Supervised Learning(自监督学习)

https://zhuanlan.zhihu.com/p/108625273

Self-Supervised Learning入门介绍

https://zhuanlan.zhihu.com/p/108906502

Self-supervised Learning再次入门

https://mp.weixin.qq.com/s/VvUj0S2OTf8BowGRjDuVag

图解自监督学习，人工智能蛋糕中最大的一块

https://mp.weixin.qq.com/s/df51T24mBVycBeI_M7QqOQ

无标记数据学习, 83ppt

https://mp.weixin.qq.com/s/2FxD6ga6b_WOdAni16wd2Q

自监督学习在计算机视觉应用最新概述，108页ppt Self-supervised learning

https://mp.weixin.qq.com/s/3kwLoojFjJoPz4pUuEVA8g

神奇的自监督场景去遮挡

https://mp.weixin.qq.com/s/r1uXn2jGsHZcZ8Nk7GnGFA

语义表征的无监督对比学习：一个新理论框架

https://mp.weixin.qq.com/s/SOaA9XNnymLgGgJ5JNSdBg

对比学习（Contrastive Learning）相关进展梳理

https://mp.weixin.qq.com/s/U0pTQkW55evm94iQORwGeA

图解SimCLR框架，用对比学习得到一个好的视觉预训练模型

https://mp.weixin.qq.com/s/eROWWPQkUs91bcv4VsQqSA

NLP中的自监督表示学习，全是动图，很过瘾的

# 深度信息检索+

https://mp.weixin.qq.com/s/NJf5e25tvT_xKXLD7UY1AQ

MySQL智能调度系统。这篇blog其实和MySQL关系不大，算是DL在负载均衡方面的应用吧。

https://mp.weixin.qq.com/s/fzdK4YPTUgiW0D0aeH7WlQ

用于跨模态检索的综合距离保持自编码器

https://mp.weixin.qq.com/s/AWsiAYyVWY83s5uJ01Lg6Q

千亿级照片，毫秒间匹配最佳结果，微软开源Bing搜索背后的关键算法

https://mp.weixin.qq.com/s/fw5dRWmvZ17lqzxjKFrCtQ

相关性特征在图片搜索中的实践

https://mp.weixin.qq.com/s/jjbiUkmJ71rM9BYs5yKFSA

从算法原理到应用部署！微信“扫一扫”识物的背后技术揭秘

https://mp.weixin.qq.com/s/38d90XC2DjMHRoWnKEeVIw

基于图像查询的视频检索

https://mp.weixin.qq.com/s/fDaZ2HU7W6LnIY_8n-Zg_A

视频版权检测算法​​

https://mp.weixin.qq.com/s/_iTmh4vPnL78HPA-0wY95g

阿里文娱搜索算法实践和思考

https://zhuanlan.zhihu.com/p/113244063

搜索中的深度匹配模型

https://zhuanlan.zhihu.com/p/118183738

搜索中的深度匹配模型（下）

https://mp.weixin.qq.com/s/FSpVcTM9BcyraQwuaJ833Q

服装局部抄袭怎么解决？ 阿里推出区域检索算法

https://mp.weixin.qq.com/s/SMAHf7od8ygNIP6Zh9za3w

KDD Cup 2020多模态检索赛道：数据分析

https://mp.weixin.qq.com/s/W8YlrSyM7K84-_jwiD6E7g

微信扫一扫识物的技术揭秘：抠图与检索

https://zhuanlan.zhihu.com/p/112719984

全面理解搜索Query：当你在搜索引擎中敲下回车后，发生了什么？

# Graph NN+

https://mp.weixin.qq.com/s/_vbcLre5HIrOGbAjTzLFjA

动态网络表征学习在推荐领域的创新与实践

https://zhuanlan.zhihu.com/p/139359188

关于GCN，我有三种写法

https://mp.weixin.qq.com/s/QF9-Pz2X4qToObGWwViFBQ

EGES：阿里在图嵌入领域中的探索

https://mp.weixin.qq.com/s/WnF-fqQyr2VNqr75Jzoqsw

Diff Pool：网络图的层次化表达

https://mp.weixin.qq.com/s/8kCKqM3yuohc4xOoFd8hGg

Heterogeneous Graph Neural Network

https://mp.weixin.qq.com/s/HUjq4TopxWLx3QTh5ZxfIQ

最新《图卷积神经网络》中文综述论文，26页pdf

https://mp.weixin.qq.com/s/RuCxY92qlhWnbZVYDXY_BQ

Mila唐建博士最新《图表示学习:算法与应用》2020研究进展，附59页ppt

https://mp.weixin.qq.com/s/2PY1baildUoZaetYlsukIQ

图卷积网络(GCN)的谱分析

# 语义分割进阶+

https://mp.weixin.qq.com/s/HJzbMoCa7GenNm78sz7YAg

全景分割是什么？

https://mp.weixin.qq.com/s/PUHytS_nLKPjlrv8RYxo8A

一文看懂实时语义分割

https://zhuanlan.zhihu.com/p/77834369

语义分割中的Attention和低秩重建

https://mp.weixin.qq.com/s/wAWB2SLaqD2SmP9-j0Ut7g

速度提升一倍，无需实例掩码预测即可实现全景分割

https://mp.weixin.qq.com/s/LZNla-NKAu8wmi-OaJD8yA

旷视研究院推出可学习的树状滤波器，实现保留结构信息的特征变换

https://mp.weixin.qq.com/s/lTPm229gzV_9RU-aiY-xQg

2019年5篇图像分割算法最佳综述

https://mp.weixin.qq.com/s/n9Xdj5RKGR9cyXXNzxzvSw

基于深度学习的图像分割在高德的实践

https://blog.csdn.net/sanshibayuan/article/details/103642419

单阶段实例分割（Single Shot Instance Segmentation）

https://mp.weixin.qq.com/s/v_TTwTWx0lu2rJmxvzQQ4g

北航、旷视联合，打造最强实时语义分割网络

https://mp.weixin.qq.com/s/aSHhpMtgzV4_6NTElTvPIA

语义分割－多层特征融合

https://mp.weixin.qq.com/s/6EOkYdiVm0Lvkc24WiRbFg

基于自适应显着性的图像分割

https://mp.weixin.qq.com/s/WuWZS25aAWDLpVZQKuP2Tw

美团无人配送CVPR2020论文CenterMask解读

https://zhuanlan.zhihu.com/p/134111177

实例分割新思路: Deep Snake

# FCN

深度学习最初流行的分割方法是，打补丁式的分类方法 (patch classification) 。逐像素地抽取周围像素对中心像素进行分类。由于当时的卷积网络末端都使用全连接层 (full connected layers) ，所以只能使用这种逐像素的分割方法。

Fully Convolutional Networks是Jonathan Long和Evan Shelhamer于2014年提出的网络结构。

论文：

《Fully Convolutional Networks for Semantic Segmentation》

代码：

https://github.com/shelhamer/fcn.berkeleyvision.org

>Jonathan Long，CMU本科（2010年）+UCB博士在读。   
>个人主页：   
>https://people.eecs.berkeley.edu/~jonlong/

>Evan Shelhamer，UCB博士在读。   
>个人主页：   
>http://imaginarynumber.net/

>Trevor Darrell，University of Pennsylvania本科（1988年）+MIT硕博（1992年、1996年）。MIT教授（1999～2008）。UCB教授。   
>个人主页：   
>https://people.eecs.berkeley.edu/~trevor/

通常CNN网络在卷积层之后会接上若干个全连接层, 将卷积层产生的特征图(feature map)映射成一个固定长度的特征向量。以AlexNet为代表的经典CNN结构适合于图像级的分类和回归任务，因为它们最后都期望得到整个输入图像的一个数值描述（概率），比如AlexNet的ImageNet模型输出一个1000维的向量表示输入图像属于每一类的概率(softmax归一化)。

示例：下图中的猫, 输入AlexNet, 得到一个长为1000的输出向量, 表示输入图像属于每一类的概率, 其中在“tabby cat”这一类统计概率最高。

![](/images/article/FCN_2.png)

然而CNN网络的问题在于：全连接层会将原来二维的矩阵（图片）压扁成一维的，从而丢失了空间信息。这对于分类是没有问题的，但对于语义分割显然就不行了。

![](/images/article/FCN.png)

上图是FCN的网络结构图，它的主要思想包括：

1.采用end-to-end的结构。

2.取消FC层。当图片的feature map缩小（下采样）到一定程度之后，进行反向的上采样操作，以匹配图片的语义分割标注图。这里的上采样所采用的方法，就是《深度学习（九）》中提到的transpose convolution。

4.由于上采样会丢失信息。因此，为了更好的预测图像中的细节部分，FCN还将网络中浅层的响应也考虑进来。具体来说，就是将Pool4和Pool3的响应也拿来，分别作为模型FCN-16s和FCN-8s的输出，与原来FCN-32s的输出结合在一起做最终的语义分割预测（如下图所示）。

![](/images/article/FCN_3.png)

上图的结构在论文中被称为Skip Layer。

FCN的另一贡献是**支持任意大小的图像**。在CNN的常见操作中，Conv和Pooling都不在意图像大小。一组参数可以应用于任意大小的图像，但FC要求固定的输入维度，这决定了输入的图像的大小必须是固定的。因此，现代的CNN为了支持任意大小的图像，都有意减少或避免使用FC。

参考：

http://www.cnblogs.com/gujianhan/p/6030639.html

全卷积网络FCN详解

https://zhuanlan.zhihu.com/p/32506912

FCN的简单实现

https://mp.weixin.qq.com/s/kc0tTcTzRAT0p7q6ejXbqQ

重新发现语义分割，一文简述全卷积网络

https://www.zhihu.com/question/56688854

卷积神经网络里输入图像大小何时是固定，何时是任意？

https://mp.weixin.qq.com/s/AXfyMeFnCENIMc2qS8hNtA

10分钟看懂全卷积神经网络（FCN）：语义分割深度模型先驱

# SegNet

SegNet是Vijay Badrinarayanan于2015年提出的。

论文：

《SegNet: A Deep Convolutional Encoder-Decoder Architecture for Robust Semantic Pixel-Wise Labelling》

代码：

https://github.com/alexgkendall/caffe-segnet

除此之外，还有一个demo网站：

http://mi.eng.cam.ac.uk/projects/segnet/

>Vijay Badrinarayanan，印度人，班加罗尔大学本科（2001年）+Georgia理工硕士（2005年）+法国INRIA博士（2009年）。剑桥大学讲师。

>Alex Kendall，新西兰奥克兰大学本科（2014年）+剑桥大学博士在读。本文二作，但是代码和demo都是他写的。

>Roberto Cipolla，剑桥大学本科（1984年）+宾夕法尼亚大学硕士（1985年）+牛津大学博士（1991年）。剑桥大学教授。

![](/images/article/SegNet.png)

相比于CNN下采样阶段的结构规整，FCN上采样时的结构就显得凌乱了。因此，SegNet采用了几乎和下采样对称的上采样结构。

参考：

http://blog.csdn.net/fate_fjh/article/details/53467948

SegNet

https://mp.weixin.qq.com/s/YwmHiQ0vyFAx_dhjsmOlAQ

编解码结构SegNet
