---
layout: post
title:  深度学习（十八）——数据增强, Graph NN, 语义分割
category: DL 
---

# 数据增强

https://mp.weixin.qq.com/s/GqPfvWwH1T0XFwiZ86cW8A

SamplePairing：针对图像处理领域的高效数据增强方式

https://mp.weixin.qq.com/s/cQtXvOjSXFc4YKn7ANBc_w

谷歌大脑提出自动数据增强方法AutoAugment：可迁移至不同数据集

https://mp.weixin.qq.com/s/ojFo7-gUh73iK3uImFS2-Q

一文道尽主流开源框架中的数据增强

https://mp.weixin.qq.com/s/xJhWu-1FyhIWbFBC5oHMkw

一文道尽深度学习中的数据增强方法（上）

https://mp.weixin.qq.com/s/OctAGrcBB0a6TOGWMmVKUw

深度学习中的数据增强（下）

https://mp.weixin.qq.com/s/lMU6_ywQqneyunqEV6uDiA

如何改善你的训练数据集？

https://mp.weixin.qq.com/s/ooX9Hj5ejO6po6Ghb4zOug

一文解读合成数据在机器学习技术下的表现

https://zhuanlan.zhihu.com/p/33485388

mixup与paring samples ，ICLR2018投稿论文的数据增广两种方式

https://mp.weixin.qq.com/s/_7xFBLPGT0VRTJ22toHJ3g

深度学习中常用的图像数据增强方法

https://mp.weixin.qq.com/s/sXV9epWguGbJEZYo4yNp5Q

如何正确使用样本扩充改进目标检测性能

https://zhuanlan.zhihu.com/p/46833956

图像数据增强之弹性形变（Elastic Distortions）

# Graph NN

https://github.com/thunlp/GNNPapers

相关论文列表

https://mp.weixin.qq.com/s/xc_TnMLs3o2LQ8eM4naZDw

AAAI2019 Tutorial《图表示学习》, 180页PPT带你从入门到精通

https://mp.weixin.qq.com/s/_aydey5ZVwrObmoFXXIYcw

Bengio等人提出图注意网络架构GAT，可处理复杂结构图

https://zhuanlan.zhihu.com/p/34232818

《Graph Attention Networks》阅读笔记

https://zhuanlan.zhihu.com/p/28170197

《Gated Graph Sequence Neural Networks》阅读笔记

https://mp.weixin.qq.com/s/Pm1HiEQOBnbo_GQ_v6Y_zw

腾讯提出自适应图卷积神经网络，接受不同图结构和规模的数据

https://mp.weixin.qq.com/s/bMpugd2Lp35VPr8fQAPzsg

一文概览图卷积网络基本结构和最新进展

https://zhuanlan.zhihu.com/p/31067515

《Semi-Supervised Classification with Graph Convolutional Networks》阅读笔记

https://mp.weixin.qq.com/s/6viSk0Ts_7eTfYrWYi_HDQ

基于图结构的实体和关系联合抽取模型简介

https://mp.weixin.qq.com/s/w5ldyp00CqkX8Kp-8Aw0nQ

图深度学习(GraphDL)，下一个人工智能算法热点？一文了解最新GDL相关文章

https://mp.weixin.qq.com/s/Jt6CjMqNFEXWoL5pkLeVyw

洛桑理工：Graph上的深度学习报告

https://zhuanlan.zhihu.com/p/36117802

《Learn to Represent Programs with Graphs》阅读笔记。这篇论文讲述了DL在程序代码纠错方面的应用。

https://zhuanlan.zhihu.com/p/37278426

Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks

https://mp.weixin.qq.com/s/iQYVyo2PHuGbEsYgdIf_oQ

DeepMind等机构提出“图网络”：面向关系推理

https://mp.weixin.qq.com/s/TAccHagxXQ82lfE91Y6xWg

CNN已老，GNN来了：重磅论文讲述深度学习的因果推理

https://mp.weixin.qq.com/s/UONtTJJgDawRPWtatAVKkg

如何利用高效的搜索算法来搜索网络的拓扑结构

https://mp.weixin.qq.com/s/lt9lZbulkW0C8A_xi6hodQ

浅析图卷积神经网络

https://mp.weixin.qq.com/s/SGCtwYWfnxjcpMJeeH1b4w

图神经网络+池化模块，斯坦福等提出层级图表征学习

https://mp.weixin.qq.com/s/DOau_vTbwCauQ8mrHkGu9Q

首个面向Facebook、arXiv网络图类的对抗攻击研究

https://mp.weixin.qq.com/s/XSug_qOqq_QaphkiRlGkIg

图卷积GCN前沿方法介绍

https://mp.weixin.qq.com/s/aeQyZ8cpz81cK8Dg-84mjA

网络表征学习综述

https://mp.weixin.qq.com/s/_0quf0IRe8mn4dnsBwf6Aw

基于路径的实体图关系抽取模型

https://mp.weixin.qq.com/s/jCgbBldpw4TGHUvN9WkJZg

在对抗中学习网络结构——87页PPT带你学习Graph中的GAN

https://mp.weixin.qq.com/s/xTZbfiLYHB64AJJRcw04qQ

知识图和神经网络：如何有效读取图节点属性

https://mp.weixin.qq.com/s/9fFjVSiMg-LwddXfNJuKuw

DeepMind开源图网络库，一种结合图和神经网络的新方法

https://mp.weixin.qq.com/s/5DmpgPN4t3p3H53Xu7_-3A

北大、微软亚洲研究院：高效的大规模图神经网络计算

https://mp.weixin.qq.com/s/BFJD8i_yg1Y6fxZS5or-rw

Bengio最新论文提出GibbsNet：深度图模型中的迭代性对抗推断

https://zhuanlan.zhihu.com/p/48834333

GCN in 2018：2018年顶会论文中的图卷积神经网络的理论与应用

https://mp.weixin.qq.com/s/TGuEvNXw_9S5-9a3KyDvvw

基于图卷积网络的图深度学习

https://mp.weixin.qq.com/s/zg3yW7e4UKIs9-m6WmcbvA

GraphWave：一种全新的无监督网络嵌入方法

https://mp.weixin.qq.com/s/rGC8O2Pyq8WL8D8ATMbH0Q

NYU、AWS联合推出：全新图神经网络框架DGL正式发布

https://mp.weixin.qq.com/s/mamet6l_lA7fhoYkysZ7PQ

华为联合LSE提出KONG：有序近邻图的核函数

https://mp.weixin.qq.com/s/WW-URKk-fNct9sC4bJ22eg

深度学习时代的图模型，清华发文综述图网络

https://mp.weixin.qq.com/s/Rr6SC-se_0q8dfEz0oUwlA

清华大学孙茂松课题组:《图神经网络: 方法与应用》综述论文

https://mp.weixin.qq.com/s/OnRB44tliuTFcjlmuRG3Xw

图神经网络“理论在哪里“？

https://mp.weixin.qq.com/s/bsNDI9YxFdaB2Q5aRz9ECw

图卷积神经网络的变种与挑战

https://mp.weixin.qq.com/s/Uy2ekBiwkI2sIo637b-16g

北大、微软提出NGra：高效大规模图神经网络计算

https://mp.weixin.qq.com/s/kcXp-uWcmIsAVfa63mor4g

图卷积网络介绍及进展

https://mp.weixin.qq.com/s/eelcT5x_kWC0dDt0_Ph4qg

清华朱文武组一文综述GraphDL五类模型

https://mp.weixin.qq.com/s/0rs8Wur7Iv6jSpFz5C-KNg

来自IEEE Fellow的GNN综述

https://mp.weixin.qq.com/s/I8pGqpKnRJp9HRglHfMZCw

手把手教你用DGL框架进行批量图分类

https://mp.weixin.qq.com/s/diIzbc0tpCW4xhbIQu8mCw

阿里凑单算法首次公开！基于Graph Embedding的打包购商品挖掘系统解析

https://mp.weixin.qq.com/s/chiHw5gKnJyTJTQeF6gViw

在向量空间中启用网络分析和推理，清华大学崔鹏博士最新分享

https://mp.weixin.qq.com/s/oKwxWbCkH-xqYSJIBdb92A

2018超网络节点表示学习

https://mp.weixin.qq.com/s/kQlxLDHLI6xxFzwJVjFj7w

GraRep: 基于全局结构信息的图结点表示学习

https://mp.weixin.qq.com/s/WQlSghxG89JCroNZSmop8w

朱军：关于图的表达学习

https://mp.weixin.qq.com/s/WMpcamrHjUDnYwqyISdooA

斯坦福Jure Leskovec图表示学习：无监督和有监督方法

https://mp.weixin.qq.com/s/mTCrTPzyeogwRHfgitfK6Q

为什么说图网络是AI的未来？

https://mp.weixin.qq.com/s/cdbHoR_E_mpIdcvmNGWfDA

掌握图神经网络GNN基本，看这篇文章就够了

https://mp.weixin.qq.com/s/043sK8IDmdTYDpbCfPLIxw

图神经网络综述：方法及应用

https://mp.weixin.qq.com/s/c6ZhSk4r3pvnjHsvpwkkSw

用图卷积网络(GCN)来做语义角色标注

https://mp.weixin.qq.com/s/B8rJRlnwGJKUSI17Ot66Xw

从CNN到GCN的联系与区别——GCN从入门到精（fang）通（qi）

https://mp.weixin.qq.com/s/DUv5c6ce-dgLOBAE4ChiQg

图神经网络为何如此强大？看完这份斯坦福31页PPT就懂了！

https://mp.weixin.qq.com/s/2SaBiMJzhSRw1G0giL9TAw

深入理解图注意力机制

https://mp.weixin.qq.com/s/sg9O761F0KHAmCPOfMW_kQ

图卷积网络到底怎么做，这是一份极简的Numpy实现

# 语义分割

Semantic segmentation是图像理解的基石性技术，在自动驾驶系统（具体为街景识别与理解）、无人机应用（着陆点判断）以及穿戴式设备应用中举足轻重。

我们都知道，图像是由许多像素（Pixel）组成，而“语义分割”顾名思义就是将像素按照图像中表达语义含义的不同进行分组（Grouping）/分割（Segmentation）。

![](/images/article/image_enet.png)

上图是语义分割网络ENet的实际效果图。其中，左图为原始图像，右图为分割任务的真实标记（Ground truth）。

显然，在图像语义分割任务中，其输入为一张HxWx3的三通道彩色图像，输出则是对应的一个HxW矩阵，矩阵的每一个元素表明了原图中对应位置像素所表示的语义类别（Semantic label）。

因此，图像语义分割也称为“图像语义标注”（Image semantic labeling）、“像素语义标注”（Semantic pixel labeling）或“像素语义分组”（Semantic pixel grouping）。

由于图像语义分割不仅要识别出对象，还要标出每个对象的边界。因此，与分类目的不同，相关模型要具有像素级的密集预测能力。

目前用于语义分割研究的两个最重要数据集是PASCAL VOC和MSCOCO。

参考：

https://zhuanlan.zhihu.com/p/21824299

从特斯拉到计算机视觉之“图像语义分割”

https://zhuanlan.zhihu.com/SemanticSegmentation

一个语义分割的专栏

https://mp.weixin.qq.com/s/zZ-i54_wqzVQxTCFABNIMQ

闲聊图像分割这件事儿

https://zhuanlan.zhihu.com/p/22308032

图像语义分割之FCN和CRF

https://zhuanlan.zhihu.com/p/25515361

图像语义分割之特征整合和结构预测

https://zhuanlan.zhihu.com/p/27794982

语义分割中的深度学习方法全解：从FCN、SegNet到各代DeepLab

https://mp.weixin.qq.com/s/4BvvwV11f9MrrYyLwUrX9w

还在用ps抠图抠瞎眼？机器学习通用背景去除产品诞生记

https://mp.weixin.qq.com/s/mQqEe4LC0VHBH2ZAtFanWQ

基于深度学习的图像语义分割方法回顾

https://mp.weixin.qq.com/s/9G3kahaoOSoB-DiGey1VLA

基于深度学习的图像语义分割算法综述

https://mp.weixin.qq.com/s/JbdwtpA3iRXReyerO4HYIg

一文了解什么是语义分割及常用的语义分割方法有哪些

https://mp.weixin.qq.com/s/jCv259hI0vl7st80Obfrcg

图像语义分割的工作原理和CNN架构变迁

https://mp.weixin.qq.com/s/KcVKKsAyz-eVsyWR0Y812A

分割算法——可以分割一切目标

# 前DL时代的语义分割

从最简单的像素级别“阈值法”（Thresholding methods）、基于像素聚类的分割方法（Clustering-based segmentation methods）到“图划分”的分割方法（Graph partitioning segmentation methods），在DL“一统江湖”之前，图像语义分割方面的工作可谓“百花齐放”。在此，我们仅以“Normalized cut”和“Grab cut”这两个基于图划分的经典分割方法为例，介绍一下前DL时代语义分割方面的研究。

## Normalized cut

Normalized cut （N-cut）方法是基于图划分（Graph partitioning）的语义分割方法中最著名的方法之一，于2000年Jianbo Shi和Jitendra Malik发表于相关领域顶级期刊TPAMI。

通常，传统基于图划分的语义分割方法都是将图像抽象为图（Graph）的形式$$\bf{G}=(\bf{V},\bf{E})$$（$$\bf{V}$$为图节点，$$\bf{E}$$为图的边），然后借助图理论（Graph theory）中的理论和算法进行图像的语义分割。

常用的方法为经典的最小割算法（Min-cut algorithm）。不过，在边的权重计算时，经典min-cut算法只考虑了局部信息。如下图所示，以二分图为例（将$$\bf{G}$$分为不相交的$$\bf{A},\bf{B}$$两部分），若只考虑局部信息，那么分离出一个点显然是一个min-cut，因此图划分的结果便是类似$$n_1$$或$$n_2$$这样离群点，而从全局来看，实际想分成的组却是左右两大部分。

![](/images/article/N_cut.jpg)
