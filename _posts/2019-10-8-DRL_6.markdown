---
layout: post
title:  深度强化学习（六）——元学习, DRL参考资源（1）
category: DRL 
---

# 元学习

人工智能的历史显示了明确的进展方向：

第一代：**良好的老式人工智能**

- 手工预测
- 什么都不学

第二代：**浅学习**

- 手工功能
- 学习预测

第三代：**深度学习**

- 手工算法（优化器，目标，架构......）
- 端到端地学习功能和预测

第四代：**元学习**

- 无手工
- 端到端学习算法和功能以及预测

## 参考

https://github.com/gopala-kr/meta-learning

元学习（meta-learning）相关文献资源大列表

https://github.com/sudharsan13296/Awesome-Meta-Learning

元学习相关资源汇总

https://mp.weixin.qq.com/s/KKK3VEpwL90g6Aro8qtXxQ

学习如何学习的算法：简述元学习研究方向现状

https://mp.weixin.qq.com/s/jlD5p5GXFmrWlxg9xvehxg

元学习—Meta Learning的兴起

https://mp.weixin.qq.com/s/qoKQwEvOnP384i5Z-_jO1A

CVPR2019最新元学习教程：基于元学习的计算机视觉应用

https://mp.weixin.qq.com/s/KtO3OTZ-bZ6m0ZSI6jTyjw

OpenAI提出Reptile：可扩展的元学习算法

https://mp.weixin.qq.com/s/T4GiL9vW7ALOzWloE_QQBA

OpenAI开发可拓展元学习算法Reptile，能快速学习

https://mp.weixin.qq.com/s/MWcoGsQJg1GBbSqzyPD9uQ

基于梯度的元学习算法，可高效适应非平稳环境

https://zhuanlan.zhihu.com/p/35695477

基于Meta Learning在动态竞争环境中实现策略自适应

https://mp.weixin.qq.com/s/AhadWUjtgsFmb8uTylTvqg

OpenAI提出新型元学习方法EPG，调整损失函数实现新任务上的快速训练

https://mp.weixin.qq.com/s/dmRdp2oMn0vGukclJSVZDg

Uber AI论文：利用反向传播训练可塑神经网络，生物启发的元学习范式

https://mp.weixin.qq.com/s/Cc4EHc6ei-PtZWhewM10xw

学习如何学习的算法：简述元学习研究方向现状

https://mp.weixin.qq.com/s/4f6-gXovdrYk7240TrUwJg

谷歌大脑：基于元学习的无监督学习更新规则

https://mp.weixin.qq.com/s/cAbMB-DB9vu2ua8t5J28ww

从零开始，了解元学习

https://mp.weixin.qq.com/s/Q36vpS1HF2IfeCsFLh656A

基于元强化学习的神经科学新理论

https://mp.weixin.qq.com/s/XtzvHOk7CdXRBy02kUmgsg

近期爆火的Meta Learning，遗传算法与深度学习的火花，再不了解你就out了

https://mp.weixin.qq.com/s/KvgYyuyICueNQPo_S27fEA

BAIR展示新型模仿学习，学会像人那样执行任务

https://zhuanlan.zhihu.com/p/41223529

最前沿:Meta RL论文解读

https://zhuanlan.zhihu.com/p/40600485

最前沿：Meta Learning前沿进展扫描

https://zhuanlan.zhihu.com/p/28639662

百家争鸣的Meta Learning/Learning to learn

https://zhuanlan.zhihu.com/p/45845001

最前沿：用模仿学习来学习增强学习

https://zhuanlan.zhihu.com/p/46059552

Meta Learning单排小教学

https://zhuanlan.zhihu.com/p/46131981

最前沿：Meta Learning在少样本文本翻译上的应用

https://zhuanlan.zhihu.com/p/46339823

谈谈无监督Meta Learning的研究

https://zhuanlan.zhihu.com/p/46340382

ICLR19最新论文解读之Meta Domain Adaptation

https://mp.weixin.qq.com/s/RBMGI20AI92ZcWSlYczqAA

伯克利、OpenAI等提出基于模型的元策略优化强化学习

https://mp.weixin.qq.com/s/p0dcov84pZqsU7XP30bexQ

Meta-Learning元学习：学会快速学习

https://mp.weixin.qq.com/s/wl8j7dLu3OxPV7MNaO2-7Q

《基于梯度的元学习》199页伯克利博士论文带你回顾元学习最新发展脉络

https://mp.weixin.qq.com/s/ftiGPBhAx5iqlW_Ltg1yhg

《元监督视觉学习》132页伯克利博士论文带你回顾元监督视觉应用最新发展脉络

https://mp.weixin.qq.com/s/K7sLM-LMcF6-gQrV1ddrDw

让智能体主动交互，DeepMind提出用元强化学习实现因果推理

https://mp.weixin.qq.com/s/8sBXlnXiZNsPRwFsgJVRQQ

谷歌提出元奖励学习，两大基准测试刷新最优结果

https://mp.weixin.qq.com/s/x7uk7jBNvnM7Tgk9lFKy3Q

元学习(Meta-Learning)综述及五篇顶会论文推荐

https://mp.weixin.qq.com/s/GF_NLkSw64_6msmFep81fw

Google Brain ICLR Talk：元学习的前沿与挑战

https://mp.weixin.qq.com/s/sQmDZsVGIADwO97yEFATkw

ICML2019《元学习》教程与必读论文列表

https://zhuanlan.zhihu.com/p/70782949

最前沿：General Meta Learning

https://mp.weixin.qq.com/s/rZdd-vWlicynthaSasX3kQ

Meta Learning入门：MAML和Reptile

https://mp.weixin.qq.com/s/MsIAkJAcYHWkkMjzd7qXKA

元学习与强化学习的概率视角，47页ppt，DeepMind牛津Yee Whye Teh

https://mp.weixin.qq.com/s/IdUhvWJYviKtPs9jCbtybA

元知识图谱推理

https://www.zhihu.com/question/291656490

求问meta-learning和few-shot learning的关系是什么？

https://mp.weixin.qq.com/s/LZbprcnben6vPqsoC1DgDA

DeepMind提出元梯度强化学习算法，显著提高大规模深度强化学习应用的性能

https://mp.weixin.qq.com/s/AH35EGTH1YDSx4WzUwY15g

三四行代码打造元学习核心，PyTorch元学习库L2L现已开源

https://github.com/tristandeleu/pytorch-meta

PyTorch上方便好用的元学习工具包

https://mp.weixin.qq.com/s/Fte0SQ7J57AVGyTiIwWKAw

元学习与深度强化学习的机器人应用，84页ppt

https://mp.weixin.qq.com/s/xu5ieaPP2de0GML7b-1BsA

谈谈元学习的技术实现框架

https://mp.weixin.qq.com/s/spRlzjFTh4KeyFfd8pmZgw

新框架ES-MAML：基于进化策略、简易的元学习方法

# DRL参考资源

https://mp.weixin.qq.com/s/ruAAQEjPIDPWPiuPepKU6Q

Deep Reinforcement Learning: An Overview

https://mp.weixin.qq.com/s/FjmlXqlpaRVLdAbjqspOJA

这是一份你必须学习的强化学习算法清单

https://mp.weixin.qq.com/s/lfXQqllfFPtuNIrQZiD-NQ

深度强化学习十大原则

https://mp.weixin.qq.com/s/I8IwPCY6-zocJKFXMr6rUg

深度强化学习的18个关键问题

https://mp.weixin.qq.com/s/_lmz0l1vP_CQ6p6DdFnHWA

谷歌大脑工程师的深度强化学习劝退文

https://zhuanlan.zhihu.com/p/39999667

强化学习路在何方？

https://mp.weixin.qq.com/s/oA98YyLqn1B22QZ5b_iDVA

IJCAI 2018：聚焦强化学习的学习效率

https://mp.weixin.qq.com/s/FtHJCXniVne2TGKfgCeS9w

Pieter Abbeel：深度强化学习加速方法

https://mp.weixin.qq.com/s/xlnwB9e1ks-4M4djnyIAyQ

解读72篇DeepMind深度强化学习论文

https://mp.weixin.qq.com/s/VYIyWRykREjOyLu4YDhLeA

61篇NIPS2019深度强化学习论文及部分解读

https://mp.weixin.qq.com/s/e6QOz-MQSn7n53EPtpw64w

DeepMind强化学习综述：她可以很快，但快从慢中来

https://mp.weixin.qq.com/s/sHP03DAeZvdBxwVPuSNRPg

如何丝滑地入门神经网络？写个AI赛车游戏，只训练4代就能安全驾驶

https://mp.weixin.qq.com/s/1SZKhG1ZbD1pl-3YQD_umg

6行代码搞定基本的RL算法，速度围观Reddit高赞帖

https://mp.weixin.qq.com/s/7BsXPQ8wC6_fHulU63ZQiQ

当强化学习遇见泛函分析

https://mp.weixin.qq.com/s/6n5HawyR4AgH8Dq0gJMw2g

强化学习的基本概念与代码实现

https://mp.weixin.qq.com/s/RLEuaiRdq6AbTSUcYQ5O3A

深度强化学习在NLP怎么用？看清华黄民烈老师这一份120页《自然语言处理和搜索中的深度强化学习应用》讲义

https://zhuanlan.zhihu.com/p/29019246

基于策略的增强学习

https://mp.weixin.qq.com/s/OY56lJ_NFf5vVAgKfKyx2A

利用强化学习自动搜索最优化方法

https://mp.weixin.qq.com/s/uDFsWebfLmka-zZX3Y_8kg

深度强化学习在面向任务的对话管理中的应用

https://mp.weixin.qq.com/s/nYOOwVoijl1p4V0A7yaI3w

机遇与挑战：用强化学习自动搜索优化算法

http://mp.weixin.qq.com/s/TBVVdX3erOpXNjXmhLmxOw

学“深度强化学习”，看懂DeepMind这篇文章就够了!

https://mp.weixin.qq.com/s/_Di73PkEWJV1-OLLHfz7yQ

组合在线学习：实时反馈玩转组合优化

https://mp.weixin.qq.com/s/aVWHlwOmNIqOlu3025_RXQ

DeepMind提出多任务强化学习新方法Distral

https://mp.weixin.qq.com/s/gFHbLF-q91sddMAX1CRbEQ

俞扬：“审时度势”的高效强化学习

https://mp.weixin.qq.com/s/lstCIiNs_qA6k7GCYUBv2w

阿尔伯塔大学提出新型多步强化学习方法，结合已有TD算法实现更好性能

https://mp.weixin.qq.com/s/ybyZpaHr-JJg7CCdXGOl5A

Seq2seq强化学习实战

https://mp.weixin.qq.com/s/TUk1PWT9CfPGEW77UKxpjw

三招武林绝学带你玩转“强化学习”

https://mp.weixin.qq.com/s/W9yhj7_frLYWJocoBR1TMQ

避免AI错把黑人识别为大猩猩：伯克利大学提出协同反向强化学习

https://mp.weixin.qq.com/s/p2hlc2PsLgrvxOF8wBZANg

李飞飞高徒范麟熙解析强化学习在游戏和现实中的应用

http://mp.weixin.qq.com/s/EPbKE-TAnAPugJDhXHEyNA

DeepMind开源Psychlab平台——搭建AI和认知心理学的桥梁

https://mp.weixin.qq.com/s/4qeHfU9GS4aDWOHsu4Dw2g

记忆增强蒙特卡洛树搜索细节解读

https://mp.weixin.qq.com/s/1zJyw67B6DqsHEJ3avbsfQ

DeepMind推出分布式深度强化学习架构IMPALA，让一个Agent学会多种技能

https://mp.weixin.qq.com/s/xJ_g3BvbM-WaIyLthHdhEw

DeepMind发布通用强化学习新范式，自主机器人可学会任何任务

https://mp.weixin.qq.com/s/To3pnx1hVq_4p7UnQVMw9A

斯坦福大学&DeepMind联合提出机器人控制新方法，RL+IL端到端地学习视觉运动策略

https://mp.weixin.qq.com/s/U0K79ELLj4wsOR4sd5G4Vw

Vicarious详解新型图式网络：赋予强化学习泛化能力

https://mp.weixin.qq.com/s/R308ohdMU8b7Ap4CLofvDg

OpenAI开源算法ACKTR与A2C：把可扩展的自然梯度应用到强化学习

https://mp.weixin.qq.com/s/C8hsGkHGtoaS9Vzm6Ub4tw

Berkeley提出“随机搜索”训练线性策略，提高RL的性能

https://mp.weixin.qq.com/s/vYDb1rTdPxO1sIS38VX5xA

DeepMind的AI学会了画画，利用强化学习完全不需人教：SPIRAL

https://mp.weixin.qq.com/s/rpPN2rgru6krRz2fr1RhsQ

模拟世界的模型：谷歌大脑与Jürgen Schmidhuber提出“人工智能梦境”

https://mp.weixin.qq.com/s/AelAD57G4GOh7qm-_rvYsg

伯克利提出DeepMimic：使用强化学习练就18般武艺

https://mp.weixin.qq.com/s/0AM4eASolsPZ7GtPYVBqDQ

伯克利今年大热的DeepMimic开源了~

https://zhuanlan.zhihu.com/p/35567591

强化学习在关系抽取、QA场景的应用

https://mp.weixin.qq.com/s/zWo2iSiJBEBwnFF478xxfQ

DeepMind：探索人类行为中的强化学习机制

https://mp.weixin.qq.com/s/oOslkEklaZSbRb8eDDCRBw

天津大学、东京大学等研究：用深度强化学习检测模型缺陷

https://mp.weixin.qq.com/s/DNT9rMynbN4Th0AVDHeY_w

BAIR提出人机合作新范式：教你如何高效安全地在月球着陆

https://zhuanlan.zhihu.com/p/36375292

最前沿：当我们以为Rainbow就是Atari游戏的巅峰时，Ape-X出来把Rainbow秒成了渣！

https://mp.weixin.qq.com/s/KqLCTSYk1C0wYpJw-hpc1g

论强化学习和概率推断的等价性：一种全新概率模型
