---
layout: post
title:  深度学习（四十九）——模型压缩与加速（2）, Mask R-CNN, Fast Image Processing
category: DL 
---

# 模型压缩与加速

https://mp.weixin.qq.com/s/OyEIcS5o6kWUu2UzuWZi3g

这么Deep且又轻量的Network，实时目标检测

https://mp.weixin.qq.com/s/mWfZ4jfuby4myGfi6TW3wQ

从超参数到架构，一文简述模型优化策略

https://mp.weixin.qq.com/s/8NDOf_8qxMMpcuXIZGJCGg

Google又发大招：高效实时实现视频目标检测

https://mp.weixin.qq.com/s/_JlaxwEYqdTTuS4hNSQTTw

这么Deep且又轻量的Network，实时目标检测

https://mp.weixin.qq.com/s/mFuxCl0Mzv5hmDFewWZkrw

FAIR&MIT提出知识蒸馏新方法：数据集蒸馏

https://mp.weixin.qq.com/s/IxVMMu_7UL5zFsDCcYfzYA

AutoML自动模型压缩再升级，MIT韩松团队利用强化学习全面超越手工调参

https://mp.weixin.qq.com/s/fU-AeaPz-lHlg0CBgqnpZQ

轻量化神经网络综述

https://mp.weixin.qq.com/s/BMsvhXytSy2nWIsGOSOSBQ

自动生成高效DNN，适用于边缘设备的生成合成工具FermiNets

https://mp.weixin.qq.com/s/nEMvoiqImd0RxrskIH7c9A

仅17KB、一万个权重的微型风格迁移网络！

https://mp.weixin.qq.com/s/pc8fJx5StxnX9it2AVU5NA

基于手机系统的实时目标检测

https://mp.weixin.qq.com/s/6wzmyhIvUVeAN4Xjfhb1Yw

论文解读：Channel pruning for Accelerating Very Deep Neural Networks

https://mp.weixin.qq.com/s/-X7NYTzOzljzOaQL7_jOkw

惊呆了！速度高达15000fps的人脸检测算法！

https://mp.weixin.qq.com/s/6eyEMW9dVBR5cZrHxn8iqA

腾讯AI Lab详解3大热点：模型压缩、自动机器学习及最优化算法

https://xmfbit.github.io/2018/02/24/paper-ssl-dnn/

论文-Learning Structured Sparsity in Deep Neural Networks

https://mp.weixin.qq.com/s/d6HFVbbHwkxPGdnbyVuMyQ

密歇根州立大学提出NestDNN：动态分配多任务资源的移动端深度学习框架

https://mp.weixin.qq.com/s/lUTusig94Htf7_4Z3X1fTQ

清华&伯克利ICLR论文：重新思考6大剪枝方法

https://mp.weixin.qq.com/s/g3y9mRhkFtzSuSMAornnDQ

韩松博士论文：面向深度学习的高效方法与硬件

https://mp.weixin.qq.com/s/aH1zQ7we8OE59-O9n4IXhw

应对未来物联网大潮：如何在内存有限的情况下部署深度学习？

https://mp.weixin.qq.com/s/IfvXrsUq8-cBDC4_3O5v_w

Facebook新研究优化硬件浮点运算，强化AI模型运行速率

https://mp.weixin.qq.com/s/Jsxiha_BFtWVLvO4HMwJ3Q

工业界第一手实战经验：深度学习高效网络结构设计

https://mp.weixin.qq.com/s/uXbLb5ITHOU0dZRSWNobVg

算力限制场景下的目标检测实战浅谈

https://mp.weixin.qq.com/s/DoeoPGnS88HQmxagKJWLlg

小米开源FALSR算法：快速精确轻量级的超分辨率模型

https://mp.weixin.qq.com/s/wT39oUWfrQK-dg7hGXRynQ

实时单人姿态估计，在自己手机上就能实现

https://mp.weixin.qq.com/s/GJ7JMtWiKBku7dVJWOfLOA

CNN能同时兼顾速度与准确度吗？CMU提出AdaScale

https://mp.weixin.qq.com/s/pmel2k2J159zQi87ib3q8A

如何让CNN高效地在移动端运行

https://mp.weixin.qq.com/s/m-wQRm3VpfQkEOoUAxEdoA

论文解读: Quantized Convolutional Neural Networks for Mobile Devices

https://mp.weixin.qq.com/s/w7O2JxDH2ECqPn50sLfxpg

不用重新训练，直接将现有模型转换为MobileNet

https://mp.weixin.qq.com/s/EW6jvf98ifBucVz74SfSIA

文档扫描：深度神经网络在移动端的实践

https://mp.weixin.qq.com/s/FvR6loJ8KUxm7qwclestcQ

专门为卷积神经网络设计的训练方法：RePr

https://mp.weixin.qq.com/s/MDgqSwVEClNqNpaWuGTEpg

微软亚研院提出用于语义分割的结构化知识蒸馏

https://mp.weixin.qq.com/s/67GSnZnJySFrCESvmwhO9A

论文解读Channel pruning for Accelerating Very Deep Neural Networks

https://mp.weixin.qq.com/s/Lkxc_9sbRY157sMWaD5c7g

视频分割在移动端的算法进展综述

https://mp.weixin.qq.com/s/F0ykoKv027ycinsAZZjbWQ

ThunderNet：国防科大、旷视提出首个在ARM上实时运行的通用目标检测算法

https://mp.weixin.qq.com/s/ie2O5BPT-QxTRhK3S0Oa0Q

剪枝需有的放矢，快手&罗切斯特大学提出基于能耗建模的模型压缩

https://mp.weixin.qq.com/s/NsvjADgQZrYkUGNN6fzXVg

驭势科技推出“东风网络”：如何找到速度-精度的最优解？

https://mp.weixin.qq.com/s/HzgRHtVwdmW6_m7OJwK-ew

SysML 2019论文解读：Accurate and Efficient 2-Bit Quantized Neural Netowrks

https://mp.weixin.qq.com/s/5NM9M1oY8bwsEqdBRVYpMg

网络规模更小、速度更快，这是谷歌提出的MorphNet

https://mp.weixin.qq.com/s/SC3ebx-C4N4H8B_R6K09cg

分段的人脸检测在移动端的应用

https://zhuanlan.zhihu.com/p/51563760

知识蒸馏（Knowledge Distillation）最新进展（一）

https://zhuanlan.zhihu.com/p/53864403

知识蒸馏（Knowledge Distillation）最新进展（二）

# Mask R-CNN

Mask R-CNN虽然挂着R-CNN的名头，但却是一个对象实例分割（不仅要分出对象的类别，连同一类对象的不同实例也要分出来）的NN。它是何恺明2017年的新作。

论文：

《Mask R-CNN》

只有非官方的代码：

Caffe版本：

https://github.com/jasjeetIM/Mask-RCNN

TensorFlow版本：

https://github.com/hillox/TFMaskRCNN

MXNet版本：

https://github.com/TuSimple/mx-maskrcnn

Pytorch版本：

https://github.com/wannabeOG/Mask-RCNN

![](/images/img2/mask_rcnn.png)

参考：

https://zhuanlan.zhihu.com/p/25954683

Mask R-CNN个人理解

https://mp.weixin.qq.com/s/E0P2B798pukbtRarWooUkg

Mask R-CNN的Keras/TensorFlow/Pytorch代码实现

https://zhuanlan.zhihu.com/p/30967656

从R-CNN到Mask R-CNN

http://zh.gluon.ai/chapter_computer-vision/object-detection.html

使用卷积神经网络的物体检测

https://mp.weixin.qq.com/s/4BRwMEr6rFYvkmKXM7rYLg

效果惊艳！FAIR提出人体姿势估计新模型，升级版Mask-RCNN

https://mp.weixin.qq.com/s/UXzhMkGIwqek4zHVNPgRbA

Mask-RCNN论文解读

https://mp.weixin.qq.com/s/_ohsx7kzgU-szP-K9_Yv1w

优于Mask R-CNN，港中文&腾讯优图提出PANet实例分割框架

https://mp.weixin.qq.com/s/uJpVqRpWWaK2cY8fYGlRag

先理解Mask R-CNN的工作原理，然后构建颜色填充器应用

https://mp.weixin.qq.com/s/x_9klKK_hIiFV1fGhxZIVA

Mask R-CNN神应用：像英剧《黑镜》一样屏蔽人像

https://mp.weixin.qq.com/s/V6m1xBS2vZQ6VRlAg5zOSA

干掉照片中那些讨厌的家伙！Mask R-CNN助你一键“除”人！

https://mp.weixin.qq.com/s/48eIhnBdYzgEiV_wESHsJA

如何使用Mask RCNN模型进行图像实体分割？

https://mp.weixin.qq.com/s/G_2tuZlaxX5w-2c1DO8FwQ

利用边缘监督信息加速Mask R-CNN实例分割训练

https://mp.weixin.qq.com/s/Ug4ZEQWVF5UjhqWw4Kwb8A

Mask R-CNN抢车位，快人一步！

https://zhuanlan.zhihu.com/p/47579399

R-CNN、Fast/Faster/Mask R-CNN、FCN、RFCN 、SSD原理简析

https://mp.weixin.qq.com/s/CsEHuGz_fAq8eWpHRq7d6g

性能超越何恺明Mask R-CNN！华科硕士生开源图像分割新方法

https://mp.weixin.qq.com/s/xug0xKfc9RgJEUci1a_xog8

实例分割的进阶三级跳：从Mask R-CNN到Hybrid Task Cascade

https://mp.weixin.qq.com/s/7Z8unW7Gsu0cf1hAwvjAxw

何恺明等人提TensorMask框架：比肩Mask R-CNN，4D张量预测新突破

# Fast Image Processing

![](/images/article/FIP.png)

上图是照片界常用的几种修图方式之一。一般将这些图片风格转换的算法，称为图像处理算子（image processing operators）。如何加速image processing operators的计算，就成为了学界研究的课题之一。

本文提出的模型就是用来加速image processing operators计算的。它是Intel Lab的Qifeng Chen和Jia Xu于2017年提出的。

论文：

《Fast Image Processing with Fully-Convolutional Networks》

代码：

https://github.com/CQFIO/FastImageProcessing

Demo网站：

http://cqf.io/ImageProcessing/

这个课题一般使用MIT-Adobe FiveK Dataset作为基准数据集。网址：

http://groups.csail.mit.edu/graphics/fivek_dataset/

这个数据集包含了5K张原始照片，并雇用了5个专业修图师，对每张图片进行修图。

众所周知，多层神经网络只要有足够的深度和宽度，就可以任意逼近任意连续函数。然而从Fast Image Processing的目的来说，神经网络的深度和宽度注定是有限的，否则肯定快不了。而这也是该课题的研究意义所在。

本文只使用了MIT-Adobe数据集中的原始图片，并使用了10种常用的算子对图片进行处理。因此，该网络训练时的输入是原始图片，而输出是处理后的图片。

![](/images/article/MCA.png)

上图是本文模型的网络结构图。它的设计特点如下：

1.采用Multi-Scale Context Aggregation作为基础网络。MCA的内容参见《深度学习（十）》中的Dilated convolution一节。

2.传统MCA一般有下采样的过程，但这里由于网络输入和输出的尺寸维度是一样的，因此，所有的feature maps都是等大的。

3.借鉴FCN的思想，去掉了池化层和全连接层。

4.L1~L3主要用于图片的特征提取和升维，而L4~L5则用于特征的聚合和降维，并最终和输出数据的尺寸维度相匹配。

在normalization方面，作者发现有的operators经过normalization之后，精度会上升，而有的精度反而会下降，因此为了统一模型，定义如下的normalization运算：

$$\Psi^s(x)=\lambda_sx+\mu_sBN(x)$$

Loss函数为：

$$\mathcal{l(K,B)}=\sum_i\frac{1}{N_i}\|\hat f (I_i;\mathcal{K,B})-f(I_i)\|^2$$

这实际上就是RGB颜色空间的MSE误差。

为了检验模型的泛化能力，本文还使用RAISE数据集作为交叉验证的数据集。该数据集的网址：

http://mmlab.science.unitn.it/RAISE/

RAISE数据集包含了8156张高分辨率原始照片，由3台不同的相机拍摄，并给出了相机的型号和参数。

# Graph NN+

https://mp.weixin.qq.com/s/s6E2vV1KrQDI4SeAnkYTKw

图神经网络将成AI下一拐点！MIT斯坦福一文综述GNN到底有多强

https://mp.weixin.qq.com/s/6vhFfSh2mveBiZXB1oZb1Q

图分类：结合胶囊网络Capsule和图卷积GCN

https://mp.weixin.qq.com/s/aGP8pcsCmEdjdCWVjA82Jg

近期必读的5篇CVPR 2019图卷积网络相关论文和代码

https://mp.weixin.qq.com/s/CpDZEqo14X_lCBh6i7feIA

图卷积神经网络(GCN)文本分类详述

https://mp.weixin.qq.com/s/XApSbi-Pg-AeYGkPN3fldg

旷视研究院提出ML-GCN：基于图卷积网络的多标签图像识别模型

https://mp.weixin.qq.com/s/49vnVOO0G_JvKrWcsN2_Ww

关系图注意力网络-Relational Graph Attention Networks
