---
layout: post
title:  爬虫, scrapy, Mysql
category: technology 
---

# 爬虫

## 自动解析网页的结构化数据

抽取结构树，对比两个网页的dom tree的相似度（卷积核），找出并抽取相似节点。

参考：

http://www.doc88.com/p-2045913772352.html

Web页面中结构化数据抽取的实现与应用

http://www.cnblogs.com/codemind/p/smart_spider_parser.html

爬虫数据采集技术趋势－智能化解析

## 参考

https://mp.weixin.qq.com/s/X9NPFFTHTk62V21o63ceOA

Python 爬虫的工具列表大全

http://www.gooseeker.com/

一个基于FireFox的网络爬虫。

https://mp.weixin.qq.com/s/0yDokR2dYzetUy4NI9edSQ

那些你不知道的爬虫反爬虫套路

https://mp.weixin.qq.com/s/yR_wENRSbxvfrcYr9O9BuQ

23个Python爬虫开源项目代码：爬取微信、淘宝、豆瓣、知乎、微博等

https://mp.weixin.qq.com/s/38ofY693bXwFWIMNqYx4-A

常用的Python爬虫技巧总结

https://mp.weixin.qq.com/s/Hp6tEQujSgCnPwSKhAE72g

关于Python爬虫，这里有一条高效的学习路径

https://mp.weixin.qq.com/s/0QnOgT8F090MOzazzsZfZA

不会编程也能爬数据！3个爬虫小工具教你实现

https://mp.weixin.qq.com/s/7HxZGSTJvxjvpAsF5LfS-g

零基础的我是这样开始写Python爬虫的

https://mp.weixin.qq.com/s/5sVrSxRAXWBn3-NBSlYMIg

不踩坑的Python爬虫：如何在一个月内学会爬取大规模数据

https://mp.weixin.qq.com/s/z2uWLEWF6e0TJWIpXyY6mQ

如何用Python爬虫获取那些价值博文

https://mp.weixin.qq.com/s/SkGUZMgBW_oFBygc4d1zQg

如何用Python编写知乎爬虫？

https://mp.weixin.qq.com/s/-PPlfkHhQzGF1N6-dMlRNA

高阶Python爬虫实战：破解极验滑动验证码

https://mp.weixin.qq.com/s/w8U-GkOhAQivuHmrVFpw3w

Python爬虫抓取智联招聘

https://mp.weixin.qq.com/s/2Su1jN_XDr--VRHB18d7dQ

爬虫大神，又出新招

https://mp.weixin.qq.com/s/AVoySo0s6l85wTG9mgkrYQ

Python网络爬虫与信息抽取系列笔记（共8篇）

https://mp.weixin.qq.com/s/SEpclyZ5Y6iF7YF7_ZjQGg

爬虫实战：爬取当当网所有Python书籍

https://mp.weixin.qq.com/s/6A9wYqTrz_h5cR15WZwedQ

你还在付费爱奇艺VIP？神级程序员教你用Python任意下！

https://mp.weixin.qq.com/s/2k2XdzpLx5syeg_68LL4Xg

12行Python暴力爬《黑豹》豆瓣短评

https://mp.weixin.qq.com/s/RccEAl2g6P66RBuvxg9N1w

从Google百度到微博，优酷腾讯到抖音，这些爬虫你用过了吗？

https://mp.weixin.qq.com/s/WDovrR4octHEIOqSEs9pxA

Python爬虫的两套解析方法和四种爬虫实现

https://mp.weixin.qq.com/s?__biz=MzIxODM4MjA5MA==&mid=2247487342&idx=2&sn=e709ff7972ee21086f0b4aedb7c676aa

一文读懂网络爬虫！

https://mp.weixin.qq.com/s/LkEfbW5oscOXyPmb5iqcGA

Python爬取并分析拉勾网招聘数据

https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&mid=2247493477&idx=4&sn=b5906ee7b5af7bd414b5223549a30e64

五十种最好用的开源爬虫软件

https://mp.weixin.qq.com/s/G2oo6HMHnQtHPqsoSxUHqQ

权力的游戏收官，我用Python致敬这场血雨腥风

https://mp.weixin.qq.com/s/WDeF3o_M4RQRgwd2iex_bg

基于Selenium模拟浏览器爬虫详解

https://mp.weixin.qq.com/s/hvv2esNsyt3xpO9x1NkCTQ

充气娃娃什么感觉？Python告诉你

# scrapy

scrapy是一个Python写的网页抓取分析工具。网页抓取分析的学名叫做“Web scraping”，可在wiki上获得更多的相关信息。

官网：

https://scrapy.org/

安装：

`sudo apt install python-scrapy`

`scrapy crawl csdn`

新建工程：

`scrapy startproject tutorial`

参考：

https://segmentfault.com/a/1190000000583419

一个中文简易教程。

https://github.com/scrapy/dirbot

官方例程。

http://www.cnblogs.com/fengzheng/p/4974509.html

另一个中文简易教程。

https://mp.weixin.qq.com/s/nIcUBS0lRrOwVUHoWmKecw

爬虫系列之使用scrapy框架

https://mp.weixin.qq.com/s/A2QNr4-LTUNy-H8zE0OgXA

教你用Scrapy建立你自己的数据集

https://mp.weixin.qq.com/s/i-umuOi8jGw8dMQmG44liQ

如何租到靠谱的房子？Scrapy爬虫帮你一网打尽各平台租房信息！这篇blog中，还有如何用Kibana处理数据的内容

https://mp.weixin.qq.com/s/hzl8D-AhpCwqZVSLTK56XQ

Python爬虫--Scrapy入门

# Mysql

## 安装

`sudo apt-get install mysql-server mysql-client mysql-workbench`

其中，mysql-workbench是一个查看mysql的GUI工具。

安装过程中，会提示输入root用户的密码。注意：这里的root是mysql的登录帐号，而不是系统的登录帐号。

·/etc/my.cnf是默认的MySQL配置文件。

## 常用操作

登录方法：

`mysql -h 192.168.4.251 -u root -p`

语句以“;”结尾。

| 名称 | 操作 |
|:--|:--|
| 添加用户 | insert into mysql.user(Host,User,Password) <br/>values("localhost","test",password("1234")); |
| 列出所有数据库 | show database; |
| 切换数据库 | use 数据库名; |
| 列出所有表 | show tables; |
| 显示数据表结构 | describe 表名; |
| 创建自增ID | create table github(id int auto_increment primary key not null,name varchar(256)); |
| 查询头N条记录 | select * from shop_info limit N; |
| 检索记录行 6-15 | select * from table limit 5,10; |
| 删除记录 | delete from shop_info where shop_id="1"; |
| 排序+别名+分组+count | select city_name,count(*) as city_count from shop_info group by city_name <br/>order by city_count desc limit 5; |
| 两列排序+两列相乘 | select shop_id,count(*)*per_pay from shop_info order by per_pay desc,shop_id desc; |
| 每日统计 | select count(shop_id),date(time_stamp) as dates from user_pay <br/>where shop_id='1234' group by dates order by dates asc; |
| 年月日 | select year(ordertime),month(ordertime),day(ordertime) from book; |
| 周数+星期几 | select week(ordertime),weekday(ordertime) from book; |
| 统计表中的记录条数 | select count(*) from user_pay; |
| 统计某一列中不同值的个数 | select count(distinct user_id) from user_pay; |

参考：

http://www.cnblogs.com/wuhou/archive/2008/09/28/1301071.html

Ubuntu安装配置Mysql

http://www.cnblogs.com/wanghetao/p/3806888.html

MySQL添加用户、删除用户与授权

## 执行脚本

mysql命令行下执行：

`source a.sql`

## 导入csv文件

http://www.mysqltutorial.org/import-csv-file-mysql-table/

Import CSV File Into MySQL Table

示例：

{% highlight sql %}
LOAD DATA LOCAL INFILE 'c:/tmp/discounts.csv' 
INTO TABLE discounts 
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 ROWS;
{% endhighlight %}

上面的语句中，LOCAL必不可少，否则会报如下错误：

`ERROR 1290 (HY000): The MySQL server is running with the --secure-file-priv option so it cannot execute this statement`

## 日志

http://www.cnblogs.com/jevo/p/3281139.html

MySQL日志

## 时间的格式

| 名称 | 格式 |
|:--|:--|
| DATE | YYYY-MM-DD |
| DATETIME | YYYY-MM-DD HH:MM:SS |
| TIMESTAMP | YYYY-MM-DD HH:MM:SS |
| YEAR | YYYY或YY |

## 中间数据的存储

有的时候，SQL中间处理的结果需要存储起来，以备后用。这时有两种办法：

1.创建View。

{% highlight sql %}
CREATE VIEW view_name AS
SELECT column_name(s)
FROM table_name
WHERE condition;
{% endhighlight %}

View并不在数据库中存储数据，而是在查询时，执行其中的select语句（每次查询，都会执行），生成中间结果。因此，View从原理来说，更像是一种语法糖，而非存储机制。

2.使用select语句创建table。

`Create table new_table_name (Select * from old_table_name);`

这种方法会将中间结果存储到数据库中，下次使用的时候，就无需重新生成了。但缺点是原table中的更新不会体现到新table中，只适合处理历史数据。

## 模糊查询

http://www.cnblogs.com/GT_Andy/archive/2009/12/25/1921914.html

SQL 模糊查询

## 三种Join的区别

left join(左联接)返回包括左表中的所有记录和右表中联结字段相等的记录。

right join(右联接)返回包括右表中的所有记录和左表中联结字段相等的记录。

inner join(等值连接)只返回两个表中联结字段相等的行。

http://www.cnblogs.com/pcjim/articles/799302.html

sql之left join、right join、inner join的区别

## 查询语句的执行顺序

![](/images/img3/sql.png)

https://mp.weixin.qq.com/s/CMcgybfgya7ftTUeUFigKg

SQL查询语句总是先执行SELECT？你们都错了

## 参考

https://mp.weixin.qq.com/s/ok6VD1b5fhG_mY9O3d_VGA

记住，永远不要在MySQL中使用“utf8”

https://mp.weixin.qq.com/s/duYi1Y5jEWSPQbO3Bgsrrw

SQL Server与MySQL中排序规则与字符集相关知识的一点总结

https://mp.weixin.qq.com/s/N7-8vtVUg3MRY2u_NYpAiA

一份值得收藏的的MySQL规范

https://mp.weixin.qq.com/s/YX1XqKVfPS9DpMi_gTFNiA

1000行MySQL学习笔记

https://www.cnblogs.com/andy6/p/6959028.html

从Oracle迁移到MySQL的各种坑及自救方案

https://mp.weixin.qq.com/s/txbusDvTKwFZdX94kDp7VQ

10个不为人知的SQL技巧

https://mp.weixin.qq.com/s/qquMk4M81Pjw9fxkostf4Q

小米：Mysql数据实时同步实践

https://shockerli.net/post/1000-line-mysql-note/

一千行MySQL学习笔记

# 世说新语

## 2019.12（续）

1942年，在安徽，日军组织去突袭八路，日军指挥官很有想法，把日伪军队伍扮成娶亲的队伍，还弄了一个花轿。去偷袭八路，反被八路痛殴一顿。

八路总结三点：

1. 雇得起花轿的都是有钱人，有钱人办喜事都是穿的花花绿绿，穿黑的黄的办喜事的没见过。

2. 娶亲队伍边上没有看热闹的小孩。

3. 当下是秋收时节，都在农忙，谁家有空嫁女儿……

----

1945年6月，美国侦察机发来情报，日军正在撤退，建议国军趁胜追击，收复柳州。

国民党46军，为了抢头功，谎称已经收复了柳州（打个提前量？），于是美国航空队直挺挺的就降落在了柳州机场，下飞机集体懵逼了，直接落在日本人包围里，全成了俘虏，抗战结束才被释放。

----

唐朝士人的理想是“中状元，娶五姓女”。所谓五姓，就是五姓七望，博陵崔、清河崔、范阳卢、陇西李、赵郡李、荥阳郑、太原王。

----

2019.12.17 山东号航空母舰入列。

![](/images/img3/Carrier.jpg)

![](/images/img3/Carrier_2.jpg)

如果你有一艘航母，你就破坏了你所在地区的稳定。

如果你有两艘，你就会对全球秩序构成威胁。

如果你有一打，你就是全球维和人员。
