---
layout: post
title:  word2vec, LSTM Speech Recognition实战
category: AI 
---

* toc
{:toc}

# word2vec

word2vec是Google于2013年开源推出的一个用于获取word vector的工具包。作者是Tomas Mikolov。

Github：

https://github.com/tmikolov/word2vec

>注：Tomas Mikolov，捷克布尔诺科技大学博士。先后在Google、Facebook担任研究员。

word2vec包中还有一个word2phrase的程序，这个程序可以根据统计信息由单词生成短语。考虑到中文的字和词之间的关系，实际上也可以用它来进行无先验数据的分词。

>注：NLP中的先验数据，最出名的当属分词词典。除此之外，还包括HMM的转移矩阵表等。

其一般方法为：

1.对原始语料按字切分，以空格分隔，相当于认为一个字就是一个词，即**单字成词**。

2.使用word2phrase**组字成词**。

`time ./word2phrase -train 1.txt -output 2.txt -threshold 100 -debug 2`

3.由于word2phrase最多只考虑到2-gram。因此，对于超过3个字以上的词语，需要迭代执行word2phrase。

我以金庸的小说为语料进行测试。从结果来看，这种方法对于人名、地名、武功招式名等专有名词，分词效果较好。但对于具有语法结构的句子，分词效果较差。比如“那人”其实是两个单字词，但却被word2phrase认为是一个双字词。

`./word2vec -train resultbig.txt -output vectors.bin -cbow 0 -size 200 -window 5 -negative 0 -hs 1 -sample 1e-3 -threads 12 -binary 1`

`./distance vectors.bin`

训练之后的结果文件中，保存着每个词的向量。可将binary选项设为0，来查看相应结果的明文。

明文和二进制数据之间的转换可使用gensim工具，参见：

https://github.com/antkillerfarm/antkillerfarm_crazy/blob/master/python/ml/nlp/hello_gensim.py

参考：

http://wei-li.cnblogs.com/p/word2vec.html

文本深度表示模型Word2Vec

http://www.cnblogs.com/wowarsenal/p/3293586.html

用中文把玩Google开源的Deep-Learning项目word2vec

http://www.jianshu.com/p/05800a28c5e4

使用word2vec训练wiki中英文语料库

# LSTM Speech Recognition实战

## 数据集

首先，在Github上搜寻了一番，发现了以下项目：

https://github.com/zzw922cn/Automatic_Speech_Recognition

https://github.com/pandeydivesh15/AVSR-Deep-Speech

但是无奈他们使用的TIMIT数据集是收费的，只好放弃了。

最终，找到了如下项目：

https://github.com/sdhayalk/TensorFlow_Speech_Recognition_Challenge

这里用到的数据集也就是著名的Speech Commands Datasets。

## 复现结果

这里只实验了最简单的那个模型，遗憾的是该代码并不能直接使用，需要相应的预处理：

https://github.com/antkillerfarm/antkillerfarm_crazy/tree/master/python/ml/tensorflow/TensorFlow_Speech_Recognition_Challenge

这里还有一个坑，该项目只使用了11类声音，而把其他19类都归为unknown。这会导致unknown的权重过重，测试准确度虚高，（无脑分类为unknown都有60%以上的精度）但实际结果很差。需要使用一些方法处理数据的不平衡。

最终，复现结果精度大概在75%～80%之间。训练时间大概要16小时。

## 炼丹一

把类别扩展到30类，精度略高，但也就80%上下。如此费时的训练，只有这点结果，实在让人丧气。于是参考warpCTC，进行炼丹。

1.LSTM由3层减为1层。

2.使用CTC loss。（参见《深度学习（二十九）》）

在识别验证码的例子中，假如有两幅图，分别是123和4567，那么Label就是：

```text
[[1,2,3,0]
 [4,5,6,7]]
```

虽然英语是表音文字，但直接分解字母作为标签显然是不太精确的。

这里需要用到ARPABET表，该表可以看做是国际音标的另一种表示法：

https://en.wikipedia.org/wiki/ARPABET

还有如下工具可以将英文单词转换为ARPABET表示：

http://www.speech.cs.cmu.edu/tools/lextool.html

这个工具所使用的词典在：

http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/

精度大为提高到90%。

## 炼丹二

1.将LSTM改为BiLSTM。

2.使用1x1的卷积处理频谱。给feature map以不同的权重，有助于强化有效声音，弱化噪声。

3.使用3层FC。只对同一time step的频点做FC，不跨time step。

原理参见《深度学习（三十）》中的Deep speech 2。

精度再次提高到96%。如果不做第1步的修改的话，精度大概是94%，但计算快了很多，大概2个小时。

## fftw

fftw是一个C语言的FFT库，由MIT的Matteo Frigo和Steven G. Johnson编写。

>fft的实现往简单的说，也就几十行代码。这里这个3M+的庞然大物当然没这么简单。它使用了汇编、并行等加速手段，还支持DCT和DST变换。

官网：

http://fftw.org/

代码：

https://github.com/FFTW/fftw3

然而，由于fftw的代码是自动生成的，因此这个代码库实际上只供专业人士使用。普通用户直接在官网下载源代码包即可。

参考：

https://blog.csdn.net/congwulong/article/details/7576012

FFTW中文参考

## ocenaudio

一个用于音频剪辑处理的工具。免费但不开源。

官网：

http://www.ocenaudio.com/

## aubio

aubio是一个C语言的音频分析库，提供了提取fbank、MFCC等特征的能力。

找到aubio的过程，堪称曲折。最近要移植MFCC提取功能，到一嵌入式平台。因此要求代码必须是C语言。

1.Kaldi是C++写的，不合要求。

2.scipy.fftpack的核心是用C和Fortran写的，其实最主要的部分是Fortran写的。

3.使用Java语言的话，jMIR是个不错的选择。

代码：

https://github.com/aubio/aubio

安装：

`sudo apt install python3-aubio python-aubio aubio-tools libaubio-dev`

aubio的fft结果是以极坐标的格式保存的，而LibROSA则是以平面坐标的格式保存的。

示例1：测试环境是否安装好了，包括C和python环境。

https://github.com/antkillerfarm/antkillerfarm_crazy/tree/master/helloworld/aubio/1

示例2：python：获取wav文件的频谱。C：log重定向+读取wav文件内容。

https://github.com/antkillerfarm/antkillerfarm_crazy/tree/master/helloworld/aubio/2

参考：

http://www.cnblogs.com/daleloogn/p/4510137.html

音乐检索研究中使用的工具

## Ooura

Takuya Ooura是东京大学的教授，他写了一套数值计算的软件叫做Ooura，其中包含了FFT的实现。这也是aubio默认的FFT实现。缺点是只支持2的整数次方的FFT采样。

代码：

http://www.kurims.kyoto-u.ac.jp/~ooura/fft.html

这是作者收集的FFT库的列表：

http://www.kurims.kyoto-u.ac.jp/~ooura/fftlinks.html

## LibROSA

LibROSA是一个分析音乐和语音的Python库。

官网：

http://librosa.github.io/

代码：

https://github.com/librosa/librosa

文档：

http://librosa.github.io/librosa/

参考：

http://www.cnblogs.com/xingshansi/p/6816308.html

音频特征提取——librosa工具包使用

## python_speech_features

python_speech_features是另一个分析音乐和语音的Python库。

代码：

https://github.com/jameslyons/python_speech_features

文档：

https://python-speech-features.readthedocs.io/en/latest/

## 参考

论文：

《Small-footprint Keyword Spotting Using Deep Neural Network and Connectionist Temporal Classifier》

这篇文章是蚂蚁金服提出的Keyword Spotting（KWS）的论文，它和本次实战所用的Speech Commands Datasets契合度很高，值得参考。

http://mp.weixin.qq.com/s/-QQjz61VAOVcWE7j-EJPhg

谈谈蚂蚁金服的语音唤醒系统

这里还有两篇炼丹文：

https://zhuanlan.zhihu.com/p/28133530

一次CTC-RNN调参经历

http://www.tbluche.com/ctc_and_blank.html

The intriguing blank label in CTC

http://spandh.dcs.shef.ac.uk/chime_challenge/chime2016/

CHiMe – Computational Hearing in Multisource Environments-国际多通道语音分离和识别大赛

https://mp.weixin.qq.com/s/_hVHettrQLNZRTrO7Qh8qg

简单的音频识别

# 非洲+

非洲三大暴君：乌干达总统阿明、中非皇帝博卡萨、扎伊尔总统蒙博托。

---

自2013年开始法国就向马里派兵，打击当地分离主义图阿雷格民兵和伊斯兰国西非分支，结果却累战累败，不得不今年宣布减少在这一地区的军事存在。

毕竟现在连马里军政府都敢驱逐法国大使。

https://www.zhihu.com/question/20360133

法国是不是一直在衰落？

---

同一个客户，敬爱的阿比总统。用某龙和契丹装甲、教官差点亡国，一周损耗三万壮丁。换了土鸡装备和教官，立刻威风了起来，把提格雷赶回了老家。

---

在非洲有个国家叫加蓬，这个国家某些地方有一种神奇的“舅甥继承制”。自己的遗产不传给自己孩子，而是传给自己外甥。因为男性不能保证自己妻子生的孩子是自己的。但是可以保证，自己亲姐妹的孩子跟自己一定有血缘关系。

---

https://zhuanlan.zhihu.com/p/311321195

埃塞俄比亚，打起来了

https://www.zhihu.com/question/40795708

索马里兰是一个什么样的存在？

https://www.zhihu.com/question/33912256

索马里有多混乱？

https://zhuanlan.zhihu.com/p/367150702

刚刚总统阵亡的乍得，是个怎样的国家？

https://zhuanlan.zhihu.com/p/368174414

超级工程，撒哈拉沙漠大运河！

https://zhuanlan.zhihu.com/p/371417880

警惕，该组织已经渗透多个国家

https://zhuanlan.zhihu.com/p/375381294

14年了，美国非洲司令部为什么设在德国？

https://mp.weixin.qq.com/s/nfPaPOpIjPrgTEGytCPf0w

埃及前总统穆巴拉克去世：毁誉参半的一生

http://history.people.com.cn/GB/198306/14325368.html

奴隶？工人？金字塔的建造者竟是一群自由民

https://www.zhihu.com/question/40455049

莱索托与斯威士兰为何未被并入南非？

https://www.zhihu.com/question/271066736/answer/2178362363

中国在非洲修了哪些铁路？

https://zhuanlan.zhihu.com/p/455814066

非洲的眼泪，为何如此贫穷（乍得湖）
