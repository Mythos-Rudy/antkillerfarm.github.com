---
layout: post
title:  机器学习（三十八）——Optimizer进阶, 时间序列分析（2）
category: ML 
---

* toc
{:toc}

# Optimizer进阶

https://mp.weixin.qq.com/s/GS3TvS9nZw-CSJds-Aw_ug

UIUC孙若愚：60页论文综述深度学习优化

https://mp.weixin.qq.com/s/7E8o1TnvmAvZgB7_AWCunQ

2018值得尝试的无参数全局优化新算法

https://mp.weixin.qq.com/s/T-v9OTcJa5OQ71QmYrFtbg

斯坦福大学提出SGD动量自调节器YellowFin

https://mp.weixin.qq.com/s/6u5W7Lm81Wtczdzp5WCJWw

DeepMind提出新型超参数最优化方法：性能超越手动调参和贝叶斯优化

https://mp.weixin.qq.com/s/0V8B-u5_bRM5Fu9oOAYjqw

清华大学：通过在单纯形上软门限投影的加速随机贪心坐标下降

https://mp.weixin.qq.com/s/LuuvvL9yZ3ucXxRq0pZfsg

优化策略：Label Smoothing Regularization_LSR原理分析

https://zhuanlan.zhihu.com/p/23866364

从梯度下降到Hessian-Free优化

https://mp.weixin.qq.com/s/HPrjEdszBSvVoVS66W-Fjw

2017年深度学习优化算法研究亮点最新综述

https://mp.weixin.qq.com/s/W06YcuGWalDbyUaZa_kZnQ

2017年深度学习优化算法最新综述

https://mp.weixin.qq.com/s/WQ6CxRS-v_y-7PnYY-1ffg

在局部误差边界条件下的随机子梯度方法的加速

https://mp.weixin.qq.com/s/rOltA6fDzWmxcSyoHYqeSg

谷歌提出最新参数优化方法Adafactor，已在TensorFlow中开源

https://mp.weixin.qq.com/s/eTVPLSpZir4A49bhmWAibQ

深度学习中的各种优化算法

https://mp.weixin.qq.com/s/CQpIhVinDPhXpp70WhyYww

当前训练神经网络最快的方式：AdamW优化算法+超级收敛

https://mp.weixin.qq.com/s/y3ThoC2A04q4uWiOsuhUJw

腾讯AI Lab提出误差补偿式量化SGD：显著降低分布式机器学习的通信成本

https://mp.weixin.qq.com/s/aBt0qXPHFvwSs-0MtJYKjQ

一文告诉你Adam、AdamW、Amsgrad区别和联系，助你实现Super-convergence的终极目标

https://mp.weixin.qq.com/s/aZlJNZsSv60ZZi2heGo_Mw

一文简述深度学习优化方法——梯度下降

https://mp.weixin.qq.com/s/DsmjjfInV_yPFWB2oSq-dA

取代学习率衰减的新方法：谷歌大脑提出增加Batch Size

https://mp.weixin.qq.com/s/jgOQGDqDKtbJXbAj3EpI9A

别用大批量mini-batch训练神经网络，用局部SGD！

https://zhuanlan.zhihu.com/p/45298186

Matrix Factorization方法证明总结

https://mp.weixin.qq.com/s/0z4mt8iVk5gLRDwbhznV2g

如何理解深度学习的优化？通过分析梯度下降的轨迹

https://mp.weixin.qq.com/s/5MI1J16sEkr4UR4rSrw1wA

Michael Jordan新研究：采样可以比优化更快地收敛

https://mp.weixin.qq.com/s/g8GLF0rf3IPAjRb9wZaS4w

神经网络的奥秘之优化器的妙用

https://mp.weixin.qq.com/s/i-fE4aISTJ0584aIHJ8R0Q

二阶优化！训练ImageNet仅需35个Epoch

https://mp.weixin.qq.com/s/LY1-F5hEyM40DrvobYRexA

腾讯AI Lab&北大提出基于随机路径积分的差分估计子非凸优化方法

https://mp.weixin.qq.com/s/5KyODpSjkdYJ9q-itQDsAA

自Adam出现以来，深度学习优化器发生了什么变化？

https://mp.weixin.qq.com/s/3FSZOlA2sGQwiPj77ShTIQ

最优化算法鸟视解读

https://mp.weixin.qq.com/s/4hSar7SuCjLkZUjuIfu1Lg

如何选择最适合你的学习率变更策略

https://zhuanlan.zhihu.com/p/32923584

Tensorflow中learning rate decay的奇技淫巧

https://mp.weixin.qq.com/s/qk3cw05ZdlYEKDGRG0fnLg

距离几何优化问题--从美国计算机教授追回被抢车辆谈起

https://mp.weixin.qq.com/s/rHkfb1pZhtzVjzYiTRB4WA

交替方向乘子法（ADMM）的基本原理

https://mp.weixin.qq.com/s/4uaaeZSXavbVuU8d1AZA6Q

浅谈交替方向乘子法(ADMM)的经典使用

https://mp.weixin.qq.com/s/E3Iq8YpIZRZOk7SP-cu1xQ

如何找到全局最小值？先让局部极小值消失吧

https://mp.weixin.qq.com/s/el1E-61YjLkhFd6AgFUc7w

拳打Adam，脚踢SGD：北大提出全新优化算法AdaBound

https://mp.weixin.qq.com/s/TfrJ-rep-TIg345SXursbw

为了围剿SGD大家这些年想过的那十几招

https://mp.weixin.qq.com/s/9laU3EW0B64rwVb7so1BEA

机器学习中的最优化算法总结

https://mp.weixin.qq.com/s/mylRodVvvzI3e0-9-fEzTw

深度研究自然梯度优化，从入门到放弃

https://mp.weixin.qq.com/s/P0qzzyVQke_c-RUF0Faitw

怎么判断一个优化问题是凸优化还是非凸优化？

https://mp.weixin.qq.com/s/scGkuMJ4lZULhmK69vWYpA

中国博士生提出最先进AI训练优化器RAdam，收敛快精度高，网友亲测：Adam可以退休了

https://mp.weixin.qq.com/s/010zXPYu36oLOoSkaA8YMg

RAdam优化器又进化：与LookAhead强强结合，性能更优速度更快（Ranger）

https://mp.weixin.qq.com/s/g5mPfqxtEQBUvJQr0ORVBg

可以丢掉SGD和Adam了，新的深度学习优化器Ranger：RAdam + LookAhead强强结合

https://mp.weixin.qq.com/s/OtmMKR0OWytcUgbCMrSc-A

不是我们喜新厌旧，而是RAdam确实是好用，新的State of the Art优化器RAdam

https://www.zhihu.com/question/305694880

为什么K-FAC这种二阶优化方法没有得到广泛的应用？

https://mp.weixin.qq.com/s/etv5Ucyo2tiu64ZtUygz0A

离线优化器

https://mp.weixin.qq.com/s/zy5ALOInXHIh8LHmihu1UA

在线优化器之FOBOS

https://mp.weixin.qq.com/s/7UhB8mSXQUfOPbDKqqg4rg

非光滑优化的光滑化

https://zhuanlan.zhihu.com/p/92230537

求解稀疏优化问题——半光滑牛顿方法

https://mp.weixin.qq.com/s/aLOd_W3juLuWaQeTdzAPjg

数值优化（1）——引入，线搜索：步长选取条件

https://zhuanlan.zhihu.com/p/68748778

指数移动平均（EMA）的原理

https://mp.weixin.qq.com/s/x7UQhSAiE9VJCzUSZfpytA

大规模锥优化之Splitting Conic Solver(SCS)

https://mp.weixin.qq.com/s/EmWRaAOTNYE0Maf6_r41oA

Adam那么棒，为什么还对SGD念念不忘？一个框架看懂深度学习优化算法

https://mp.weixin.qq.com/s/sXIOEGWdjE4_NWjVIe2d3Q

耶鲁大学等提出AdaBelief的新型优化器，速度快，训练稳，泛化强

https://mp.weixin.qq.com/s/xeRBLkJTUs5wx2hZjyYeeQ

那些年“号称”要超越Adam的优化器

# 时间序列分析

## 工具

http://mp.weixin.qq.com/s/ioaS7RQ6bsJs4_X0G4ZHyQ

如何优雅地用TensorFlow预测时间序列：TFTS库详细教程

https://mp.weixin.qq.com/s/7WuB0uvGSAek9b4TP_0r9g

内置降维、聚类等算法，时间序列数据分析Python库Deeptime

https://zhuanlan.zhihu.com/p/391897734

FaceBook开源全网第一个时序王器Kats

## 参考

https://www.kaggle.com/thebrownviking20/everything-you-can-do-with-a-time-series/notebook

时间序列入门教程，从理论到业务实践，Kaggle kernels Master整理分享

https://mp.weixin.qq.com/s/V2cOgbq869TLChe1sWUQqg

开源时间序列数据集整理

https://mp.weixin.qq.com/s/FRSe1mJTvk9U66ta-r9iCQ

手把手教你用Python玩转时序数据，从采样、预测到聚类

https://mp.weixin.qq.com/s/7Y2we8gLidKMgnZCWnZURg

时间序列预测方法综述

https://mp.weixin.qq.com/s/Q82YzANWDMkKWm5k2XmPkA

严谨解决5种机器学习算法在预测股价的应用

https://mp.weixin.qq.com/s/iKM6zMSm1F2icjy79F9Hcg

季节性的分析才不简单，小心不要在随机数据中也分析出季节性

https://mp.weixin.qq.com/s/p8oN4xh-FHnay2eTsk6Gng

基于高阶模糊认知图与小波变换的时间序列预测

https://mp.weixin.qq.com/s/lmJk-iIzxxPmnZa6D8i_nw

一文简述如何使用嵌套交叉验证方法处理时序数据

https://mp.weixin.qq.com/s/05WAZcklXnL_hFPLZW9t7Q

时间序列模型之相空间重构模型

https://mp.weixin.qq.com/s/rIgjtILF7EtuBS5UWCEFcQ

重大事件后，股价将何去何从？

https://mp.weixin.qq.com/s/Y9d55KI64y-uRrWPRbDBzA

Kaggle知识点：时序数据与Embedding

https://mp.weixin.qq.com/s/DxRoTGtdrwqcjXL_ot57eg

如何找到时序数据中线性的趋势

https://mp.weixin.qq.com/s/iDUFr11-YX6oa6bLXWK3iQ

时序特征挖掘的奇技淫巧

https://mp.weixin.qq.com/s/S3xjk9QekWoni0eEvBhlLQ

特征工程之处理时间序列数据

https://mp.weixin.qq.com/s/15HXAIhmtYLbG3MjwEKDSQ

从移动平均到指数平滑

https://mp.weixin.qq.com/s/56so2p7a4wIgo38nVSR44A

时间序列分解总结

https://mp.weixin.qq.com/s/eHovfZiheQsv4Mb276su9w

核密度估计和非参数回归

https://mp.weixin.qq.com/s/6TpT1FH87esQWsUig0oS_Q

手把手教你用Python进行时间序列分解和预测

https://mp.weixin.qq.com/s/y6LL52Al3w5ErnpPX0A35Q

开源新书《时间序列分析，数据/方法/应用》，6章110页pdf带你了解最新进展

https://mp.weixin.qq.com/s/S3o4T8-CXVnS1laXE_g70w

Python中的时间序列分解

https://mp.weixin.qq.com/s/XImzWu0ZBe8Cgquc167iLA

用于时间序列数据的泊松回归模型

# Attention进阶+

https://mp.weixin.qq.com/s/-SU5cNbklI31WLmTawZJIQ

自注意模型学不好？这个方法帮你解决！

https://mp.weixin.qq.com/s/K5EbO0djcXHN4K5LQiMh5g

Triplet Attention机制让Channel和Spatial交互更加丰富

https://mp.weixin.qq.com/s/C4f0N_bVWU9YPY34t-HAEA

UNC&Adobe提出模块化注意力模型MAttNet，解决指示表达的理解问题

https://mp.weixin.qq.com/s/V3brXuey7Gear0f_KAdq2A

基于注意力机制的交易上下文感知推荐，悉尼科技大学和电子科技大学最新工作

https://mp.weixin.qq.com/s/2gxp7A38epQWoy7wK8Nl6A

谷歌翻译最新突破，“关注机制”让机器读懂词与词的联系

https://zhuanlan.zhihu.com/p/25928551

用深度学习（CNN RNN Attention）解决大规模文本分类问题-综述和实践

https://mp.weixin.qq.com/s/l4HN0_VzaiO-DwtNp9cLVA

循环注意力区域实现图像多标签分类

https://mp.weixin.qq.com/s/zhZLK4pgJzQXN49YkYnSjA

自适应注意力机制在Image Caption中的应用

https://mp.weixin.qq.com/s/uvr-G5-_lKpyfyn5g7ES0w

基于注意力机制，机器之心带你理解与训练神经机器翻译系统

https://mp.weixin.qq.com/s/ANpBFnsLXTIiW6WHzGrv2g

自注意力机制学习句子embedding

https://mp.weixin.qq.com/s/49fQX8yiOIwDyof3PD01rA

CMU&谷歌大脑提出新型问答模型QANet：仅使用卷积和自注意力，性能大大优于RNN

https://mp.weixin.qq.com/s/c64XucML13OwI26_UE9xDQ

滴滴披露语音识别新进展：基于Attention显著提升中文识别率

https://mp.weixin.qq.com/s/7OYY3L7gL4wVv_EjoosOHA

如何增强Attention Model的推理能力

https://mp.weixin.qq.com/s/9Kt6_DfeYRnhsb10aCSFGw

FAGAN：完全注意力机制（Full Attention）GAN，Self-attention+GAN

https://mp.weixin.qq.com/s/lZOIK5BRXZrmL_Z9crl6sA

机器翻译新突破！“普适注意力”模型：概念简单参数少，性能大增

https://mp.weixin.qq.com/s/jRfOzKO6OlQLokIzipbqUQ

为什么使用自注意力机制？

https://zhuanlan.zhihu.com/p/339123850

关于attention机制的一些细节的思考

https://mp.weixin.qq.com/s/n4mzHSweOT-vDWBGs0XFbw

卷积神经网络中的自我注意
