---
layout: post
title:  NVIDIA, GPU通信技术
category: Chip 
---

* toc
{:toc}

# NVIDIA

NVIDIA作为行业龙头，其影响力甚至在Khronos Group之上，它提出的标准很多成为了行业的事实标准。

>最近（2018.2），公司副总M给我们讲座的时候，回顾他早年在NVIDIA的经历，当时他作为公司骨干，曾拥有数万股NV的股票，可惜早都卖了。这十几年来，NV股票经过5次分拆，当初的一股现在要值6500美元。他要不卖，现在可能已经是亿万富翁了。。。

![](/images/img3/nvidia.jpg)

## 术语

iGPU：Integrated Graphics Processing Unit。

dGPU：Discrete Graphics Processing Unit。

## 产品线

Tesla产品专为数据中心与工作站计算应用而设计。

Quadro产品专为专业图形与工程应用而设计。

GeForce产品专为互动游戏与消费类应用而设计。

|  | NVIDIA Tesla V100 | NVIDIA RTX 3090 |
|:--:|:--:|:--:|
| FP32 (float) performance | 14.13 TFLOPS | 35.58 TFLOPS |
| FP64 (double) performance | 7066 GFLOPS | 1112 GFLOPS |

RTX系列属于对于机器学习来说性价比较高的显卡，但是双精度浮点数性能很弱。

## 驱动安装

查看显卡硬件型号：

`ubuntu-drivers devices`

安装驱动：

`sudo ubuntu-drivers autoinstall`

参考：

https://zhuanlan.zhihu.com/p/59618999

Ubuntu 18.04安装NVIDIA显卡驱动

## CUDA

CUDA是NVIDIA最早推出的通用数学运算库。除了基本的数学运算之外，还提供了一些工具包：

cuBLAS：线性计算库。

NVBLAS：多GPU版的cuBLAS。

cuFFT：FFT计算库。

nvGRAPH：图计算库。（这里的图是数学图论中的图，和DL框架中的计算图是两回事。）

cuRAND：随机数生成库。

cuSPARSE；稀疏矩阵计算库。

cuSOLVER：解线性方程的计算库。包括解稠密方程的cuSolverDN、解稀疏方程的cuSolverSP和矩阵分解的cuSolverRF。

CUTLASS：另一个线性计算库。功能比cuBLAS更多。

## Deep Learning SDK

cuDNN：DL计算库。

NCCL：多结点、多GPU的通信库。

TensorRT：嵌入式设备上专用于DL inference的计算库。

NVIDIA DIGITS：一款web应用工具，可在网页上对Caffe进行图形化操作和可视化。

TensorRT还有个云端的集群版本：

https://github.com/NVIDIA/tensorrt-inference-server

参考：

https://mp.weixin.qq.com/s/v8-JHd5tWm41WLqR-h6eKA

使用TensorRT集成加速TensorFlow推理

https://mp.weixin.qq.com/s/rMvhsi2vXxVC65C5Z4IXIw

AI视频处理加速引擎TensorRT及Deepstream介绍

https://zhuanlan.zhihu.com/p/35657027

高性能深度学习支持引擎实战——TensorRT

https://www.zhihu.com/question/63219175

如何理解Nvidia英伟达的Multi-GPU多卡通信框架NCCL？

## NVDLA

NVIDIA Deep Learning Accelerator是一个开源的用于inference的芯片方案。官网：

http://nvdla.org/

参考：

https://mp.weixin.qq.com/s/aFmr6WKhZ3E-PsF6-uJvJg

一图理清Nvidia AI软件栈

## NVIDIA DALI

NVIDIA DALI是一个GPU加速的数据增强和图像加载库，为优化深度学习框架数据pipeline而设计，而其中的NVIDIA nvJPEG是用于JPEG解码的高性能GPU加速库。

代码：

https://github.com/NVIDIA/dali

## Tensor Core

https://mp.weixin.qq.com/s/pPjPLqgXZ8iCPS42vXJpuQ

NVIDIA Tensor Core深度学习核心解析

## PTX

PTX (Parallel Thread Execution) 是NVIDIA GPU的伪指令集，之所以加个伪字，主要是因为这个指令集并不是真的硬件指令集，而仅仅是个抽象指令集。

gcc和llvm都有特定的pass可以生成PTX代码。

NVIDIA GPU真正的指令集，被称作SASS。

https://zhuanlan.zhihu.com/p/161624982

SASS指令集概述

## CUDA-X AI

CUDA-X AI是软件加速库的集合，这些库建立在CUDA之上，提供对于深度学习、机器学习和高性能计算必不可少的优化功能。这些库包括cuDNN（用于加速深度学习基元）、cuML（用于加速数据科学工作流程和机器学习算法）、TensorRT（用于优化受训模型的推理性能）、cuDF（用于访问 pandas 之类的数据科学 API）、cuGraph（用于在图形上执行高性能分析），以及超过13个的其他库。

官网：

https://www.nvidia.cn/technologies/cuda-x/

## RAPIDS

RAPIDS，全称Real-time Acceleration Platform for Integrated Data Science，是NVIDIA针对数据科学和机器学习推出的一套开源GPU加速库，基于CUDA-X AI打造。

官网：

https://rapids.ai/

代码：

https://github.com/rapidsai

![](/images/img4/RAPIDS.png)

参考：

https://blog.csdn.net/sinat_26917383/article/details/104503795

NVIDIA的python-GPU算法生态

## CUDA实战

安装：

http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html

参考：

http://ishare.iask.sina.com.cn/f/17211495.html

深入浅出谈CUDA技术

http://blog.csdn.net/xsc_c/article/category/2186063

某人的并行计算专栏

https://mp.weixin.qq.com/s/9D7uda3CV7volenhl-jchg

推荐几个不错的CUDA入门教程

https://mp.weixin.qq.com/s/bvNnzkOzGYYYewc3G9DOIw

GPU是如何优化运行机器学习算法的？

https://mp.weixin.qq.com/s/nAwxtOUi6HpIjVOREgEfaA

CUDA编程入门极简教程

https://mp.weixin.qq.com/s/-zdIWkuRZXhsLJmOZljOBw

《基于GPU-多核-集群等并行化编程》

https://mp.weixin.qq.com/s/bCb5VsH58JII886lpg9lvg

如何在CUDA中为Transformer编写一个PyTorch自定义层

https://mp.weixin.qq.com/s/OYSzol-vufiKPuU9YxtbuA

矩阵相乘在GPU上的终极优化：深度解析Maxas汇编器工作原理

https://zhuanlan.zhihu.com/p/358220419

PyTorch自定义CUDA算子教程与运行时间分析

https://zhuanlan.zhihu.com/p/358778742

详解PyTorch编译并调用自定义CUDA算子的三种方式

https://zhuanlan.zhihu.com/p/360441891

熬了几个通宵，我写了份CUDA新手入门代码

https://mp.weixin.qq.com/s/EZxO8IIBDJ4c7eQhUffc2w

怎样节省2/3的GPU？爱奇艺vGPU的探索与实践

https://mp.weixin.qq.com/s/3VjGpyXZSkJhy6sFPUsZzw

GPU虚拟化，算力隔离，和qGPU

https://zhuanlan.zhihu.com/p/383115932

大佬是怎么优雅实现矩阵乘法的？

https://zhuanlan.zhihu.com/p/410278370

CUDA矩阵乘法终极优化指南

https://www.zhihu.com/column/c_1437330196193640448

深入浅出GPU优化

# AMD

![](/images/img4/latestGPU.png)

HIP：Heterogeneous Interface for Portability。

HIP是AMD提出的C++接口，号称能兼容CUDA和自家的ROCm。

# Shader

基于OpenGL的OpenGL Shading Language，简称GLSL;

基于DirectX的High Level Shading Language，简称HLSL;

NVIDIA公司的C for Graphic，简称Cg。

除此之外，一些框架也有自己的SL，例如Unity-Shader。

https://zhuanlan.zhihu.com/p/47433678

三大Shader编程语言（CG/HLSL/GLSL）

https://zhuanlan.zhihu.com/p/25024372

跨平台shader编译的过去、现在和未来

http://tieba.baidu.com/p/2155772860

GPU和Shader技术的基础知识

http://www.jianshu.com/p/8687a040eb48

GPU处理图像Shader的入门

https://zhuanlan.zhihu.com/p/25595069

卡通渲染（上）：致从没看懂过着色器代码的你

https://zhuanlan.zhihu.com/p/25939794

卡通渲染（下）

# GPU通信技术

## RDMA

RDMA网卡（Remote Direct Memory Access，这是一种硬件的网络技术，它使得计算机访问远程的内存时无需远程机器上CPU的干预）已经可以提供50~100Gbps的网络带宽和微秒级的传输延迟。

目前许多以深度学习为目标应用的GPU机群都部署了这样的网络。

UCX是一个建立在RDMA等技术之上的用于数据处理和高性能计算的通信框架，RDMA是其底层核心之一。

OpenUCX是UCX的一个开源实现。

官网：

https://www.openucx.org/

参考：

https://mp.weixin.qq.com/s/_xcE8RUs0m4gwk3kxpe9jA

基于HTM/RDMA的可扩展内存事务处理系统

https://www.zhihu.com/column/c_1231181516811390976

一个RDMA方面的专栏

## NVLink

NVLink技术提供比PCIe 3更高的带宽与更多的链路，并可提升多GPU和多GPU/CPU系统配置的可扩展性。

官网：

https://www.nvidia.cn/data-center/nvlink/

![](/images/img3/nvlink.png)

Tesla V100中以NVLink连接的GPU至GPU和GPU至CPU通信。

![](/images/img3/nvlink_2.png)

在DGX-1V服务器中，混合立体网络拓扑使用NVLink连接8个Tesla V100加速器。每个GPU有6条nvlink通道，总带宽高达300GB/s。

从上图可以看到，即使每个GPU拥有6条nvlink通道，仍然无法做到“全连接”（即任意两个GPU之间存在双向通道）。这就引出了下一个更加疯狂的技术：nvswitch。

![](/images/img3/nvswitch.png)

NVSwitch是首款节点交换架构，可支持单个服务器节点中16个全互联的GPU，并可使全部8个GPU对分别以300GB/s的惊人速度进行同时通信。这16个全互联的GPU还可作为单个大型加速器，拥有0.5 TB统一显存空间和2 PetaFLOPS计算性能。

## 参考

https://www.infoq.cn/article/3D4MsRVS8ZOtGCj7*krT

GPU通信技术初探

https://zhuanlan.zhihu.com/p/67785062

不止显卡！这些硬件因素也影响着你的深度学习模型性能
