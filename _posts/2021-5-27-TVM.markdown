---
layout: post
title:  TVM
category: AI 
---

* toc
{:toc}

# TVM

TVM是陈天奇领导的一个DL加速框架项目。它处于DL框架（如tensorflow、pytorch）和硬件后端（如CUDA、OpenCL）之间，兼顾了前者的易用性和后者的执行效率。

官网：

https://tvm.apache.org/

代码：

https://github.com/apache/tvm

![](/images/img3/tvm_stack.png)

论文：

《TVM: End-to-End Optimization Stack for Deep Learning》

和同类项目的差异：

- TFLite和ONNXRuntime只能接收特定格式的模型。而TVM这些都能接收。

- NCNN、MACE之类的项目，一般只考虑了ARM CPU的优化，对于异构计算做的比较少。

- TVM强化了图优化的部分，使之更类似于编译器的架构。

## 架构

官网：

https://tvm.apache.org/docs/arch/index.html

![](/images/img4/tvm_dyn_workflow.svg)

![](/images/img4/tvm_static_overview.svg)

## 安装

TVM暂时**不支持**pip安装，`pip install tvm`安装的是另一个同名软件。。。

## TVM Runtime

![](/images/img4/tvm_rpc.png)

TVM采用C/S模式进行部署，其中在target机器上的部分，被称为TVM Runtime。

TVM Runtime的代码通常比较薄，只需要把host发过来的优化结果执行即可。

官方文档：

http://tvm.apache.org/docs/dev/runtime.html

TVM Runtime也是BYOC的重要组成部分。

BYOC：Bring Your Own Codegen

https://tvm.apache.org/2020/07/15/how-to-bring-your-own-codegen-to-tvm

How to Bring Your Own Codegen to TVM

这是中文翻译版：

https://zhuanlan.zhihu.com/p/337033822

如何在TVM上集成Codegen（上）

https://zhuanlan.zhihu.com/p/337037547

如何在TVM上集成Codegen（下）

示例：

https://github.com/antkillerfarm/antkillerfarm_crazy/blob/master/python/ml/tvm/pytorch2tvm.py

该示例包含以下内容：

1.如何导入pytorch和tflite的模型。

2.local执行和remote执行。

3.使用`print(mod.astext(show_meta_data=False))`可以打印相关IR的内容。meta data有的时候包含了权重，打印出来意义不大，反而导致其他部分没法看了。

参考：

https://zhuanlan.zhihu.com/p/369981405

部署TVM Runtime

https://zhuanlan.zhihu.com/p/352988283

TVM学习记录——pytorch

## NNVM

NNVM是一个类似于ONNX、NNEF的中间表示。

官网：

https://github.com/dmlc/nnvm

参考：

https://mp.weixin.qq.com/s/qkvX0rmEe0yQ-BhCmWAXSQ

李沐：AWS开源端到端AI框架编译器NNVM

## Relay

Relay是TVM中用来替代NNVM的模块，其本身被认为是NNVM第二代。

官网：

https://tvm.apache.org/docs/arch/relay_intro.html

NNVM本质上只能描述传统的计算图，这属于Data Flow的范畴。但是现在的DL框架越来越灵活，不仅能对数据进行计算，还能对数据进行一定的控制处理，也就是所谓的Control Flow（if-else/ADT matching/递归调用）。

参考：

https://zhuanlan.zhihu.com/p/91283238

TVM图编译器Relay简单探究

https://zhuanlan.zhihu.com/p/390087648

Relay IR与Relay Pass

https://mp.weixin.qq.com/s/Kt4xDLo-NRui8Whl0DqcSA

Data Flow和Control Flow

## Pass

https://tvm.apache.org/docs/how_to/extend_tvm/use_pass_infra.html

和LLVM类似，TVM的Pass也可分为两类：

ModulePass：将整个程序视作一个单元处理的pass。

FunctionPass：以单个函数为作用域的pass, 每个函数间是相互独立的。

FunctionPass包括了Relay层的`tvm.relay.transform.FunctionPass`和TIR层的`tvm.tir.transform.PrimFuncPass`。

部分pass：

- FoldConstant: src/relay/transforms/fold_constant.cc

- AlterOpLayout: src/relay/transforms/alter_op_layout.cc

- Legalize: src/relay/transforms/legalize.cc

- MergeComposite: src/relay/transforms/merge_composite.cc

参考：

https://zhuanlan.zhihu.com/p/378739411

万字长文入门TVM Pass

https://www.cnblogs.com/wujianming-110117/p/14580172.html

TVM Pass IR如何使用

https://zhuanlan.zhihu.com/p/112813859

Relay Pass in TVM

https://zhuanlan.zhihu.com/p/358437531

pass总结

## Schedule Primitives

https://tvm.apache.org/docs/how_to/work_with_schedules/schedule_primitives.html

## Layout

TVM默认的input layout: NCHW，kernel layout: OIHW。

## Backend

python层面：

python/tvm/relay/op/contrib/ethosn.py

```python
@register_pattern_table("ethos-n")
def pattern_table():
@tvm.ir.register_op_attr("nn.max_pool2d", "target.ethos-n")
def max_pool2d(attrs, args):
```

relay层面：

src/relay/backend/contrib/ethosn

```cpp
TVM_REGISTER_GLOBAL("relay.ext.ethos-n").set_body_typed(CompileEthosn);
```

runtime层面：

src/runtime/contrib/ethosn

test：

tests/python/contrib/test_ethosn

## 代码分析

TVM建立了一套类型系统：

```cpp
class BaseExprNode : public Object;
class BaseExpr : public ObjectRef;
```

根据基类，查看实际类型：

`XX->checked_type()`

## Quantize

![](/images/img4/TVM_QNN.png)

## microTVM

microTVM可用于那些没有OS的单片机。

官网：

https://tvm.apache.org/docs/arch/microtvm_design.html

![](/images/img4/microtvm_workflow.svg)

![](/images/img4/microtvm_host_driven.svg)

![](/images/img4/microtvm_standalone.svg)

从上面的图来看，microTVM只要在单片机的main函数中启动即可，同时参数也可以放到FLASH上。

PS：这种能直接寻址的FLASH，多半是NOR FLASH。

参考：

https://zhuanlan.zhihu.com/p/337085225

TinyML-TVM是如何驯服Tiny的（上）

https://zhuanlan.zhihu.com/p/337087273

TinyML-TVM是如何驯服Tiny的（下）

## 参考

https://zhuanlan.zhihu.com/p/139552817

一篇关于深度学习编译器架构的综述论文

https://www.zhihu.com/question/396105855

针对神经网络的编译器和传统编译器的区别和联系是什么？

https://mp.weixin.qq.com/s/8bXwxYyNjdThlGQQ70cgWQ

TVM：端到端自动深度学习编译器，244页ppt

https://zhuanlan.zhihu.com/p/333706468

TVM学习系列blog

https://zhuanlan.zhihu.com/p/163717035

AI编译优化

https://www.zhihu.com/question/267167829

如何看待Tensor Comprehensions？与TVM有何异同？（这个问题下的答案不多，但基本都是陈天奇、贾扬清之类的大佬）

https://mp.weixin.qq.com/s/irvBbPKENiZX9G_6wh5c-Q

陈天奇等人提出TVM：深度学习自动优化代码生成器

https://mp.weixin.qq.com/s/28n8g_epHsYB0I9GVc_lww

陈天奇团队TVM重磅更新：直接在浏览器使用GPU

https://mp.weixin.qq.com/s/7JGLm-hkCZBNDLA98qvWNA

自动生成硬件优化内核：陈天奇等人发布深度学习编译器TVM

https://mp.weixin.qq.com/s/YVIvdMznb3oatIXqD5a5_A

陈天奇等人提出AutoTVM：让AI来编译优化AI系统底层算子

https://mp.weixin.qq.com/s/HquT_mKm7x_rbDGz4Voqpw

阿里巴巴最新实践：TVM+TensorFlow提高神经机器翻译性能

https://zhuanlan.zhihu.com/p/50529704

手把手带你遨游TVM

https://mp.weixin.qq.com/s/z5rsU_uAAaRxgD9YAxDkZA

陈天奇：深度学习编译技术的现状和未来

https://zhuanlan.zhihu.com/p/75203171

如何利用TVM快速实现超越Numpy(MKL)的GEMM

https://zhuanlan.zhihu.com/p/58918363

TVM: Deep Learning模型的优化编译器

https://zhuanlan.zhihu.com/p/87664838

也谈TVM和深度学习编译器

https://mp.weixin.qq.com/s/VE3CySjjS2rTpUDPnKcLTg

陈天奇最新研究：递归模型编译器CORTEX

https://zhuanlan.zhihu.com/p/358585143

深度学习编译器及TVM介绍

https://zhuanlan.zhihu.com/p/360385060

TVM中的scheduler

https://zhuanlan.zhihu.com/p/388452164

tvm or mlir？

# TVM实战

## 问题的由来

最近客户反馈我们的backend导入Pytorch模型会出错，而TFLite模型是OK的。

打印模型的IR后，我们发现：

这是Pytorch模型的IR片段：

```text
  %0 = qnn.quantize(%input, 0.0186579f, 114, out_dtype="uint8", axis=1);
  %1 = nn.pad(%0, 114f, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %2 = qnn.quantize(%features.0.0_weight, 0.00288958f, 0, out_dtype="int8", axis=0);
  %3 = qnn.conv2d(%1, %2, 114, 0, 0.0186579f, 0.00288958f, strides=[2, 2], padding=[0, 0, 0, 0], channels=32, kernel_size=[3, 3], out_dtype="int32");
  %4 = qnn.quantize(%features.0.0_bias, 5.39136e-05f, 0, out_dtype="int32", axis=0);
  %5 = nn.bias_add(%3, %4);
  %6 = qnn.requantize(%5, 5.39136e-05f, 0, 0.0150183f, 0, axis=1, out_dtype="int32");
  %7 = clip(%6, a_min=0f, a_max=255f);
  %8 = cast(%7, dtype="uint8");
```

这是TFLite模型的IR片段：

```text
  %0 = qnn.quantize(%input, 0.0186579f /* ty=float32 */, 114 /* ty=int32 */, out_dtype="uint8", axis=1) /* ty=Tensor[(1, 3, 224, 224), uint8] */;
  %1 = nn.pad(%0, 114f /* ty=float32 */, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(1, 3, 226, 226), uint8] */;
  %2 = qnn.conv2d(%1, meta[relay.Constant][0] /* ty=Tensor[(32, 3, 3, 3), int8] */, 114 /* ty=int32 */, 0 /* ty=int32 */, 0.0186579f /* ty=float32 */, 0.00288958f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=32, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(1, 32, 112, 112), int32] */;
  %3 = nn.bias_add(%2, meta[relay.Constant][1] /* ty=Tensor[(32), int32] */) /* ty=Tensor[(1, 32, 112, 112), int32] */;
  %4 = qnn.requantize(%3, 5.39136e-05f /* ty=float32 */, 0 /* ty=int32 */, 0.0150183f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype="uint8") /* ty=Tensor[(1, 32, 112, 112), uint8] */;
```

可以看出同一个QnnConv2D两者的展开形式存在一定的差异，但是语义上却基本是一致的。

## 模型导入

在继续主题之前，我们首先来看看这个展开形式的差异是如何造成的。



# GLOW

代码：

https://github.com/pytorch/glow

参考：

https://zhuanlan.zhihu.com/p/102127047

Glow: Graph Lowering Compiler for Neural Networks

# NNFusion

代码：

https://github.com/microsoft/nnfusion

参考：

https://mp.weixin.qq.com/s/CMTOW3cYQkkECpPuzZl0nQ

RAMMER如何进一步“压榨”加速器性能
