---
layout: post
title:  数学狂想曲（三）——统计杂谈
category: math 
---

# 概率分布（1）

## 泊松分布（续）

参考：

https://www.zhihu.com/question/26441147

泊松分布的现实意义是什么，为什么现实生活多数服从于泊松分布？

http://www.ruanyifeng.com/blog/2015/06/poisson-distribution.html

泊松分布和指数分布：10分钟教程

http://blog.csdn.net/kicilove/article/details/78655856

数据科学家应知必会的6种常见概率分布

## 贝塔分布和共轭先验分布

$$f(x;\alpha,\beta)=\frac{x^{\alpha-1}(1-x)^{\beta-1}}{B(\alpha,\beta)}$$

贝塔分布的PDF和CDF如下图所示：

![](/images/article/beta.png)

![](/images/article/beta1.png)

从上图可以看出它是个百变星君，它可以是凹的、凸的、单调上升的、单调下降的；可以是曲线也可以是直线。由于Beta分布能够拟合如此之多的形状，因此它在统计数据拟合中，被广泛使用。

下面来讲一下Beta分布的推导，并引出共轭先验分布的概念。

设一事件A的概率$$p(A)=\theta$$，为了估计$$\theta$$的值，作了n次独立观察，其中事件A出现的次数为X。显然X服从二项分布$$X\sim B(n,\theta)$$。

因此：

$$p(X=x\mid \theta)= \binom{n}{x}\theta^{x}(1-\theta)^{n-x}$$

利用贝叶斯公式，我们首先需要确定先验概率$$p(\theta)$$。在未得到其余信息前，我们只能认为$$\theta$$在(0,1)上均匀分布（即$$\theta\sim Uniform(0,1)$$），这是一种不失偏颇的先验估计。

则联合概率分布为：

$$p(x,\theta)=p(x\mid \theta)p(\theta)$$

边缘概率分布：

$$\begin{align}p(x)&=\int_{0}^{1}p(x,\theta)d\theta=\int_{0}^{1}\binom{n}{x}\theta^{x}(1-\theta)^{n-x}d\theta\\
&=\binom{n}{x}B(x+1,n-x+1)=\binom{n}{x}\frac{\Gamma(x+1)\Gamma(n-x+1)}{\Gamma(n+2)}\end{align}$$

综合以上，可得$$\theta$$的后验分布:

$$p(\theta\mid x)=\frac{p(x,\theta)}{p(x)}=\frac{\theta^{(x+1)-1}(1-\theta)^{(n-x+1)-1}}{B(x+1,n-x+1)}$$

因此：$$\theta \mid x\sim Beta(x+1,n-x+1)$$

考虑到$$Uniform(0,1)=Beta(1,1)$$，因此在这个例子中，先验分布和后验分布，实际上是同一类型的分布。这种情况被称为共轭先验分布。

上述过程的形式化描述为：

$$Uniform(\theta)+B(n,\theta)\to Beta(x+1,n-x+1)$$

即

$$先验参数分布+数据分布\to 后验分布$$

**定义**：设$$\theta$$是某分布中的一个参数，$$\pi(\theta)$$是其先验分布。假如由抽样信息算得的后验分布$$\pi(\theta \mid x)$$与$$\pi(\theta)$$同属于一个分布族，则称$$\pi(\theta)$$是$$\theta$$的**共轭先验分布**。

从这个定义可以看出，共轭先验分布是对某一分布中的参数而言的，离开指定参数及其所在的分布，谈论共轭先验分布是没有意义的。

常见的共轭先验分布：

| 总体分布 | 参数 | 共轭先验分布 |
|:--:|:--:|:--:|
| 二项分布 | 成功概率 | 贝塔分布 |
| 泊松分布 | 均值 | 伽马分布 |
| 指数分布 | 均值倒数 | 伽马分布 |
| 正态分布（方差已知） | 均值 | 正态分布 |
| 正态分布（方差未知） | 方差 | 倒伽马分布 |

共轭先验分布中，由于先验分布和后验分布都是同一个分布族，因此有利于简化计算。同时，先验参数往往会传递到后验分布，这样就能够比较方便的确定参数的实际意义。

参考：

http://blog.csdn.net/u010945683/article/details/49149815

共轭先验分布

## 多项分布和狄利克雷分布

伯努利试验只有两个可能的实验结果，如果实验结果的个数超过2个，那么二项分布就变成了多项分布（multinomial distribution）：

$$f(x_1,\ldots,x_k;n,p_1,\ldots,p_k)=\frac{n!}{x_1!\cdots x_k!} p_1^{x_1} \cdots p_k^{x_k}$$

多项分布对应的共轭先验分布是狄利克雷分布（Dirichlet distribution）：

$$f \left(x_1,\cdots, x_{K}; \alpha_1,\cdots, \alpha_K \right) = \frac{1}{\mathrm{B}(\boldsymbol\alpha)} \prod_{i=1}^K x_i^{\alpha_i - 1}\tag{1}$$

这里引入向量表示的贝塔函数：

$$\mathrm{B}(\boldsymbol\alpha) = \frac{\prod_{i=1}^K \Gamma(\alpha_i)}{\Gamma\left(\sum_{i=1}^K \alpha_i\right)},\qquad\boldsymbol{\alpha}=(\alpha_1,\cdots,\alpha_K)$$

狄利克雷分布的密度函数如下所示(3维)：

![](/images/article/dirichlet-distribution.png)

上面的图，实际上是个4维图，只不过用一个平面上的三角形代表实验结果的3维而已。这也是一种高维数据可视化的方法。

和多项分布类似的还有Categorical Distribution：

- 将一个小球放入k个桶，记变量X为k个桶内的小球个数，所以是一个向量，并且是One-hot的形式，因为这个小球只能在一个桶里面，所以是服从Categorical分布；

- 将n个小球放入k个桶，记变量X为k个桶内的小球个数，是一个向量，并且向量元素的和为n，所以是服从多项分布。

参考：

http://cos.name/2013/01/lda-math-beta-dirichlet/

LDA-math-认识Beta/Dirichlet分布

http://www.cs.cmu.edu/~epxing/Class/10701-08s/recitation/dirichlet.pdf

Dirichlet Distribution, Dirichlet Process and Dirichlet Process Mixture

https://zhuanlan.zhihu.com/p/59550457

Categorical Distribution

## 各种概率分布的关系

![](/images/article/distribution.jpg)

参考：

http://www.math.wm.edu/~leemis/2008amstat.pdf

Univariate Distribution Relationships

http://www.wzchen.com/s/probability_cheatsheet.pdf

Probability Cheatsheet v2.0

https://mp.weixin.qq.com/s/svNVryWhiGxWFBz0s0dX5g

概率论简史

# 统计杂谈

## 统计模拟

统计模拟是数理统计中非常有用的工具之一， 它是利用计算机产生某概率模型的随机数，再通过这些随机数来模拟真实模型。

这方面的书籍首推Sheldon M.Ross所著的《Simulation》。

>注：Sheldon M.Ross，斯坦福大学统计学博士（1968），UCB教授（1976～2004），南加州大学Industrial and Systems Engineering系主任。

以下仅记录一些简单的结论。

### 均匀分布

通过线性同余生成器（linear congruential generator, LCG）可以生成伪随机数，且该随机数满足均匀分布。

$$x_n=ax_{n-1}\quad \mathrm{modulo} \quad m$$

这里的a和m通常都是大质数。

### 正态分布

**Box-Muller变换**：如果随机变量$$U_1,U_2$$独立且$$U_1, U_2 \sim Uniform(0,1)$$，

$$\begin{align} 
Z_0 & = \sqrt{-2\ln U_1} cos(2\pi U_2) \\ 
Z_1 & = \sqrt{-2\ln U_1} sin(2\pi U_2) 
\end{align}$$

则$$Z_0,Z_1$$独立且服从标准正态分布。

>注：George Edward Pelham Box，1919~2013，英国统计学家。伦敦学院大学博士，先后供职于普林斯顿大学和威斯康辛-麦迪逊大学。Ronald Aylmer Fisher的女婿。英国皇家学会会员，美国统计协会主席，数理统计学会（这是一个国际组织）主席。

>Mervin Edgar Muller，俄亥俄州立大学教授。

https://mp.weixin.qq.com/s?__biz=MzI1MTIzMzI2MA==&mid=2650561098&idx=1&sn=675375265279cce7fdb1ecd94fd7a549

生成特定分布随机数的方法

### numpy实战

从上面的描述可以看出，统计模拟一般包括两步：

1.生成均匀分布的随机数（Random generator）。例如：`numpy.random.rand`或`tf.random.uniform`。

2.通过采样（Draw samples）将分布变为特定分布。例如：`numpy.random.multinomial`或`tf.random.categorical`。

### Mersenne Twister

LCG是最古老，也是最知名的伪随机序列生成器算法（Pseudorandom number generator, PRNG）。然而它也有一些缺点：

1.如果用于选择n维空间中的点，那么这些点至多会位于$$(n! \cdot m)^{1/n}$$超平面（Marsaglia's Theorem）。

2.当m为2的幂时，低阶比特周期较短。

因此，在Monte Carlo模拟或者加密算法领域，通常要使用更高质量的PRNG。

Mersenne Twister算法是1997年由Makoto Matsumoto(松本 眞)和Takuji Nishimura(西村 拓士)提出的算法。这种算法由于和梅森素数（Mersenne prime）有关，故名。

该算法最常见的实现基于梅森素数$$2^{19937}-1$$，因此又被称为MT19937。原始的MT19937可以生成32位的随机数，它还有64位的版本：MT19937-64。

MT算法的实现也很多了，参见原作者的官网：

http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html

----

除了MT算法之外，Philox算法也是比较常用的，且后者更适合并行，速度也更快。

Philox原作者官网：

http://www.thesalmons.org/john/random123/

Philox算法的实现一般以philox_4x32_10的形式命名，它表明算法一次能生成4个32位的无符号数，10表示运算迭代的次数。

官方的代码由于要考虑各种兼容性，写的复杂无比，这里有一个精简版：

https://github.com/antkillerfarm/antkillerfarm_crazy/blob/master/Tool/Gcc/random/philox.c

还有一个进阶版，增加了多线程并行生成、均匀分布变换、正态分布变换的功能：

https://github.com/antkillerfarm/antkillerfarm_crazy/blob/master/Tool/Gcc/random/philox_1.c

----

https://bashtage.github.io/randomgen/index.html

这是一个RNG（Random Number Generation）项目，集成了多种算法。

参考：

https://blog.csdn.net/wuha391/article/details/78486021

随机算法mt19937

https://blog.csdn.net/caimouse/article/details/55668071

mt19937是什么鬼？

http://michaelbrundage.com/note/2005/01/05/random-number-generation/

这是一篇RNG方面的综述。

http://www.azillionmonkeys.com/qed/random.html

这篇blog讲述了将随机整数变为浮点数，需要注意的问题。

## 统计力学与组合优化

MCMC和Gibbs Sampling最早都是统计力学的概念，后来才被用于机器学习领域。现将统计力学与组合优化的对应关系罗列如下：

| 统计力学 | 组合优化 |
|:--:|:--:|
| 样本 | 问题实例 |
| 状态（构形） | 构形 |
| 能量 | 代价函数 |
| 温度 | 控制参数 |
| 基态能量 | 最小代价 |
| 基态构形 | 最小构形 |

## 频率统计学派 vs. 贝叶斯学派

对数学史感兴趣的朋友，可以看看陈希孺院士的《数理统计学简史》一书。rickjin文章的内容有相当部分取自该书。

>注：陈希孺，1934～2005，数理统计学家。1956年毕业于武汉大学数学系，1997年当选为中国科学院院士。

该书中关于频率统计学派和贝叶斯学派的争议，引起了我的注意。
